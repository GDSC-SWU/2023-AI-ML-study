{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d964c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c478160",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_merges=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0360668",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'l o w </w>' : 5,\n",
    "         'l o w e r </w>' : 2,\n",
    "         'n e w e s t </w>':6,\n",
    "         'w i d e s t </w>':3\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4721892d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Iteration 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
      "new merge: ('e', 's')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
      "new merge: ('es', 't')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
      "new merge: ('est', '</w>')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('l', 'o')\n",
      "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('lo', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 6"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('n', 'e')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('ne', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('new', 'est</w>')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('low', '</w>')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('w', 'i')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
     ]
    }
   ],
   "source": [
    "def get_stats(dictionary):\n",
    "    # 유니그램의 pair들의 빈도수를 카운트\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in dictionary.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    print('현재 pair들의 빈도수 :', dict(pairs))\n",
    "    return pairs\n",
    "\n",
    "def merge_dictionary(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "bpe_codes = {}\n",
    "bpe_codes_reverse = {}\n",
    "\n",
    "for i in range(num_merges):\n",
    "    display(Markdown(\"### Iteration {}\".format(i + 1)))\n",
    "    pairs = get_stats(dictionary)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    dictionary = merge_dictionary(best, dictionary)\n",
    "\n",
    "    bpe_codes[best] = i\n",
    "    bpe_codes_reverse[best[0] + best[1]] = best\n",
    "\n",
    "    print(\"new merge: {}\".format(best))\n",
    "    print(\"dictionary: {}\".format(dictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ad3d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('e', 's'): 0, ('es', 't'): 1, ('est', '</w>'): 2, ('l', 'o'): 3, ('lo', 'w'): 4, ('n', 'e'): 5, ('ne', 'w'): 6, ('new', 'est</w>'): 7, ('low', '</w>'): 8, ('w', 'i'): 9}\n"
     ]
    }
   ],
   "source": [
    "print(bpe_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ed5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def encode(orig):\n",
    "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
    "\n",
    "    word = tuple(orig) + ('</w>',)\n",
    "    display(Markdown(\"__word split into characters:__ <tt>{}</tt>\".format(word)))\n",
    "\n",
    "    pairs = get_pairs(word)    \n",
    "\n",
    "    if not pairs:\n",
    "        return orig\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        display(Markdown(\"__Iteration {}:__\".format(iteration)))\n",
    "\n",
    "        print(\"bigrams in the word: {}\".format(pairs))\n",
    "        bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
    "        print(\"candidate for merging: {}\".format(bigram))\n",
    "        if bigram not in bpe_codes:\n",
    "            display(Markdown(\"__Candidate not in BPE merges, algorithm stops.__\"))\n",
    "            break\n",
    "        first, second = bigram\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            try:\n",
    "                j = word.index(first, i)\n",
    "                new_word.extend(word[i:j])\n",
    "                i = j\n",
    "            except:\n",
    "                new_word.extend(word[i:])\n",
    "                break\n",
    "\n",
    "            if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                new_word.append(first+second)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_word = tuple(new_word)\n",
    "        word = new_word\n",
    "        print(\"word after merging: {}\".format(word))\n",
    "        if len(word) == 1:\n",
    "            break\n",
    "        else:\n",
    "            pairs = get_pairs(word)\n",
    "\n",
    "    # 특별 토큰인 </w>는 출력하지 않는다.\n",
    "    if word[-1] == '</w>':\n",
    "        word = word[:-1]\n",
    "    elif word[-1].endswith('</w>'):\n",
    "        word = word[:-1] + (word[-1].replace('</w>',''),)\n",
    "\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5229416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'k', 'i', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'k'), ('l', 'o'), ('k', 'i'), ('i', '</w>')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'k', 'i', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('lo', 'k'), ('k', 'i'), ('i', '</w>')}\n",
      "candidate for merging: ('lo', 'k')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('lo', 'k', 'i')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"loki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e20380e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('w', 'e'), ('t', '</w>'), ('e', 's'), ('s', 't'), ('l', 'o'), ('o', 'w')}\n",
      "candidate for merging: ('e', 's')\n",
      "word after merging: ('l', 'o', 'w', 'es', 't', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('t', '</w>'), ('w', 'es'), ('es', 't'), ('l', 'o'), ('o', 'w')}\n",
      "candidate for merging: ('es', 't')\n",
      "word after merging: ('l', 'o', 'w', 'est', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 3:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('est', '</w>'), ('l', 'o'), ('w', 'est')}\n",
      "candidate for merging: ('est', '</w>')\n",
      "word after merging: ('l', 'o', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 4:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'est</w>'), ('l', 'o')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 5:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('lo', 'w'), ('w', 'est</w>')}\n",
      "candidate for merging: ('lo', 'w')\n",
      "word after merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 6:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('low', 'est</w>')}\n",
      "candidate for merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('low', 'est')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96131148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'w', 'i', 'n', 'g', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('n', 'g'), ('i', 'n'), ('w', 'i'), ('l', 'o'), ('o', 'w'), ('g', '</w>')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'w', 'i', 'n', 'g', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('lo', 'w'), ('n', 'g'), ('i', 'n'), ('w', 'i'), ('g', '</w>')}\n",
      "candidate for merging: ('lo', 'w')\n",
      "word after merging: ('low', 'i', 'n', 'g', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 3:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('low', 'i'), ('i', 'n'), ('g', '</w>'), ('n', 'g')}\n",
      "candidate for merging: ('low', 'i')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('low', 'i', 'n', 'g')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f03d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('h', 'i', 'g', 'h', 'i', 'n', 'g', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('h', 'i'), ('n', 'g'), ('i', 'n'), ('g', 'h'), ('i', 'g'), ('g', '</w>')}\n",
      "candidate for merging: ('h', 'i')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('h', 'i', 'g', 'h', 'i', 'n', 'g')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"highing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c6c0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\ana\\lib\\site-packages (0.1.99)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bcb6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce84b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x217ed466b50>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21955926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        My family and I normally do not watch local mo...\n",
       "1        Believe it or not, this was at one time the wo...\n",
       "2        After some internet surfing, I found the \"Home...\n",
       "3        One of the most unheralded great works of anim...\n",
       "4        It was the Sixties, and anyone with long hair ...\n",
       "                               ...                        \n",
       "49995    the people who came up with this are SICK AND ...\n",
       "49996    The script is so so laughable... this in turn,...\n",
       "49997    \"So there's this bride, you see, and she gets ...\n",
       "49998    Your mind will not be satisfied by this nobud...\n",
       "49999    The chaser's war on everything is a weekly sho...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('IMDb_Reviews.csv')\n",
    "train_df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "436f57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 개수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print('리뷰 개수 :',len(train_df)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c57ec220",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imdb_review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(train_df['review']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0cfe0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=imdb_review.txt --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771abfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>▁Tony</td>\n",
       "      <td>-3671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>rough</td>\n",
       "      <td>-4073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>▁blond</td>\n",
       "      <td>-4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>▁fail</td>\n",
       "      <td>-1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>▁te</td>\n",
       "      <td>-446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>awn</td>\n",
       "      <td>-3527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>▁way</td>\n",
       "      <td>-410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>▁concept</td>\n",
       "      <td>-2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>and</td>\n",
       "      <td>-189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>▁carry</td>\n",
       "      <td>-3206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1\n",
       "3674     ▁Tony -3671\n",
       "4076     rough -4073\n",
       "4259    ▁blond -4256\n",
       "1261     ▁fail -1258\n",
       "449        ▁te  -446\n",
       "3530       awn -3527\n",
       "413       ▁way  -410\n",
       "2588  ▁concept -2585\n",
       "192        and  -189\n",
       "3209    ▁carry -3206"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv('imdb.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfe862e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d085f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"imdb.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b039c6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't at all think of it this way.\n",
      "['▁I', '▁didn', \"'\", 't', '▁at', '▁all', '▁think', '▁of', '▁it', '▁this', '▁way', '.']\n",
      "[41, 624, 4950, 4926, 139, 170, 378, 30, 58, 73, 413, 4945]\n",
      "\n",
      "I have waited a long time for someone to film\n",
      "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
      "[41, 142, 1364, 1121, 4, 668, 285, 93, 1079, 33, 91]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "  \"I didn't at all think of it this way.\",\n",
    "  \"I have waited a long time for someone to film\"\n",
    "]\n",
    "for line in lines:\n",
    "  print(line)\n",
    "  print(sp.encode_as_pieces(line))\n",
    "  print(sp.encode_as_ids(line))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7002c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83dd5f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁character'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.IdToPiece(430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee3bfc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.PieceToId('▁character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c42b614c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iul wa fall aold timeooland to film'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds([41, 141, 1364, 1120, 4, 666, 285, 92, 1078, 33, 91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6a747bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have waited a long time for someone to film'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodePieces(['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6b23322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
      "[41, 142, 1364, 1121, 4, 668, 285, 93, 1079, 33, 91]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode('I have waited a long time for someone to film', out_type=str))\n",
    "print(sp.encode('I have waited a long time for someone to film', out_type=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acbf8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b82eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x217821bc790>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff78ed6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_df = pd.read_table('ratings.txt')\n",
    "naver_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d7abbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 개수 : 200000\n"
     ]
    }
   ],
   "source": [
    "print('리뷰 개수 :',len(naver_df)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "562b6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(naver_df.isnull().values.any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "315d6e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "naver_df = naver_df.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(naver_df.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "631b95c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 개수 : 199992\n"
     ]
    }
   ],
   "source": [
    "print('리뷰 개수 :',len(naver_df)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bd9c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(naver_df['document']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "096d8007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>영화</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁이</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁아</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ᄏᄏ</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  <unk>  0\n",
       "1    <s>  0\n",
       "2   </s>  0\n",
       "3     ..  0\n",
       "4     영화 -1\n",
       "5    ▁영화 -2\n",
       "6     ▁이 -3\n",
       "7     ▁아 -4\n",
       "8    ... -5\n",
       "9     ᄏᄏ -6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv('naver.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc025038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5986d6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"naver.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81db06dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뭐 이딴 것도 영화냐.\n",
      "['▁뭐', '▁이딴', '▁것도', '▁영화냐', '.']\n",
      "[136, 970, 1299, 2593, 3276]\n",
      "\n",
      "진짜 최고의 영화입니다 ㅋㅋ\n",
      "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
      "[54, 204, 825, 121]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "  \"뭐 이딴 것도 영화냐.\",\n",
    "  \"진짜 최고의 영화입니다 ㅋㅋ\",\n",
    "]\n",
    "for line in lines:\n",
    "  print(line)\n",
    "  print(sp.encode_as_pieces(line))\n",
    "  print(sp.encode_as_ids(line))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c351ea32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb746a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'영화'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.IdToPiece(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5570273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'진짜 원 산~~'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds([54, 200, 821, 85])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d05af515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'진짜 최고의 영화입니다 ᄏᄏ'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodePieces(['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c17cd033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
      "[54, 204, 825, 121]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode('진짜 최고의 영화입니다 ㅋㅋ', out_type=str))\n",
    "print(sp.encode('진짜 최고의 영화입니다 ㅋㅋ', out_type=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59f416b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\ana\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: huggingface_hub<0.17,>=0.16.4 in c:\\ana\\lib\\site-packages (from tokenizers) (0.16.4)\n",
      "Requirement already satisfied: requests in c:\\ana\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\ana\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\ana\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\ana\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (21.3)\n",
      "Requirement already satisfied: fsspec in c:\\ana\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\ana\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\ana\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\ana\\lib\\site-packages (from packaging>=20.9->huggingface_hub<0.17,>=0.16.4->tokenizers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<0.17,>=0.16.4->tokenizers) (0.4.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\ana\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ana\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ana\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\ana\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d405ab37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x217811ab5e0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6215970",
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_df = pd.read_table('ratings.txt')\n",
    "naver_df = naver_df.dropna(how='any')\n",
    "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(naver_df['document']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0907bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(lowercase=False, strip_accents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "017abb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'naver_review.txt'\n",
    "vocab_size = 30000\n",
    "limit_alphabet = 6000\n",
    "min_frequency = 5\n",
    "\n",
    "tokenizer.train(files=data_file,\n",
    "                vocab_size=vocab_size,\n",
    "                limit_alphabet=limit_alphabet,\n",
    "                min_frequency=min_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69654e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./vocab.txt']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab 저장\n",
    "tokenizer.save_model('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee20962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>말밖에는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>맘을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>맛도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>망하지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>망한다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0       [PAD]\n",
       "1       [UNK]\n",
       "2       [CLS]\n",
       "3       [SEP]\n",
       "4      [MASK]\n",
       "...       ...\n",
       "29995    말밖에는\n",
       "29996      맘을\n",
       "29997      맛도\n",
       "29998     망하지\n",
       "29999     망한다\n",
       "\n",
       "[30000 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab 로드\n",
    "df = pd.read_fwf('vocab.txt', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "308ebe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 결과 : ['아', '배고', '##픈', '##데', '짜장면', '##먹고', '##싶다']\n",
      "정수 인코딩 : [2111, 20630, 3501, 3317, 24681, 7872, 7379]\n",
      "디코딩 : 아 배고픈데 짜장면먹고싶다\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode('아 배고픈데 짜장면먹고싶다')\n",
    "print('토큰화 결과 :',encoded.tokens)\n",
    "print('정수 인코딩 :',encoded.ids)\n",
    "print('디코딩 :',tokenizer.decode(encoded.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b949ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 결과 : ['커피', '한잔', '##의', '여유', '##를', '즐기', '##다']\n",
      "정수 인코딩 : [12825, 25645, 3280, 12696, 3412, 10784, 3241]\n",
      "디코딩 : 커피 한잔의 여유를 즐기다\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode('커피 한잔의 여유를 즐기다')\n",
    "print('토큰화 결과 :',encoded.tokens)\n",
    "print('정수 인코딩 :',encoded.ids)\n",
    "print('디코딩 :',tokenizer.decode(encoded.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f16f39ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁이', '▁영화는', '▁정말', '▁재미있', '습니다.']\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer, CharBPETokenizer, SentencePieceBPETokenizer\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer()\n",
    "tokenizer.train('naver_review.txt', vocab_size=10000, min_frequency=5)\n",
    "\n",
    "encoded = tokenizer.encode(\"이 영화는 정말 재미있습니다.\")\n",
    "print(encoded.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f01e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
