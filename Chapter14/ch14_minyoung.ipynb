{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xDCnm9boZb2X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib3\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def download_zip(url, output_path):\n",
        "    response = requests.get(url, headers=headers, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(output_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"ZIP file downloaded to {output_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n",
        "\n",
        "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
        "output_path = \"fra-eng.zip\"\n",
        "download_zip(url, output_path)\n",
        "\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, output_path)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "852cLNmZZiKe",
        "outputId": "bb6c8c24-6eca-4f29-85aa-9dcbe557475f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP file downloaded to fra-eng.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']\n",
        "print('전체 샘플의 개수 :',len(lines))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bhkmQ_5aQW8",
        "outputId": "827efbff-fc14-40f0-8bc6-a57575a395d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 개수 : 227815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000] # 6만개만 저장\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5-SWRwhVakUY",
        "outputId": "cde096f5-5d85-44c7-9ce7-88766e2c3a9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          src                                 tar\n",
              "50684   No one is interested.            Ça n'intéresse personne.\n",
              "56461  I don't think I snore.      Je ne crois pas que je ronfle.\n",
              "48486   I kept my mouth shut.                  Je tins ma langue.\n",
              "34754     Is this book yours?             Ce livre est-il à toi ?\n",
              "706                 I'm lazy.                  Je suis paresseux.\n",
              "27091      I really like you.                 Je t'aime vraiment.\n",
              "50789   Playing cards is fun.  C'est amusant de jouer aux cartes.\n",
              "32200     Don't buy that one.                   N'achetez pas ça.\n",
              "6410            This is hers.                  Ce sont les siens.\n",
              "7287           Don't be rude.              Ne soyez pas impolie !"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73b77f44-6dcf-429b-9251-d935554ab14a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50684</th>\n",
              "      <td>No one is interested.</td>\n",
              "      <td>Ça n'intéresse personne.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56461</th>\n",
              "      <td>I don't think I snore.</td>\n",
              "      <td>Je ne crois pas que je ronfle.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48486</th>\n",
              "      <td>I kept my mouth shut.</td>\n",
              "      <td>Je tins ma langue.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34754</th>\n",
              "      <td>Is this book yours?</td>\n",
              "      <td>Ce livre est-il à toi ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706</th>\n",
              "      <td>I'm lazy.</td>\n",
              "      <td>Je suis paresseux.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27091</th>\n",
              "      <td>I really like you.</td>\n",
              "      <td>Je t'aime vraiment.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50789</th>\n",
              "      <td>Playing cards is fun.</td>\n",
              "      <td>C'est amusant de jouer aux cartes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32200</th>\n",
              "      <td>Don't buy that one.</td>\n",
              "      <td>N'achetez pas ça.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6410</th>\n",
              "      <td>This is hers.</td>\n",
              "      <td>Ce sont les siens.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7287</th>\n",
              "      <td>Don't be rude.</td>\n",
              "      <td>Ne soyez pas impolie !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73b77f44-6dcf-429b-9251-d935554ab14a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73b77f44-6dcf-429b-9251-d935554ab14a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73b77f44-6dcf-429b-9251-d935554ab14a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea092ec7-534d-444e-befa-784333443264\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea092ec7-534d-444e-befa-784333443264')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea092ec7-534d-444e-befa-784333443264 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DxpbGscXaoTf",
        "outputId": "bffaa495-2c76-4397-9a24-74fc439faacb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          src                                       tar\n",
              "2014              I enjoy it.                          \\t J'aime ça. \\n\n",
              "27729      I'm on page three.            \\t Je suis à la page trois. \\n\n",
              "34803     It has no parallel.            \\t Ça n'a pas de parallèle. \\n\n",
              "18712        You are a prude.                  \\t Tu es un puritain. \\n\n",
              "39675    Have a safe journey.                   \\t Fais bon voyage ! \\n\n",
              "59580  That seems like a lot.            \\t Ça semble être beaucoup. \\n\n",
              "53309   What's in the coffee?  \\t Qu'est-ce qu'il y a dans le café ? \\n\n",
              "58507  It won't happen again.             \\t Ça ne se produira plus. \\n\n",
              "43517    The law was changed.      \\t La législation a été modifiée. \\n\n",
              "19042        You're too slow.               \\t Vous êtes trop lents. \\n"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77f2759e-68b0-4c2c-bd81-20bf4936880b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>I enjoy it.</td>\n",
              "      <td>\\t J'aime ça. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27729</th>\n",
              "      <td>I'm on page three.</td>\n",
              "      <td>\\t Je suis à la page trois. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34803</th>\n",
              "      <td>It has no parallel.</td>\n",
              "      <td>\\t Ça n'a pas de parallèle. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18712</th>\n",
              "      <td>You are a prude.</td>\n",
              "      <td>\\t Tu es un puritain. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39675</th>\n",
              "      <td>Have a safe journey.</td>\n",
              "      <td>\\t Fais bon voyage ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59580</th>\n",
              "      <td>That seems like a lot.</td>\n",
              "      <td>\\t Ça semble être beaucoup. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53309</th>\n",
              "      <td>What's in the coffee?</td>\n",
              "      <td>\\t Qu'est-ce qu'il y a dans le café ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58507</th>\n",
              "      <td>It won't happen again.</td>\n",
              "      <td>\\t Ça ne se produira plus. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43517</th>\n",
              "      <td>The law was changed.</td>\n",
              "      <td>\\t La législation a été modifiée. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19042</th>\n",
              "      <td>You're too slow.</td>\n",
              "      <td>\\t Vous êtes trop lents. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77f2759e-68b0-4c2c-bd81-20bf4936880b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77f2759e-68b0-4c2c-bd81-20bf4936880b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77f2759e-68b0-4c2c-bd81-20bf4936880b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c5ea55bd-3ba0-4ea7-a677-99672cb3ea03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5ea55bd-3ba0-4ea7-a677-99672cb3ea03')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c5ea55bd-3ba0-4ea7-a677-99672cb3ea03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자 집합 구축\n",
        "src_vocab = set()\n",
        "for line in lines.src: # 1줄씩 읽음\n",
        "    for char in line: # 1개의 문자씩 읽음\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)"
      ],
      "metadata": {
        "id": "ZLXAmR7Vaqqz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print('source 문장의 char 집합 :',src_vocab_size)\n",
        "print('target 문장의 char 집합 :',tar_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXPrIoHjasBX",
        "outputId": "7780bf54-4618-4a8f-f0dd-6a26b2d03367"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 char 집합 : 80\n",
            "target 문장의 char 집합 : 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDYuesr8atLV",
        "outputId": "764cab27-7706-4642-dd76-d3e8ad0e8581"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCJQ9NFsaudq",
        "outputId": "d25f34ef-3236-4295-acb6-739a5e8a685f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, 'ï': 77, '’': 78, '€': 79}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102, '‽': 103}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = []\n",
        "\n",
        "# 1개의 문장\n",
        "for line in lines.src:\n",
        "  encoded_line = []\n",
        "  # 각 줄에서 1개의 char\n",
        "  for char in line:\n",
        "    # 각 char을 정수로 변환\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  encoder_input.append(encoded_line)\n",
        "print('source 문장의 정수 인코딩 :',encoder_input[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PvXvj9Qav1y",
        "outputId": "2fb38456-763c-4d4a-a1ae-dec308a43299"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(tar_to_index[char])\n",
        "  decoder_input.append(encoded_line)\n",
        "print('target 문장의 정수 인코딩 :',decoder_input[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srZwbiajaw80",
        "outputId": "ad74cb7b-05de-496f-8f34-01e2e1cadd59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장의 정수 인코딩 : [[1, 3, 48, 52, 3, 4, 3, 2], [1, 3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [1, 3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [1, 3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target = []\n",
        "for line in lines.tar:\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    if timestep > 0:\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "    timestep = timestep + 1\n",
        "  decoder_target.append(encoded_line)\n",
        "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTOa0qqnayXy",
        "outputId": "c0e0e325-3f66-4570-a433-894d4da0d709"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장 레이블의 정수 인코딩 : [[3, 48, 52, 3, 4, 3, 2], [3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print('source 문장의 최대 길이 :',max_src_len)\n",
        "print('target 문장의 최대 길이 :',max_tar_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLCmoRweazhP",
        "outputId": "dc491ade-e4f6-447f-aa78-0c9ec78073b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이 : 22\n",
            "target 문장의 최대 길이 : 76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "metadata": {
        "id": "Oue9C5gZa0ri"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "metadata": {
        "id": "rcijg_z_a2vW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "OaGh_p0Aa4Di"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "\n",
        "# encoder_outputs은 여기서는 불필요\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "mA5KtBeQa6JI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "\n",
        "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "metadata": {
        "id": "SnmqjuBba79z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR0OVSVTa-Nk",
        "outputId": "fb011f88-a92d-4929-825a-9133f90f3c90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 [==============================] - 24s 19ms/step - loss: 0.8495 - val_loss: 0.7650\n",
            "Epoch 2/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.5740 - val_loss: 0.6610\n",
            "Epoch 3/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.5042 - val_loss: 0.6061\n",
            "Epoch 4/40\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.4566 - val_loss: 0.5537\n",
            "Epoch 5/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.4206 - val_loss: 0.5209\n",
            "Epoch 6/40\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.3947 - val_loss: 0.4911\n",
            "Epoch 7/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3750 - val_loss: 0.4707\n",
            "Epoch 8/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3589 - val_loss: 0.4559\n",
            "Epoch 9/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3456 - val_loss: 0.4438\n",
            "Epoch 10/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3342 - val_loss: 0.4335\n",
            "Epoch 11/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3241 - val_loss: 0.4223\n",
            "Epoch 12/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3150 - val_loss: 0.4141\n",
            "Epoch 13/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3070 - val_loss: 0.4050\n",
            "Epoch 14/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2997 - val_loss: 0.3977\n",
            "Epoch 15/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2932 - val_loss: 0.3931\n",
            "Epoch 16/40\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2870 - val_loss: 0.3905\n",
            "Epoch 17/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2814 - val_loss: 0.3801\n",
            "Epoch 18/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2762 - val_loss: 0.3782\n",
            "Epoch 19/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2714 - val_loss: 0.3738\n",
            "Epoch 20/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2669 - val_loss: 0.3692\n",
            "Epoch 21/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2625 - val_loss: 0.3660\n",
            "Epoch 22/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2584 - val_loss: 0.3637\n",
            "Epoch 23/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2546 - val_loss: 0.3615\n",
            "Epoch 24/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2508 - val_loss: 0.3598\n",
            "Epoch 25/40\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2474 - val_loss: 0.3562\n",
            "Epoch 26/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2440 - val_loss: 0.3558\n",
            "Epoch 27/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2408 - val_loss: 0.3527\n",
            "Epoch 28/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2378 - val_loss: 0.3526\n",
            "Epoch 29/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2349 - val_loss: 0.3500\n",
            "Epoch 30/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2321 - val_loss: 0.3491\n",
            "Epoch 31/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2293 - val_loss: 0.3479\n",
            "Epoch 32/40\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2267 - val_loss: 0.3474\n",
            "Epoch 33/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2242 - val_loss: 0.3474\n",
            "Epoch 34/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2218 - val_loss: 0.3455\n",
            "Epoch 35/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2194 - val_loss: 0.3440\n",
            "Epoch 36/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2170 - val_loss: 0.3442\n",
            "Epoch 37/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2148 - val_loss: 0.3426\n",
            "Epoch 38/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2126 - val_loss: 0.3436\n",
            "Epoch 39/40\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2105 - val_loss: 0.3414\n",
            "Epoch 40/40\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.2084 - val_loss: 0.3429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fc8d0183640>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n"
      ],
      "metadata": {
        "id": "rWqWK4MTa_kx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
        "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n"
      ],
      "metadata": {
        "id": "DmIEdLmZc2Yy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())\n"
      ],
      "metadata": {
        "id": "4tVD1Hdcc3xI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_tar_len):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence\n"
      ],
      "metadata": {
        "id": "1LrbP3Cec5ZX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index:seq_index+1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장:', lines.src[seq_index])\n",
        "  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpI1qPSAc6yT",
        "outputId": "f7678bee-abb5-47d0-8032-e470eb6d55d4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 410ms/step\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go.\n",
            "정답 문장: Bouge ! \n",
            "번역 문장: Dégage ! \n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Hello!\n",
            "정답 문장: Bonjour ! \n",
            "번역 문장: Salut ! \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Got it!\n",
            "정답 문장: J'ai pigé ! \n",
            "번역 문장: Allez ! \n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go home.\n",
            "정답 문장: Rentre à la maison. \n",
            "번역 문장: Va au lit ! \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Get going.\n",
            "정답 문장: En avant. \n",
            "번역 문장: Allez-vous ! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ],
      "metadata": {
        "id": "QtKTfQOCdC__"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def download_zip(url, output_path):\n",
        "    response = requests.get(url, headers=headers, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(output_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"ZIP file downloaded to {output_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n",
        "\n",
        "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
        "output_path = \"fra-eng.zip\"\n",
        "download_zip(url, output_path)\n",
        "\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, output_path)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySNXJrwLdIYG",
        "outputId": "8bdd2059-90ff-477d-b119-611c86fa647e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP file downloaded to fra-eng.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 33000\n"
      ],
      "metadata": {
        "id": "CiM6ZccpdPmf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_ascii(s):\n",
        "  # 프랑스어 악센트(accent) 삭제\n",
        "  # 예시 : 'déjà diné' -> deja dine\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  # 악센트 제거 함수 호출\n",
        "  sent = to_ascii(sent.lower())\n",
        "\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) \"I am a student.\" => \"I am a student .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # 다수 개의 공백을 하나의 공백으로 치환\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent\n"
      ],
      "metadata": {
        "id": "1zj5pcqndRzm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 테스트\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print('전처리 전 영어 문장 :', en_sent)\n",
        "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
        "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
        "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mEDiO1GdTOD",
        "outputId": "cfcd2f06-f999-4f4e-d863-d93ad8747da5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 영어 문장 : Have you had dinner?\n",
            "전처리 후 영어 문장 : have you had dinner ?\n",
            "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
            "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"fra.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      # source 데이터와 target 데이터 분리\n",
        "      src_line, tar_line, _ = line.strip().split('\\t')\n",
        "\n",
        "      # source 데이터 전처리\n",
        "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # target 데이터 전처리\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line)\n",
        "      decoder_input.append(tar_line_in)\n",
        "      decoder_target.append(tar_line_out)\n",
        "\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "\n",
        "  return encoder_input, decoder_input, decoder_target\n"
      ],
      "metadata": {
        "id": "P32B_t8vdUwm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
        "print('인코더의 입력 :',sents_en_in[:5])\n",
        "print('디코더의 입력 :',sents_fra_in[:5])\n",
        "print('디코더의 레이블 :',sents_fra_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxih4dLGdXAx",
        "outputId": "58414fbc-5569-490f-8e61-0de3012a51bf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
            "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
            "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "metadata": {
        "id": "VK66u-t5dY4w"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
        "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
        "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdVWby5ada8w",
        "outputId": "c2549dc9-d725-43e9-9df8-2f0ff29e0a0c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력의 크기(shape) : (33000, 7)\n",
            "디코더의 입력의 크기(shape) : (33000, 16)\n",
            "디코더의 레이블의 크기(shape) : (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiXTMp8odcxN",
        "outputId": "82110ed7-fdb2-4f76-d32a-4b7b5cb2e0de"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어 집합의 크기 : 4481, 프랑스어 단어 집합의 크기 : 7873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "metadata": {
        "id": "qwWdnvCTdeHO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('랜덤 시퀀스 :',indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37JfslQvdfng",
        "outputId": "562d3044-3e5b-4d93-958e-68a97b1014c4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시퀀스 : [ 4924 19374 27793 ...  4062 12237 19344]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "iOnzQ6YNdgvi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1OnwqYidh_X",
        "outputId": "e03f7deb-8b26-41e7-8058-9ac51db712ff"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5, 25, 13, 70,  3,  1,  0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPuqL5TbdlPf",
        "outputId": "ba9c11be-42b4-4b79-f7eb-a0b8afdbb118"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,   7,  20,  97,  11,  54, 128,   1,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lkQS85Sdnhf",
        "outputId": "df288ba0-3d6b-4411-f41b-fc749b90b496"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  7,  20,  97,  11,  54, 128,   1,   3,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(33000*0.1)\n",
        "print('검증 데이터의 개수 :',n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtkc1yaxdo3X",
        "outputId": "534b20b8-6c8f-475d-b79c-55306f86845f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 데이터의 개수 : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "kBrj56Rqdqof"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yB2zLj2dsI6",
        "outputId": "b8605a93-2ea3-46ea-d3af-3b2542f2806b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (29700, 7)\n",
            "훈련 target 데이터의 크기 : (29700, 16)\n",
            "훈련 target 레이블의 크기 : (29700, 16)\n",
            "테스트 source 데이터의 크기 : (3300, 7)\n",
            "테스트 target 데이터의 크기 : (3300, 16)\n",
            "테스트 target 레이블의 크기 : (3300, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "2pEsxjX5dtgO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_units = 64"
      ],
      "metadata": {
        "id": "soopdxJZdvsh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "metadata": {
        "id": "vLOodj3ddxeq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 모델의 입력과 출력을 정의.\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "ctGrTOJBdywt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVM6yysqd0pw",
        "outputId": "bbbf0f79-dcc8-4949-8f03-d2ff7a74f260"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 36s 111ms/step - loss: 3.4171 - acc: 0.6154 - val_loss: 2.0300 - val_acc: 0.6219\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 1.8653 - acc: 0.6666 - val_loss: 1.7425 - val_acc: 0.7397\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 1.6554 - acc: 0.7451 - val_loss: 1.5809 - val_acc: 0.7526\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 9s 38ms/step - loss: 1.5158 - acc: 0.7587 - val_loss: 1.4744 - val_acc: 0.7619\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 9s 39ms/step - loss: 1.4230 - acc: 0.7656 - val_loss: 1.4009 - val_acc: 0.7716\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 1.3474 - acc: 0.7776 - val_loss: 1.3383 - val_acc: 0.7832\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 1.2807 - acc: 0.7887 - val_loss: 1.2802 - val_acc: 0.7953\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 1.2197 - acc: 0.8005 - val_loss: 1.2307 - val_acc: 0.8033\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 1.1651 - acc: 0.8085 - val_loss: 1.1872 - val_acc: 0.8092\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 1.1155 - acc: 0.8144 - val_loss: 1.1492 - val_acc: 0.8157\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 1.0704 - acc: 0.8205 - val_loss: 1.1146 - val_acc: 0.8199\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 1.0286 - acc: 0.8254 - val_loss: 1.0820 - val_acc: 0.8232\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.9871 - acc: 0.8305 - val_loss: 1.0511 - val_acc: 0.8281\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.9481 - acc: 0.8352 - val_loss: 1.0218 - val_acc: 0.8317\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.9123 - acc: 0.8397 - val_loss: 0.9999 - val_acc: 0.8341\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.8791 - acc: 0.8433 - val_loss: 0.9750 - val_acc: 0.8367\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.8464 - acc: 0.8465 - val_loss: 0.9544 - val_acc: 0.8394\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.8165 - acc: 0.8498 - val_loss: 0.9346 - val_acc: 0.8414\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.7882 - acc: 0.8529 - val_loss: 0.9189 - val_acc: 0.8431\n",
            "Epoch 20/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.7619 - acc: 0.8557 - val_loss: 0.9021 - val_acc: 0.8452\n",
            "Epoch 21/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.7368 - acc: 0.8584 - val_loss: 0.8887 - val_acc: 0.8475\n",
            "Epoch 22/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.7140 - acc: 0.8611 - val_loss: 0.8785 - val_acc: 0.8475\n",
            "Epoch 23/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.6925 - acc: 0.8631 - val_loss: 0.8646 - val_acc: 0.8501\n",
            "Epoch 24/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.6711 - acc: 0.8658 - val_loss: 0.8561 - val_acc: 0.8507\n",
            "Epoch 25/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.6515 - acc: 0.8681 - val_loss: 0.8457 - val_acc: 0.8515\n",
            "Epoch 26/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.6316 - acc: 0.8708 - val_loss: 0.8376 - val_acc: 0.8524\n",
            "Epoch 27/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.6137 - acc: 0.8729 - val_loss: 0.8270 - val_acc: 0.8539\n",
            "Epoch 28/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.5953 - acc: 0.8751 - val_loss: 0.8193 - val_acc: 0.8557\n",
            "Epoch 29/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.5790 - acc: 0.8772 - val_loss: 0.8122 - val_acc: 0.8565\n",
            "Epoch 30/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.5618 - acc: 0.8795 - val_loss: 0.8070 - val_acc: 0.8563\n",
            "Epoch 31/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.5461 - acc: 0.8816 - val_loss: 0.7985 - val_acc: 0.8570\n",
            "Epoch 32/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.5303 - acc: 0.8840 - val_loss: 0.7943 - val_acc: 0.8583\n",
            "Epoch 33/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.5160 - acc: 0.8861 - val_loss: 0.7884 - val_acc: 0.8590\n",
            "Epoch 34/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.5025 - acc: 0.8884 - val_loss: 0.7843 - val_acc: 0.8602\n",
            "Epoch 35/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.4887 - acc: 0.8904 - val_loss: 0.7785 - val_acc: 0.8608\n",
            "Epoch 36/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4752 - acc: 0.8926 - val_loss: 0.7791 - val_acc: 0.8611\n",
            "Epoch 37/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.4658 - acc: 0.8939 - val_loss: 0.7698 - val_acc: 0.8637\n",
            "Epoch 38/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.4504 - acc: 0.8970 - val_loss: 0.7681 - val_acc: 0.8629\n",
            "Epoch 39/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4392 - acc: 0.8988 - val_loss: 0.7654 - val_acc: 0.8646\n",
            "Epoch 40/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.4275 - acc: 0.9010 - val_loss: 0.7633 - val_acc: 0.8646\n",
            "Epoch 41/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.4184 - acc: 0.9024 - val_loss: 0.7593 - val_acc: 0.8658\n",
            "Epoch 42/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4056 - acc: 0.9050 - val_loss: 0.7565 - val_acc: 0.8656\n",
            "Epoch 43/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.3966 - acc: 0.9065 - val_loss: 0.7553 - val_acc: 0.8657\n",
            "Epoch 44/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.3862 - acc: 0.9084 - val_loss: 0.7535 - val_acc: 0.8667\n",
            "Epoch 45/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3769 - acc: 0.9103 - val_loss: 0.7524 - val_acc: 0.8667\n",
            "Epoch 46/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.3686 - acc: 0.9117 - val_loss: 0.7500 - val_acc: 0.8678\n",
            "Epoch 47/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3591 - acc: 0.9136 - val_loss: 0.7492 - val_acc: 0.8682\n",
            "Epoch 48/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.3508 - acc: 0.9149 - val_loss: 0.7514 - val_acc: 0.8681\n",
            "Epoch 49/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.3428 - acc: 0.9167 - val_loss: 0.7476 - val_acc: 0.8691\n",
            "Epoch 50/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.3351 - acc: 0.9181 - val_loss: 0.7447 - val_acc: 0.8693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fc7481bf430>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# 디코더 설계 시작\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# 수정된 디코더\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n"
      ],
      "metadata": {
        "id": "12ra31bed2kF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 정수 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 단어로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "    if (sampled_char == '<eos>' or\n",
        "        len(decoded_sentence) > 50):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence\n"
      ],
      "metadata": {
        "id": "MwrfcHTvgNHh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_src(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0):\n",
        "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "  return sentence\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
        "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "  return sentence\n"
      ],
      "metadata": {
        "id": "U7TRLuCQgOrb"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F4QuTyPgQ_A",
        "outputId": "c67ca4d4-113f-4e9f-a9db-c95a6f6b1ec3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 400ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "입력문장 : he is english . \n",
            "정답문장 : il est anglais . \n",
            "번역문장 : il est anglais . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "입력문장 : i hurried . \n",
            "정답문장 : je me suis precipite . \n",
            "번역문장 : je me suis precipite . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "입력문장 : i ve heard enough . \n",
            "정답문장 : j en ai assez entendu . \n",
            "번역문장 : j ai besoin d un peu d essence . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "입력문장 : i ordered pizza . \n",
            "정답문장 : j ai commande de la pizza . \n",
            "번역문장 : j ai commande de la pizza . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "입력문장 : you re not fat . \n",
            "정답문장 : vous n etes pas grosse . \n",
            "번역문장 : vous n etes pas grosse . \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTnz0HfbgSaw",
        "outputId": "c3359052-50a2-4a50-9e33-d0f5b246b7e4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "입력문장 : tom left . \n",
            "정답문장 : tom est parti . \n",
            "번역문장 : tom a demande . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "입력문장 : go ahead . \n",
            "정답문장 : vas y . \n",
            "번역문장 : avance ! \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "입력문장 : you re ridiculous . \n",
            "정답문장 : vous etes ridicule . \n",
            "번역문장 : tu es ridicule . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "입력문장 : i feel ready . \n",
            "정답문장 : je me sens prete . \n",
            "번역문장 : je me sens pret . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "입력문장 : i like to run . \n",
            "정답문장 : j aime courir . \n",
            "번역문장 : j aime voyager . \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n"
      ],
      "metadata": {
        "id": "M_DfVw3kgWp3"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화 된 문장(tokens)에서 n-gram을 카운트\n",
        "def simple_count(tokens, n):\n",
        "  return Counter(ngrams(tokens, n))\n"
      ],
      "metadata": {
        "id": "4eYVpUJegcuN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate = \"It is a guide to action which ensures that the military always obeys the commands of the party.\"\n",
        "tokens = candidate.split() # 토큰화\n",
        "result = simple_count(tokens, 1) # n = 1은 유니그램\n",
        "print('유니그램 카운트 :',result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9PznnPRget2",
        "outputId": "bdbed3d3-0623-4e2b-b611-1cc8581b432e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유니그램 카운트 : Counter({('the',): 3, ('It',): 1, ('is',): 1, ('a',): 1, ('guide',): 1, ('to',): 1, ('action',): 1, ('which',): 1, ('ensures',): 1, ('that',): 1, ('military',): 1, ('always',): 1, ('obeys',): 1, ('commands',): 1, ('of',): 1, ('party.',): 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidate = 'the the the the the the the'\n",
        "tokens = candidate.split() # 토큰화\n",
        "result = simple_count(tokens, 1) # n = 1은 유니그램\n",
        "print('유니그램 카운트 :',result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4f6Pp3lggAQ",
        "outputId": "120a58a7-40e3-484c-8bf0-87852ab4622d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유니그램 카운트 : Counter({('the',): 7})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_clip(candidate, reference_list, n):\n",
        "  # Ca 문장에서 n-gram 카운트\n",
        "  ca_cnt = simple_count(candidate, n)\n",
        "  max_ref_cnt_dict = dict()\n",
        "\n",
        "  for ref in reference_list:\n",
        "    # Ref 문장에서 n-gram 카운트\n",
        "    ref_cnt = simple_count(ref, n)\n",
        "\n",
        "    # 각 Ref 문장에 대해서 비교하여 n-gram의 최대 등장 횟수를 계산.\n",
        "    for n_gram in ref_cnt:\n",
        "      if n_gram in max_ref_cnt_dict:\n",
        "        max_ref_cnt_dict[n_gram] = max(ref_cnt[n_gram], max_ref_cnt_dict[n_gram])\n",
        "      else:\n",
        "        max_ref_cnt_dict[n_gram] = ref_cnt[n_gram]\n",
        "\n",
        "  return {\n",
        "        # count_clip = min(count, max_ref_count)\n",
        "        n_gram: min(ca_cnt.get(n_gram, 0), max_ref_cnt_dict.get(n_gram, 0)) for n_gram in ca_cnt\n",
        "     }\n"
      ],
      "metadata": {
        "id": "fMV_WYt8ghT2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate = 'the the the the the the the'\n",
        "references = [\n",
        "    'the cat is on the mat',\n",
        "    'there is a cat on the mat'\n",
        "]\n",
        "result = count_clip(candidate.split(),list(map(lambda ref: ref.split(), references)),1)\n",
        "print('보정된 유니그램 카운트 :',result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFF3PMnhgiZU",
        "outputId": "ac7be8d5-bfc4-4f60-8731-e39d919360c4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "보정된 유니그램 카운트 : {('the',): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_precision(candidate, reference_list, n):\n",
        "  clip_cnt = count_clip(candidate, reference_list, n)\n",
        "  total_clip_cnt = sum(clip_cnt.values()) # 분자\n",
        "\n",
        "  cnt = simple_count(candidate, n)\n",
        "  total_cnt = sum(cnt.values()) # 분모\n",
        "\n",
        "  # 분모가 0이 되는 것을 방지\n",
        "  if total_cnt == 0:\n",
        "    total_cnt = 1\n",
        "\n",
        "  # 분자 : count_clip의 합, 분모 : 단순 count의 합 ==> 보정된 정밀도\n",
        "  return (total_clip_cnt / total_cnt)\n"
      ],
      "metadata": {
        "id": "XzVA1jatgj4q"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = modified_precision(candidate.split(), list(map(lambda ref: ref.split(), references)), n=1)\n",
        "print('보정된 유니그램 정밀도 :',result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SlyazM1glDB",
        "outputId": "e1abbef2-4453-4ee1-bf93-047498b0355e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "보정된 유니그램 정밀도 : 0.2857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수\n",
        "def closest_ref_length(candidate, reference_list):\n",
        "  ca_len = len(candidate) # ca 길이\n",
        "  ref_lens = (len(ref) for ref in reference_list) # Ref들의 길이\n",
        "  # 길이 차이를 최소화하는 Ref를 찾아서 Ref의 길이를 리턴\n",
        "  closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))\n",
        "  return closest_ref_len"
      ],
      "metadata": {
        "id": "R0NId_t2gmno"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def brevity_penalty(candidate, reference_list):\n",
        "  ca_len = len(candidate)\n",
        "  ref_len = closest_ref_length(candidate, reference_list)\n",
        "\n",
        "  if ca_len > ref_len:\n",
        "    return 1\n",
        "\n",
        "  # candidate가 비어있다면 BP = 0 → BLEU = 0.0\n",
        "  elif ca_len == 0 :\n",
        "    return 0\n",
        "  else:\n",
        "    return np.exp(1 - ref_len/ca_len)\n"
      ],
      "metadata": {
        "id": "maF0F1ZPgpt4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu_score(candidate, reference_list, weights=[0.25, 0.25, 0.25, 0.25]):\n",
        "  bp = brevity_penalty(candidate, reference_list) # 브레버티 패널티, BP\n",
        "\n",
        "  p_n = [modified_precision(candidate, reference_list, n=n) for n, _ in enumerate(weights,start=1)]\n",
        "  # p1, p2, p3, ..., pn\n",
        "  score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n",
        "  return bp * np.exp(score)\n"
      ],
      "metadata": {
        "id": "v6pd_P5QgsL0"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
        "references = [\n",
        "    'It is a guide to action that ensures that the military will forever heed Party commands',\n",
        "    'It is the guiding principle which guarantees the military forces always being under the command of the Party',\n",
        "    'It is the practical guide for the army always to heed the directions of the party'\n",
        "]\n",
        "\n",
        "print('실습 코드의 BLEU :',bleu_score(candidate.split(),list(map(lambda ref: ref.split(), references))))\n",
        "print('패키지 NLTK의 BLEU :',bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqk5EugKg1SD",
        "outputId": "d48d6918-32d6-4338-ad19-c38e95a22cec"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실습 코드의 BLEU : 0.5045666840058485\n",
            "패키지 NLTK의 BLEU : 0.5045666840058485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjTO621Tg3UJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}