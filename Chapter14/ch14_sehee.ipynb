{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib3\n",
        "import unicodedata\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, GRU, Masking\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from nltk import ngrams"
      ],
      "metadata": {
        "id": "cXWrE4825fNx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문자(Char) level Machine Translator\n",
        "seq2seq는 기계 번역에 많이 사용한다"
      ],
      "metadata": {
        "id": "MKsJAE8I5Q_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_VYIIC25H9c",
        "outputId": "89488527-13a0-405b-9128-e92b24fef5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP file downloaded to fra-eng.zip\n"
          ]
        }
      ],
      "source": [
        "# data 다운 받기\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def download_zip(url, output_path):\n",
        "    response = requests.get(url, headers=headers, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(output_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"ZIP file downloaded to {output_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n",
        "\n",
        "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
        "output_path = \"fra-eng.zip\"\n",
        "download_zip(url, output_path)\n",
        "\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, output_path)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 읽어와 dataframe 생성하기\n",
        "# 예제와 데이터 개수가 다름\n",
        "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']\n",
        "print('전체 샘플의 개수 :',len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XP0E73q7bW4",
        "outputId": "594d7e3d-cdd8-41e2-b49f-7dda9386f663"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 개수 : 227815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000] # 6만개만 저장\n",
        "lines.sample(10) # 10개 random 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "QlFLhTQG7gW2",
        "outputId": "bd4c0646-f33b-4014-d540-df809efec997"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         src                               tar\n",
              "20036      He winked at her.      Il lui a fait un clin d'œil.\n",
              "30498     We're all retired.  Nous sommes toutes à la pension.\n",
              "17416       They feared you.             Elles te craignaient.\n",
              "15434       I have to think.             Il me faut réfléchir.\n",
              "39501   Everybody hates you.       Tout le monde vous déteste.\n",
              "39740   He did the opposite.              Il fit le contraire.\n",
              "2696             We made it.                Nous avons réussi.\n",
              "21637      I've never tried.            Je n'ai jamais essayé.\n",
              "39399   Don't fret about it.       Ne te tracasse pas pour ça.\n",
              "49307  I won't ever give up.         Je n'abandonnerai jamais."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-209d5c7a-5af0-47b9-bba0-e35400a8098d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20036</th>\n",
              "      <td>He winked at her.</td>\n",
              "      <td>Il lui a fait un clin d'œil.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30498</th>\n",
              "      <td>We're all retired.</td>\n",
              "      <td>Nous sommes toutes à la pension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17416</th>\n",
              "      <td>They feared you.</td>\n",
              "      <td>Elles te craignaient.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15434</th>\n",
              "      <td>I have to think.</td>\n",
              "      <td>Il me faut réfléchir.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39501</th>\n",
              "      <td>Everybody hates you.</td>\n",
              "      <td>Tout le monde vous déteste.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39740</th>\n",
              "      <td>He did the opposite.</td>\n",
              "      <td>Il fit le contraire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2696</th>\n",
              "      <td>We made it.</td>\n",
              "      <td>Nous avons réussi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21637</th>\n",
              "      <td>I've never tried.</td>\n",
              "      <td>Je n'ai jamais essayé.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39399</th>\n",
              "      <td>Don't fret about it.</td>\n",
              "      <td>Ne te tracasse pas pour ça.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49307</th>\n",
              "      <td>I won't ever give up.</td>\n",
              "      <td>Je n'abandonnerai jamais.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-209d5c7a-5af0-47b9-bba0-e35400a8098d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-209d5c7a-5af0-47b9-bba0-e35400a8098d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-209d5c7a-5af0-47b9-bba0-e35400a8098d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3e52798-3c86-4040-99fb-6c7c0dd35aec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3e52798-3c86-4040-99fb-6c7c0dd35aec')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3e52798-3c86-4040-99fb-6c7c0dd35aec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 <sos> token과 종료 <eos> token 삽입 필요\n",
        "# \\t = start / \\n = end 로 간주\n",
        "\n",
        "# 모든 data 앞 뒤에 시퀀스 삽입\n",
        "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "UfV8KTFU7sUd",
        "outputId": "9909ca8b-a298-4887-c59f-b8d885174505"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          src                                        tar\n",
              "48823   I prefer it this way.      \\t Je le préfère de cette manière. \\n\n",
              "41645    I'm absolutely fine.           \\t Je vais parfaitement bien. \\n\n",
              "8738           It's very big.                    \\t C'est très grand. \\n\n",
              "58913  My cat will love this.                 \\t Mon chat adorera ça. \\n\n",
              "57311  I think you're a liar.       \\t Je pense que tu es un menteur. \\n\n",
              "52341   Tom is philosophical.                  \\t Tom est philosophe. \\n\n",
              "37917     Where's your drink?                   \\t Où est ton verre ? \\n\n",
              "52602   Tom was hit by a car.  \\t Tom a été renversé par une voiture. \\n\n",
              "10869         Have you eaten?                    \\t Avez-vous mangé ? \\n\n",
              "48075   I didn't expect help.           \\t Je n'attendais pas d'aide. \\n"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-195d92ad-13d5-43f2-a16a-07c84c9bc9a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48823</th>\n",
              "      <td>I prefer it this way.</td>\n",
              "      <td>\\t Je le préfère de cette manière. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41645</th>\n",
              "      <td>I'm absolutely fine.</td>\n",
              "      <td>\\t Je vais parfaitement bien. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8738</th>\n",
              "      <td>It's very big.</td>\n",
              "      <td>\\t C'est très grand. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58913</th>\n",
              "      <td>My cat will love this.</td>\n",
              "      <td>\\t Mon chat adorera ça. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57311</th>\n",
              "      <td>I think you're a liar.</td>\n",
              "      <td>\\t Je pense que tu es un menteur. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52341</th>\n",
              "      <td>Tom is philosophical.</td>\n",
              "      <td>\\t Tom est philosophe. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37917</th>\n",
              "      <td>Where's your drink?</td>\n",
              "      <td>\\t Où est ton verre ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52602</th>\n",
              "      <td>Tom was hit by a car.</td>\n",
              "      <td>\\t Tom a été renversé par une voiture. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10869</th>\n",
              "      <td>Have you eaten?</td>\n",
              "      <td>\\t Avez-vous mangé ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48075</th>\n",
              "      <td>I didn't expect help.</td>\n",
              "      <td>\\t Je n'attendais pas d'aide. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-195d92ad-13d5-43f2-a16a-07c84c9bc9a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-195d92ad-13d5-43f2-a16a-07c84c9bc9a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-195d92ad-13d5-43f2-a16a-07c84c9bc9a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7893722-81e4-4c9f-9158-ae8742be9688\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7893722-81e4-4c9f-9158-ae8742be9688')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7893722-81e4-4c9f-9158-ae8742be9688 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자 집합 구축\n",
        "# src에서 수행\n",
        "src_vocab = set() # 빈 집합 생성\n",
        "for line in lines.src: # 1줄씩 읽음\n",
        "    for char in line: # 1개의 문자씩 읽음\n",
        "        src_vocab.add(char) # 집합에 문자 추가하기\n",
        "\n",
        "# tar에서 수행\n",
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)"
      ],
      "metadata": {
        "id": "GDBuEbmQ7_en"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print('source 문장의 char 집합(영어) :',src_vocab_size)\n",
        "print('target 문장의 char 집합(프랑스어) :',tar_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-w66bxQ8N3q",
        "outputId": "d27aedae-c1f2-4d5d-a55e-24b4257a3dd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 char 집합 : 80\n",
            "target 문장의 char 집합 : 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정렬하여 순서를 정해주고 index 사용하여 출력하기\n",
        "# 막 호출하려고 하면 오류 출력\n",
        "# 1차적으로 정렬하기\n",
        "\n",
        "# 영어\n",
        "src_vocab = sorted(list(src_vocab)) # 정렬!\n",
        "\n",
        "# 프랑스어\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6S6NhQ98UT3",
        "outputId": "3c6c20ce-f006-4dc7-8913-7a01f30294a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dict 생성하고 index 부여하기\n",
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsqxlpAT8cID",
        "outputId": "f6e50924-6d4d-40bd-e742-4767bddf5fa8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, 'ï': 77, '’': 78, '€': 79}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102, '‽': 103}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 정수 인코딩 수행하기\n",
        "encoder_input = []\n",
        "\n",
        "# 목적: 영어(src) columns를 돌아가며 1개의 문장 씩 정수 인코딩을 수행하여 리스트에 넣는다.\n",
        "for line in lines.src:\n",
        "  encoded_line = []\n",
        "  # 각 줄에서 1개의 char 본다\n",
        "  for char in line:\n",
        "    # 각 char을 정수로 변환하여 리스트를 넣는다\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  encoder_input.append(encoded_line)\n",
        "print('source 문장의 정수 인코딩 :',encoder_input[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwvgpx0s8pBQ",
        "outputId": "692272ef-6b2c-4069-e1b1-461094370de8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프랑스어 정수 인코딩 수행하기 - 영어와 동일, 데이터만 다름\n",
        "decoder_input = []\n",
        "\n",
        "for line in lines.tar:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(tar_to_index[char])\n",
        "  decoder_input.append(encoded_line)\n",
        "print('target 문장의 정수 인코딩 :',decoder_input[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbjHp6Fj8_1o",
        "outputId": "926e0f73-5456-4785-b449-5915af1753c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장의 정수 인코딩 : [[1, 3, 48, 52, 3, 4, 3, 2], [1, 3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [1, 3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [1, 3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 과정까지 훈련 데이터 준비 완료\\\n",
        "아래부터는 학습에서 실제로 필요한 label 데이터 구축\\\n",
        "왜 필요한가?\\\n",
        "<교사 강요>\\\n",
        "예측값을 계속 넣고 학습시킨다면 잘못된 길로 빠질 수 있음\\\n",
        "따라서 정확한 값인 label을 넣고 학습시킨다"
      ],
      "metadata": {
        "id": "gZe63goY9k7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# label을 구축하기\n",
        "# 실제값에는 <sos> 토큰 제거\n",
        "# 시작할 때 <sos>를 입력으로 받되 출력은 단어이어야 함\n",
        "\n",
        "decoder_target = []\n",
        "\n",
        "# 프랑스어 list 돌기\n",
        "for line in lines.tar:\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "\n",
        "  # 라인에 있는 문자마다 본다\n",
        "  for char in line:\n",
        "\n",
        "    # 시점이 0 이상이라면\n",
        "    if timestep > 0:\n",
        "\n",
        "      # 정수 인코딩을 수행한 결과를 encoded_list에 넣는다\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "\n",
        "    # 시점을 1 증가시킴\n",
        "    timestep = timestep + 1\n",
        "  decoder_target.append(encoded_line)\n",
        "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGy9hbQN9bZE",
        "outputId": "fe63f854-ad8c-4d7f-f991-e87c4d787e01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장 레이블의 정수 인코딩 : [[3, 48, 52, 3, 4, 3, 2], [3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding을 위한 문장 길이 확인\n",
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print('source 문장의 최대 길이 :',max_src_len)\n",
        "print('target 문장의 최대 길이 :',max_tar_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFkkiJW0-Mkd",
        "outputId": "3699f6fe-8e48-4d2b-f7d9-6f2fc0236198"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이 : 22\n",
            "target 문장의 최대 길이 : 76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "metadata": {
        "id": "FOZOeIa_-bmG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one - hot encoding\n",
        "# 문자 단위 번역기이기 때문에 워드 임베딩은 별도로 사용되지 않음\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "metadata": {
        "id": "Thc0a-F8-imD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델"
      ],
      "metadata": {
        "id": "eR47DrO7-sVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어를 입력 받아야하니까 영어 사전 크기로\n",
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True) # 은닉층 노드 수 = 256, 마지막 hs만 반환\n",
        "\n",
        "# encoder_outputs은 여기서는 불필요\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# LSTM은 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태. = context vector\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "QFPP09Ut-q2R"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프랑스어로 출력해야하니까 프랑스어 사전 크기로\n",
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True) # 은닉층 노드 수 = 256\n",
        "\n",
        "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달, input data를 넘겨줌.(initial_state=encoder_states)\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "# 분류해야할 것은 단어사전 만큼의 크기, 따라서 단어 사전 크기로 class개수 지정\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "\n",
        "# softmax 통과\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "# input = encoder에서 입력하는 값(영어 사전 크기의 벡터)(인코더의 입력)\n",
        "          #decoder에서 입력하는 값(프랑스어 사전 크기의 벡터)(디코더의 입력)\n",
        "# output = 디코더의 최종 출력 - softmax를 통과하여 영어 - 프랑스어 변환이 된 결과\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# optimizer: RMSProp , loss function: Cross entropy\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "metadata": {
        "id": "ZZadj6XM_I6t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtCEcftq_c1j",
        "outputId": "163e348a-0c9f-4a7c-992a-5f8c4cca590c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 [==============================] - 22s 17ms/step - loss: 0.8540 - val_loss: 0.7754\n",
            "Epoch 2/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.5740 - val_loss: 0.6601\n",
            "Epoch 3/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.5034 - val_loss: 0.5973\n",
            "Epoch 4/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.4563 - val_loss: 0.5545\n",
            "Epoch 5/40\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.4230 - val_loss: 0.5196\n",
            "Epoch 6/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3964 - val_loss: 0.4949\n",
            "Epoch 7/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3748 - val_loss: 0.4712\n",
            "Epoch 8/40\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.3576 - val_loss: 0.4522\n",
            "Epoch 9/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3434 - val_loss: 0.4412\n",
            "Epoch 10/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.3315 - val_loss: 0.4265\n",
            "Epoch 11/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3210 - val_loss: 0.4175\n",
            "Epoch 12/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.3117 - val_loss: 0.4084\n",
            "Epoch 13/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3035 - val_loss: 0.4002\n",
            "Epoch 14/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2961 - val_loss: 0.3931\n",
            "Epoch 15/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2893 - val_loss: 0.3879\n",
            "Epoch 16/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2832 - val_loss: 0.3837\n",
            "Epoch 17/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2774 - val_loss: 0.3778\n",
            "Epoch 18/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2722 - val_loss: 0.3744\n",
            "Epoch 19/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2673 - val_loss: 0.3706\n",
            "Epoch 20/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2627 - val_loss: 0.3673\n",
            "Epoch 21/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2583 - val_loss: 0.3635\n",
            "Epoch 22/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2543 - val_loss: 0.3622\n",
            "Epoch 23/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2506 - val_loss: 0.3582\n",
            "Epoch 24/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2469 - val_loss: 0.3559\n",
            "Epoch 25/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2435 - val_loss: 0.3550\n",
            "Epoch 26/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2403 - val_loss: 0.3537\n",
            "Epoch 27/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2372 - val_loss: 0.3508\n",
            "Epoch 28/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2342 - val_loss: 0.3502\n",
            "Epoch 29/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2315 - val_loss: 0.3482\n",
            "Epoch 30/40\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2288 - val_loss: 0.3475\n",
            "Epoch 31/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2260 - val_loss: 0.3464\n",
            "Epoch 32/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2236 - val_loss: 0.3469\n",
            "Epoch 33/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2212 - val_loss: 0.3460\n",
            "Epoch 34/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2190 - val_loss: 0.3454\n",
            "Epoch 35/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2166 - val_loss: 0.3438\n",
            "Epoch 36/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2143 - val_loss: 0.3430\n",
            "Epoch 37/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2121 - val_loss: 0.3437\n",
            "Epoch 38/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2100 - val_loss: 0.3421\n",
            "Epoch 39/40\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2079 - val_loss: 0.3412\n",
            "Epoch 40/40\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2059 - val_loss: 0.3433\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f94b08c0a60>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델을 동작시켜보자! - 입력한 문장에 대해 번역하게 하기"
      ],
      "metadata": {
        "id": "qmg5lxXlBPyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 정의\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "\n",
        "# 디코더 정의\n",
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,)) # hs 기억하기\n",
        "decoder_state_input_c = Input(shape=(256,)) # 셀 상태 기억하기\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] # decoder의 input 정제\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
        "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
        "decoder_states = [state_h, state_c] # 리스트로 저장\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs) # softxmax 통과\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "OG6zU-cVA57Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인덱스를 통해 단어를 얻을 수 있는 영어, 프랑스어 사전\n",
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "metadata": {
        "id": "1CMpLyaYBfPR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  # 입력에 대해 encoder가 예측한다.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # 디코더 초기 입력 설정\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성 - 최초 시점\n",
        "  # 프랑스어 사전 크기의 0벡터 생성 - 디코더에 입력할 시퀀스\n",
        "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "  # /t가 나타나는 위치에 1을 할당 - 문장에 끝에 1을 할당\n",
        "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    # 예측 token과 해당 시점의 hs, 셀 상태 또한 반환 받음\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    # 문장 속에서 문자의 확률을 예측한 값 중에 가장 값이 높은 인덱스를 선택한다.\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    # 인덱스를 문자로 변환한다\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_tar_len):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    # 0벡터로 초기화\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    # 원핫 벡터이기 때문에 이전에 등장한 인덱스에 1을 지정해주면 됨\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "-h8eSi4wCRp1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index:seq_index+1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장:', lines.src[seq_index])\n",
        "  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG0O7NpqC9Mm",
        "outputId": "945849db-6627-41c4-eae1-269b82f85413"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 367ms/step\n",
            "1/1 [==============================] - 0s 359ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go.\n",
            "정답 문장: Bouge ! \n",
            "번역 문장: Au retournée ! \n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Hello!\n",
            "정답 문장: Bonjour ! \n",
            "번역 문장: Salut ! \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Got it!\n",
            "정답 문장: J'ai pigé ! \n",
            "번역 문장: Attendez ! \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go home.\n",
            "정답 문장: Rentre à la maison. \n",
            "번역 문장: Vas ! \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Get going.\n",
            "정답 문장: En avant. \n",
            "번역 문장: Déplacez-vous. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word-Level 번역기"
      ],
      "metadata": {
        "id": "1vcWzvCFDt4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data import는 이전과 동일한 과정을 거침\n",
        "# 따라서 수행하지는 않으나 혹시 몰라서 적어놓음\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def download_zip(url, output_path):\n",
        "    response = requests.get(url, headers=headers, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(output_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"ZIP file downloaded to {output_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n",
        "\n",
        "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
        "output_path = \"fra-eng.zip\"\n",
        "download_zip(url, output_path)\n",
        "\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, output_path)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "metadata": {
        "id": "WrhzHTgWDhyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text preprocessing\n",
        "def to_ascii(s):\n",
        "  # 프랑스어 악센트(accent) 삭제\n",
        "  # 예시 : 'déjà diné' -> deja dine\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  # 악센트 제거 함수 호출\n",
        "  sent = to_ascii(sent.lower()) # 소문자 변환\n",
        "\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) \"I am a student.\" => \"I am a student .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # 다수 개의 공백을 하나의 공백으로 치환\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent"
      ],
      "metadata": {
        "id": "S6SrGgBREM-L"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 테스트\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print('전처리 전 영어 문장 :', en_sent)\n",
        "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
        "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
        "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxs9Do1bEQUk",
        "outputId": "6f87efba-df6c-4c35-803d-3cacb097f0f1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 영어 문장 : Have you had dinner?\n",
            "전처리 후 영어 문장 : have you had dinner ?\n",
            "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
            "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 33000개 샘플 사용\n",
        "num_samples = 33000\n",
        "\n",
        "# 사용할 33000개의 sample에 대한 전처리 수행\n",
        "def load_preprocessed_data():\n",
        "\n",
        "  # encoder의 입력, decoder의 입력, decoder의 lable(교사 강요)\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"fra.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      # source 데이터와 target 데이터 분리\n",
        "      src_line, tar_line, _ = line.strip().split('\\t') # tab을 기준으로 line split\n",
        "\n",
        "      # source 데이터 전처리\n",
        "      src_line = [w for w in preprocess_sentence(src_line).split()] # 전처리 후 공백 기준으로 word split\n",
        "\n",
        "      # target 데이터 전처리\n",
        "      tar_line = preprocess_sentence(tar_line) # 이전에 정의한 전처리 함수 호출\n",
        "\n",
        "      # <sos> 토큰 붙여주기 - 문장의 시작\n",
        "      # 굳이 입력할 때는 eos를 넣어줄 필요가 없음, 예측할 것이 eos이고 이것이 문장의 끝이기 때문에\n",
        "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      # <eos> 토큰 붙여주기 - 문장의 끝\n",
        "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      # 전처리한 데이터 저장하기\n",
        "      encoder_input.append(src_line)\n",
        "      decoder_input.append(tar_line_in)\n",
        "      decoder_target.append(tar_line_out)\n",
        "\n",
        "      # 문장 끝까지 다 돌면\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "\n",
        "  return encoder_input, decoder_input, decoder_target"
      ],
      "metadata": {
        "id": "pVqWs896ES0r"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 5개만 sample 출력해보기\n",
        "# dataset 지정 안해줘도 내부에서 txt 파일 호출하여 원하는 수(33000)만큼 전처리\n",
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
        "print('인코더의 입력 :',sents_en_in[:5])\n",
        "print('디코더의 입력 :',sents_fra_in[:5])\n",
        "print('디코더의 레이블 :',sents_fra_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsH2nmHeEGlf",
        "outputId": "a5a56686-b5ac-4b9a-8fe0-ff55ab01a10a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
            "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
            "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 현재 시점의 디코더 셀의 입력은 오직 이전 디코더 셀의 출력을 입력으로 받는다고 했는데 디코더의 입력에 해당하는 데이터인 sents_fra_in이 왜 필요할까?\\\n",
        "A. 훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고, 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용한다. (교사 강요)"
      ],
      "metadata": {
        "id": "feEz28ziGRGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 단어 집합 생성\n",
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "# 프랑스어 단어 집합 생성\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "# 각 문장을 정수 인덱싱 및 패딩 처리\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "metadata": {
        "id": "hWyBDu0wGBe2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
        "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
        "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNkY80N4HUFW",
        "outputId": "3153b2e8-9105-423d-8f33-a359044e0162"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력의 크기(shape) : (33000, 7)\n",
            "디코더의 입력의 크기(shape) : (33000, 16)\n",
            "디코더의 레이블의 크기(shape) : (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제랑 단어집합 크기가 다름\n",
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9cHVNiHWQP",
        "outputId": "d15e4ca2-7c93-4f83-cfa1-3d49b0c0f5c1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어 집합의 크기 : 4481, 프랑스어 단어 집합의 크기 : 7873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 -> 정수 리스트 / 정수 -> 단어 리스트  각각 생성\n",
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "metadata": {
        "id": "AQXnm9IjHaYk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 섞기\n",
        "\n",
        "# encoder_input과 동일한 크기의 인텍스 배열을 생성\n",
        "indices = np.arange(encoder_input.shape[0])\n",
        "\n",
        "# 인덱싱 된 배열을 무작위로 섞기\n",
        "np.random.shuffle(indices)\n",
        "print('랜덤 시퀀스 :',indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWI5oVqUHm2Q",
        "outputId": "269be6d1-613b-4555-f0d6-29cb597ac4da"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시퀀스 : [20600 15582   232 ...  2734  7091 27667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]\n",
        "\n",
        "print(encoder_input[30997])\n",
        "print(decoder_input[30997]) # <sos> 존재\n",
        "print(decoder_target[30997]) # <eos> 존재\n",
        "\n",
        "# decoder_input과 decoder_target은 앞에 붙은 <sos> 토큰과 뒤에 붙은 <eos>을 제외하면 동일한 정수 시퀀스를 가져야 함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRj2zYWLH603",
        "outputId": "90d73278-43b1-4eec-ef64-5fbeaeec688d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   5  335 3142    1    0    0    0]\n",
            "[   2    7    8  324    8 4643    1    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[   7    8  324    8 4643    1    3    0    0    0    0    0    0    0\n",
            "    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터: 10프로\n",
        "n_of_val = int(33000*0.1)\n",
        "print('검증 데이터의 개수 :',n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBiEQI_yIByK",
        "outputId": "74a1a024-92e8-4543-fbc3-6d61b4dbb8a9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 데이터의 개수 : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "zIOmEJHyIjCL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PDtHdRvImCZ",
        "outputId": "f68fab55-825c-48e6-bb7e-e5dcf93da11d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (29700, 7)\n",
            "훈련 target 데이터의 크기 : (29700, 16)\n",
            "훈련 target 레이블의 크기 : (29700, 16)\n",
            "테스트 source 데이터의 크기 : (3300, 7)\n",
            "테스트 target 데이터의 크기 : (3300, 16)\n",
            "테스트 target 레이블의 크기 : (3300, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64  # 임베딩 벡터 차원\n",
        "hidden_units = 64  # LSTM 은닉 상태 크기"
      ],
      "metadata": {
        "id": "pO-W5R9OInYL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # encoder 출력 값(필요하진 않음), 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "metadata": {
        "id": "18QSi4WWIyj8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층, 프랑스어 - 은닉층 크기\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb) # 패딩 0은 연산에서 제외\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용 -> context vector(연결되는 다리)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "# 디코더는 다중 클래스 분류 문제를 해결하는 중\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 모델의 입력과 출력을 정의.\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 손실함수: Cross entropy\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "aPtU05vLI7fx"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력으로 영어 사전, <sos>토큰이 있는 프랑스어 사전, <eos>토큰이 있는 프랑스어 사전을 각각 넘겨준다.(label)\n",
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gACGgS7QJcNG",
        "outputId": "a6fda93f-6f56-4fb4-eb93-2904f4cd2cc7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 34s 106ms/step - loss: 3.3680 - acc: 0.6144 - val_loss: 2.0467 - val_acc: 0.6188\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 9s 38ms/step - loss: 1.8559 - acc: 0.6642 - val_loss: 1.7622 - val_acc: 0.7381\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 8s 36ms/step - loss: 1.6488 - acc: 0.7449 - val_loss: 1.6064 - val_acc: 0.7473\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 1.5112 - acc: 0.7575 - val_loss: 1.4957 - val_acc: 0.7623\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 1.4078 - acc: 0.7697 - val_loss: 1.4056 - val_acc: 0.7749\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 9s 37ms/step - loss: 1.3128 - acc: 0.7892 - val_loss: 1.3287 - val_acc: 0.7891\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 1.2375 - acc: 0.8002 - val_loss: 1.2697 - val_acc: 0.7977\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 1.1758 - acc: 0.8080 - val_loss: 1.2205 - val_acc: 0.8042\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 1.1202 - acc: 0.8160 - val_loss: 1.1739 - val_acc: 0.8130\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 1.0669 - acc: 0.8237 - val_loss: 1.1317 - val_acc: 0.8187\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 1.0178 - acc: 0.8308 - val_loss: 1.0971 - val_acc: 0.8238\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.9758 - acc: 0.8356 - val_loss: 1.0665 - val_acc: 0.8283\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.9374 - acc: 0.8395 - val_loss: 1.0396 - val_acc: 0.8308\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.9013 - acc: 0.8431 - val_loss: 1.0151 - val_acc: 0.8332\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.8682 - acc: 0.8468 - val_loss: 0.9934 - val_acc: 0.8363\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.8368 - acc: 0.8502 - val_loss: 0.9727 - val_acc: 0.8382\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.8064 - acc: 0.8535 - val_loss: 0.9555 - val_acc: 0.8400\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.7782 - acc: 0.8564 - val_loss: 0.9387 - val_acc: 0.8413\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.7516 - acc: 0.8592 - val_loss: 0.9231 - val_acc: 0.8431\n",
            "Epoch 20/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.7262 - acc: 0.8622 - val_loss: 0.9067 - val_acc: 0.8456\n",
            "Epoch 21/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.7017 - acc: 0.8650 - val_loss: 0.8937 - val_acc: 0.8463\n",
            "Epoch 22/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.6776 - acc: 0.8676 - val_loss: 0.8793 - val_acc: 0.8484\n",
            "Epoch 23/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.6554 - acc: 0.8700 - val_loss: 0.8699 - val_acc: 0.8489\n",
            "Epoch 24/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.6332 - acc: 0.8727 - val_loss: 0.8585 - val_acc: 0.8506\n",
            "Epoch 25/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.6129 - acc: 0.8749 - val_loss: 0.8494 - val_acc: 0.8511\n",
            "Epoch 26/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.5933 - acc: 0.8772 - val_loss: 0.8372 - val_acc: 0.8533\n",
            "Epoch 27/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.5744 - acc: 0.8796 - val_loss: 0.8288 - val_acc: 0.8535\n",
            "Epoch 28/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.5564 - acc: 0.8822 - val_loss: 0.8213 - val_acc: 0.8547\n",
            "Epoch 29/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.5389 - acc: 0.8847 - val_loss: 0.8147 - val_acc: 0.8549\n",
            "Epoch 30/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.5223 - acc: 0.8869 - val_loss: 0.8071 - val_acc: 0.8560\n",
            "Epoch 31/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.5061 - acc: 0.8894 - val_loss: 0.8022 - val_acc: 0.8571\n",
            "Epoch 32/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4909 - acc: 0.8915 - val_loss: 0.7961 - val_acc: 0.8587\n",
            "Epoch 33/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.4771 - acc: 0.8934 - val_loss: 0.7927 - val_acc: 0.8577\n",
            "Epoch 34/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.4630 - acc: 0.8959 - val_loss: 0.7862 - val_acc: 0.8587\n",
            "Epoch 35/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4490 - acc: 0.8980 - val_loss: 0.7813 - val_acc: 0.8604\n",
            "Epoch 36/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.4354 - acc: 0.9007 - val_loss: 0.7768 - val_acc: 0.8608\n",
            "Epoch 37/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.4237 - acc: 0.9024 - val_loss: 0.7750 - val_acc: 0.8614\n",
            "Epoch 38/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.4121 - acc: 0.9042 - val_loss: 0.7713 - val_acc: 0.8617\n",
            "Epoch 39/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.4007 - acc: 0.9067 - val_loss: 0.7685 - val_acc: 0.8622\n",
            "Epoch 40/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.3892 - acc: 0.9086 - val_loss: 0.7638 - val_acc: 0.8631\n",
            "Epoch 41/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3793 - acc: 0.9103 - val_loss: 0.7640 - val_acc: 0.8632\n",
            "Epoch 42/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.3687 - acc: 0.9127 - val_loss: 0.7590 - val_acc: 0.8649\n",
            "Epoch 43/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.3594 - acc: 0.9142 - val_loss: 0.7585 - val_acc: 0.8652\n",
            "Epoch 44/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.3499 - acc: 0.9160 - val_loss: 0.7557 - val_acc: 0.8659\n",
            "Epoch 45/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.3411 - acc: 0.9178 - val_loss: 0.7547 - val_acc: 0.8662\n",
            "Epoch 46/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.3325 - acc: 0.9192 - val_loss: 0.7549 - val_acc: 0.8664\n",
            "Epoch 47/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.3245 - acc: 0.9209 - val_loss: 0.7517 - val_acc: 0.8677\n",
            "Epoch 48/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.3159 - acc: 0.9230 - val_loss: 0.7526 - val_acc: 0.8670\n",
            "Epoch 49/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3087 - acc: 0.9240 - val_loss: 0.7504 - val_acc: 0.8668\n",
            "Epoch 50/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.3018 - acc: 0.9257 - val_loss: 0.7511 - val_acc: 0.8672\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f94afedc2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 동작 시키기\n",
        "<전체적인 번역 과정>\n",
        "1. 번역하고자 하는 입력 문장이 인코더로 입력되어 인코더의 마지막 시점의 은닉 상태와 셀 상태를 얻는다.\n",
        "2. 인코더의 은닉 상태와 셀 상태, 그리고 토큰 <sos>를 디코더로 보낸다.\n",
        "3. 디코더가 토큰 <eos>가 나올 때까지 다음 단어를 예측하는 행동을 반복한다."
      ],
      "metadata": {
        "id": "8uCotjFFJ1S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# 디코더 설계 시작\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_units,)) # hs 저장\n",
        "decoder_state_input_c = Input(shape=(hidden_units,)) # 셀 상태 저장\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] # 두 가지 합쳐서 리스트로\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# 수정된 디코더\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "GNGc9cAkJxkv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 정수 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용 - decoder에게는 당연\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 단어로 변환\n",
        "    # 리스트에서 가장 확률이 높은 인덱스를 가져온다.\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "    # 가장 확률이 높은 인덱스를 문자로 변환한다.\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "    if (sampled_char == '<eos>' or\n",
        "        len(decoded_sentence) > 50):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 상태 초기화: 0벡터\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "tcwtYcrpKvoi"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_src(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0):\n",
        "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "  return sentence\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
        "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "7Gbf1UJzM1-g"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYaz98T5M363",
        "outputId": "c3d5f2de-0165-4e58-fdf8-293eea78a7dc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 363ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "입력문장 : do come again . \n",
            "정답문장 : revenez nous voir . \n",
            "번역문장 : viens encore y aller . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "입력문장 : you re very tall . \n",
            "정답문장 : vous etes tres grande . \n",
            "번역문장 : vous etes tres grande . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "입력문장 : what s that ? \n",
            "정답문장 : qu est ce la ? \n",
            "번역문장 : qu est ce que c est ? \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "입력문장 : i was impressed . \n",
            "정답문장 : j ai ete impressionnee . \n",
            "번역문장 : j ai ete impressionne . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "입력문장 : who developed it ? \n",
            "정답문장 : qui l a developpee ? \n",
            "번역문장 : qui l a batie ? \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T6maQt0M5Og",
        "outputId": "d059d928-0a4d-49a9-f78a-746e5ffcbee6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "입력문장 : let s watch tv . \n",
            "정답문장 : allons regarder la television . \n",
            "번역문장 : prenons le l air . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "입력문장 : i m a hard worker . \n",
            "정답문장 : je suis un bourreau de travail . \n",
            "번역문장 : je suis vraiment une chanson . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "입력문장 : it s all over now . \n",
            "정답문장 : maintenant tout est fini . \n",
            "번역문장 : c est tout que nous en aller a fait . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "입력문장 : tom waved . \n",
            "정답문장 : tom a fait signe de la main . \n",
            "번역문장 : tom a vu tom . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "입력문장 : wait and see . \n",
            "정답문장 : attendons en buvant du the . \n",
            "번역문장 : allez vous en train de travailler ! \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}