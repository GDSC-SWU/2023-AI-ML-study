{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdN_id52h_GC"
      },
      "source": [
        "## 문자 레벨 기계 번역기 구현하기\n",
        "\n",
        "-> 병렬 코퍼스 필요 : 두 개 이상의 언어가 병렬적으로 구성된 코퍼스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3i4RK7IOEOfN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib3\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-yHjkEzieLi",
        "outputId": "fea6e130-a3de-4bc5-f81d-d7ca9aba442a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 개수 : 26354\n"
          ]
        }
      ],
      "source": [
        "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']\n",
        "print('전체 샘플의 개수 :',len(lines))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HmL76_ewiute",
        "outputId": "164b01ee-4668-4d5d-c355-5b63a5d50569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      src                             tar\n",
              "11759     I'd like a hug.            J'aimerais un câlin.\n",
              "9684       Tom will work.                Tom travaillera.\n",
              "13983     You seem upset.        Vous semblez contrariée.\n",
              "11012     Hello everyone!                Salut les gens !\n",
              "25466  Do as you see fit.   Faites comme bon vous semble.\n",
              "20972   I pay my own way.          Je peux me gérer seul.\n",
              "5791        Is that snow?  Est-ce que c'est de la neige ?\n",
              "14837    Go to the store.                 Va au magasin !\n",
              "25195  Are you up for it?                  Y es-tu prêt ?\n",
              "17838    Tom is perverse.                Tom est pervers."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54920afa-644b-4b62-81fe-859b353870c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11759</th>\n",
              "      <td>I'd like a hug.</td>\n",
              "      <td>J'aimerais un câlin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9684</th>\n",
              "      <td>Tom will work.</td>\n",
              "      <td>Tom travaillera.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13983</th>\n",
              "      <td>You seem upset.</td>\n",
              "      <td>Vous semblez contrariée.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11012</th>\n",
              "      <td>Hello everyone!</td>\n",
              "      <td>Salut les gens !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25466</th>\n",
              "      <td>Do as you see fit.</td>\n",
              "      <td>Faites comme bon vous semble.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20972</th>\n",
              "      <td>I pay my own way.</td>\n",
              "      <td>Je peux me gérer seul.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5791</th>\n",
              "      <td>Is that snow?</td>\n",
              "      <td>Est-ce que c'est de la neige ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14837</th>\n",
              "      <td>Go to the store.</td>\n",
              "      <td>Va au magasin !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25195</th>\n",
              "      <td>Are you up for it?</td>\n",
              "      <td>Y es-tu prêt ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17838</th>\n",
              "      <td>Tom is perverse.</td>\n",
              "      <td>Tom est pervers.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54920afa-644b-4b62-81fe-859b353870c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54920afa-644b-4b62-81fe-859b353870c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54920afa-644b-4b62-81fe-859b353870c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3755e4b1-1c70-4880-8eaf-f7f5453b8a87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3755e4b1-1c70-4880-8eaf-f7f5453b8a87')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3755e4b1-1c70-4880-8eaf-f7f5453b8a87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000] # 6만개만 저장\n",
        "lines.sample(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Q7P1LaMGkrEZ",
        "outputId": "ab407475-5e91-42ce-85fd-d3be2e5eb981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    src                                 tar\n",
              "9500     Tom is family.  \\tTom fait partie de la famille.\\n\n",
              "16195  I'm often wrong.           \\tJe me trompe souvent.\\n\n",
              "9220     That's ironic.                 \\tC'est ironique.\\n\n",
              "8867     Lock the safe.     \\tVerrouillez le coffre-fort.\\n\n",
              "8195     I woke you up.               \\tJe t'ai réveillé.\\n\n",
              "8021     I outrank you.            \\tJe passe avant vous.\\n\n",
              "7551     He's no saint.          \\tCe n'est pas un saint.\\n\n",
              "7475     He is awesome.                  \\tIl est génial.\\n\n",
              "5457      I won't come.             \\tJe ne viendrai pas.\\n\n",
              "18842  You're adorable.            \\tVous êtes adorables.\\n"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95861911-70c4-4d6d-b054-422b28d838a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9500</th>\n",
              "      <td>Tom is family.</td>\n",
              "      <td>\\tTom fait partie de la famille.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16195</th>\n",
              "      <td>I'm often wrong.</td>\n",
              "      <td>\\tJe me trompe souvent.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9220</th>\n",
              "      <td>That's ironic.</td>\n",
              "      <td>\\tC'est ironique.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8867</th>\n",
              "      <td>Lock the safe.</td>\n",
              "      <td>\\tVerrouillez le coffre-fort.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8195</th>\n",
              "      <td>I woke you up.</td>\n",
              "      <td>\\tJe t'ai réveillé.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8021</th>\n",
              "      <td>I outrank you.</td>\n",
              "      <td>\\tJe passe avant vous.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7551</th>\n",
              "      <td>He's no saint.</td>\n",
              "      <td>\\tCe n'est pas un saint.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7475</th>\n",
              "      <td>He is awesome.</td>\n",
              "      <td>\\tIl est génial.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5457</th>\n",
              "      <td>I won't come.</td>\n",
              "      <td>\\tJe ne viendrai pas.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18842</th>\n",
              "      <td>You're adorable.</td>\n",
              "      <td>\\tVous êtes adorables.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95861911-70c4-4d6d-b054-422b28d838a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95861911-70c4-4d6d-b054-422b28d838a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95861911-70c4-4d6d-b054-422b28d838a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-777907ad-7b49-434c-8770-2d7e7fb01382\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-777907ad-7b49-434c-8770-2d7e7fb01382')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-777907ad-7b49-434c-8770-2d7e7fb01382 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "lines.tar=lines.tar.apply(lambda x : '\\t' + x + '\\n')\n",
        "lines.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "php_ncuqn_MO"
      },
      "outputs": [],
      "source": [
        "#문자 집합 구축\n",
        "src_vocab=set()\n",
        "for line in lines.src:\n",
        "  for char in line:\n",
        "    src_vocab.add(char)\n",
        "\n",
        "tar_vocab=set()\n",
        "for line in lines.tar:\n",
        "  for char in line:\n",
        "    tar_vocab.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqLTLUDjoQKr",
        "outputId": "76baf48b-eca8-4103-a82c-6571979a6838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 char 집합 : 77\n",
            "target 문장의 char 집합 : 104\n"
          ]
        }
      ],
      "source": [
        "src_vocab_size=len(src_vocab)+1\n",
        "tar_vocab_size=len(tar_vocab)+1\n",
        "print('source 문장의 char 집합 :', src_vocab_size)\n",
        "print('target 문장의 char 집합 :', tar_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgvuSIeaob78",
        "outputId": "ae934986-b97e-46ba-eef4-1eaf4b0782da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
          ]
        }
      ],
      "source": [
        "src_vocab=sorted(list(src_vocab))\n",
        "tar_vocab=sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UivRgyOolf3",
        "outputId": "cc7a6342-2a7c-43de-d0c3-988791ffa0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102, '‽': 103}\n"
          ]
        }
      ],
      "source": [
        "#각 문자에 인덱스 부여\n",
        "src_to_index=dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index=dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS4rl-4ao1VZ",
        "outputId": "bfe43bd2-b6ad-48bd-aa5d-dd20a08de971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 정수 인코딩: [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
          ]
        }
      ],
      "source": [
        "#정수 인코딩\n",
        "#영어먼저\n",
        "\n",
        "encoder_input=[]\n",
        "\n",
        "#1개의 문장\n",
        "for line in lines.src:\n",
        "  encoded_line=[]\n",
        "  for char in line:\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  encoder_input.append(encoded_line)\n",
        "print('source 문장의 정수 인코딩:',encoder_input[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjFqQTBOpIeE",
        "outputId": "c3769081-c521-4a34-c693-3455837207e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장의 정수 인코딩: [[1, 48, 52, 3, 4, 2], [1, 39, 52, 69, 54, 59, 56, 14, 2], [1, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 2], [1, 28, 66, 72, 58, 56, 3, 4, 2], [1, 45, 52, 63, 72, 71, 3, 4, 2]]\n"
          ]
        }
      ],
      "source": [
        "#프랑스어 정수 인코딩\n",
        "decoder_input=[]\n",
        "for line in lines.tar:\n",
        "  encoded_line=[]\n",
        "  for char in line:\n",
        "    encoded_line.append(tar_to_index[char])\n",
        "  decoder_input.append(encoded_line)\n",
        "print('target 문장의 정수 인코딩:',decoder_input[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6W9Sz6fpdhQ",
        "outputId": "0ba7ae48-9ea2-4014-9141-807284d77ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장 레이블의 정수 인코딩: [[48, 52, 3, 4, 2], [39, 52, 69, 54, 59, 56, 14, 2], [31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 2], [28, 66, 72, 58, 56, 3, 4, 2], [45, 52, 63, 72, 71, 3, 4, 2]]\n"
          ]
        }
      ],
      "source": [
        "#정수 인코딩 과정에서 <sos> => 프랑스어 맨 앞에 붙어있는 \" 제거 가좡\n",
        "decoder_target=[]\n",
        "for line in lines.tar:\n",
        "  timestep =0\n",
        "  encoded_line=[]\n",
        "  for char in line:\n",
        "    if timestep>0:\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "    timestep=timestep+1\n",
        "  decoder_target.append(encoded_line)\n",
        "print('target 문장 레이블의 정수 인코딩:',decoder_target[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n6PdgeoqQKK",
        "outputId": "5eb4defa-cae0-4c14-96e8-58132f2b9e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이:  18\n",
            "target 문장의 최대 길이:  59\n"
          ]
        }
      ],
      "source": [
        "#패딩 작업 진행\n",
        "#영어랑 프랑스어 따로따로\n",
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print('source 문장의 최대 길이: ',max_src_len)\n",
        "print('target 문장의 최대 길이: ',max_tar_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9LJstMTHqi7F"
      },
      "outputs": [],
      "source": [
        "#padding 작업\n",
        "encoder_input=pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input=pad_sequences(decoder_input,maxlen=max_tar_len, padding='post')\n",
        "decoder_target=pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Mrv-rbqaq4IJ"
      },
      "outputs": [],
      "source": [
        "#원 핫 인코딩 수행\n",
        "encoder_input=to_categorical(encoder_input)\n",
        "decoder_input=to_categorical(decoder_input)\n",
        "decoder_target=to_categorical(decoder_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4ImJq967rC2L"
      },
      "outputs": [],
      "source": [
        "##seq2seq 모델 설계\n",
        "#훈련시키기\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sN-NPcohrgMz"
      },
      "outputs": [],
      "source": [
        "encoder_inputs=Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm=LSTM(units=256, return_state=True)\n",
        "\n",
        "#encoder_outputs는 여기서 불필요함\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "#LSTM은 바닐라 RNN과는 달리 상태가 두개, 은닉상태와 셀 상태\n",
        "encoder_states=[state_h,state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uPGNU22brx_l"
      },
      "outputs": [],
      "source": [
        "decoder_inputs=Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "\n",
        "#디코더에게 인코더의 은닉 상태, 셀 상태를 전달\n",
        "decoder_outputs,_,_ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer =Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs=decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model=Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2y5IKR-s1R7",
        "outputId": "c4b28f95-9cb1-429c-f21a-85ed28d7cb6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "330/330 [==============================] - 16s 19ms/step - loss: 1.1524 - val_loss: 1.0427\n",
            "Epoch 2/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.7771 - val_loss: 0.8489\n",
            "Epoch 3/40\n",
            "330/330 [==============================] - 7s 22ms/step - loss: 0.6721 - val_loss: 0.7744\n",
            "Epoch 4/40\n",
            "330/330 [==============================] - 8s 23ms/step - loss: 0.6166 - val_loss: 0.7225\n",
            "Epoch 5/40\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.5765 - val_loss: 0.6743\n",
            "Epoch 6/40\n",
            "330/330 [==============================] - 5s 15ms/step - loss: 0.5422 - val_loss: 0.6500\n",
            "Epoch 7/40\n",
            "330/330 [==============================] - 5s 17ms/step - loss: 0.5144 - val_loss: 0.6220\n",
            "Epoch 8/40\n",
            "330/330 [==============================] - 6s 20ms/step - loss: 0.4913 - val_loss: 0.5953\n",
            "Epoch 9/40\n",
            "330/330 [==============================] - 6s 17ms/step - loss: 0.4729 - val_loss: 0.5836\n",
            "Epoch 10/40\n",
            "330/330 [==============================] - 5s 15ms/step - loss: 0.4562 - val_loss: 0.5623\n",
            "Epoch 11/40\n",
            "330/330 [==============================] - 4s 12ms/step - loss: 0.4418 - val_loss: 0.5465\n",
            "Epoch 12/40\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.4287 - val_loss: 0.5325\n",
            "Epoch 13/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.4170 - val_loss: 0.5322\n",
            "Epoch 14/40\n",
            "330/330 [==============================] - 4s 12ms/step - loss: 0.4061 - val_loss: 0.5193\n",
            "Epoch 15/40\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.3965 - val_loss: 0.5063\n",
            "Epoch 16/40\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.3873 - val_loss: 0.4979\n",
            "Epoch 17/40\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.3786 - val_loss: 0.4930\n",
            "Epoch 18/40\n",
            "330/330 [==============================] - 6s 17ms/step - loss: 0.3708 - val_loss: 0.4896\n",
            "Epoch 19/40\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.3636 - val_loss: 0.4793\n",
            "Epoch 20/40\n",
            "330/330 [==============================] - 5s 16ms/step - loss: 0.3566 - val_loss: 0.4785\n",
            "Epoch 21/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.3498 - val_loss: 0.4727\n",
            "Epoch 22/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.3437 - val_loss: 0.4725\n",
            "Epoch 23/40\n",
            "330/330 [==============================] - 6s 17ms/step - loss: 0.3375 - val_loss: 0.4660\n",
            "Epoch 24/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.3320 - val_loss: 0.4640\n",
            "Epoch 25/40\n",
            "330/330 [==============================] - 4s 14ms/step - loss: 0.3268 - val_loss: 0.4556\n",
            "Epoch 26/40\n",
            "330/330 [==============================] - 5s 15ms/step - loss: 0.3214 - val_loss: 0.4590\n",
            "Epoch 27/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.3161 - val_loss: 0.4527\n",
            "Epoch 28/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.3114 - val_loss: 0.4526\n",
            "Epoch 29/40\n",
            "330/330 [==============================] - 6s 18ms/step - loss: 0.3067 - val_loss: 0.4519\n",
            "Epoch 30/40\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.3020 - val_loss: 0.4488\n",
            "Epoch 31/40\n",
            "330/330 [==============================] - 6s 17ms/step - loss: 0.2977 - val_loss: 0.4487\n",
            "Epoch 32/40\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.2933 - val_loss: 0.4473\n",
            "Epoch 33/40\n",
            "330/330 [==============================] - 5s 16ms/step - loss: 0.2892 - val_loss: 0.4441\n",
            "Epoch 34/40\n",
            "330/330 [==============================] - 7s 21ms/step - loss: 0.2850 - val_loss: 0.4408\n",
            "Epoch 35/40\n",
            "330/330 [==============================] - 5s 15ms/step - loss: 0.2811 - val_loss: 0.4401\n",
            "Epoch 36/40\n",
            "330/330 [==============================] - 5s 16ms/step - loss: 0.2773 - val_loss: 0.4425\n",
            "Epoch 37/40\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.2736 - val_loss: 0.4399\n",
            "Epoch 38/40\n",
            "330/330 [==============================] - 5s 16ms/step - loss: 0.2699 - val_loss: 0.4389\n",
            "Epoch 39/40\n",
            "330/330 [==============================] - 6s 17ms/step - loss: 0.2663 - val_loss: 0.4399\n",
            "Epoch 40/40\n",
            "330/330 [==============================] - 5s 16ms/step - loss: 0.2627 - val_loss: 0.4461\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b9408246560>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.fit(x=[encoder_input, decoder_input],y=decoder_target,batch_size=64, epochs=40, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Yq7VDa1RtVb4"
      },
      "outputs": [],
      "source": [
        "#seq2seq 기계 번역기 동장시키기\n",
        "encoder_model =Model(inputs=encoder_inputs, outputs=encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Wcm32s-8t7m3"
      },
      "outputs": [],
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
        "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "V-kWLe6OutUr"
      },
      "outputs": [],
      "source": [
        "#인덱스로부터 단어를 얻을 수 있는 index_to_src와 index_to_tar\n",
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_tar_len):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence\n"
      ],
      "metadata": {
        "id": "cfyME0k2AlRr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index:seq_index+1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장:', lines.src[seq_index])\n",
        "  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력\n"
      ],
      "metadata": {
        "id": "NInTcbTJB_Qu",
        "outputId": "1013bb66-c69f-4c22-85d9-db624f765427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 508ms/step\n",
            "1/1 [==============================] - 1s 514ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go.\n",
            "정답 문장: ouge !\n",
            "번역 문장: ars !\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Hello!\n",
            "정답 문장: onjour !\n",
            "번역 문장: idez-le.\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Got it!\n",
            "정답 문장: 'ai pigé !\n",
            "번역 문장: arde-le.\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go home.\n",
            "정답 문장: entre à la maison.\n",
            "번역 문장: a au travail !\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Get going.\n",
            "정답 문장: n avant.\n",
            "번역 문장: écampe !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word-Level 번역기 만들기\n"
      ],
      "metadata": {
        "id": "yoe7K1teCnTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ],
      "metadata": {
        "id": "UJ9j9unJCBLR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 33000\n"
      ],
      "metadata": {
        "id": "gjQ8lGsvD4js"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#구두점 등을 제거하거나 단어와 구분해주기 위한 전처리\n",
        "\n",
        "def to_ascii(s):\n",
        "  # 프랑스어 악센트(accent) 삭제\n",
        "  # 예시 : 'déjà diné' -> deja dine\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  # 악센트 제거 함수 호출\n",
        "  sent = to_ascii(sent.lower())\n",
        "\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) \"I am a student.\" => \"I am a student .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # 다수 개의 공백을 하나의 공백으로 치환\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent\n"
      ],
      "metadata": {
        "id": "7BuwjkmvEt_Y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 테스트\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print('전처리 전 영어 문장 :', en_sent)\n",
        "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
        "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
        "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))\n"
      ],
      "metadata": {
        "id": "d9HRP0U1EvBT",
        "outputId": "c828e042-e118-4924-baef-097e9ec9c74d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 영어 문장 : Have you had dinner?\n",
            "전처리 후 영어 문장 : have you had dinner ?\n",
            "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
            "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"fra.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      # source 데이터와 target 데이터 분리\n",
        "      src_line, tar_line, _ = line.strip().split('\\t')\n",
        "\n",
        "      # source 데이터 전처리\n",
        "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # target 데이터 전처리\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line)\n",
        "      decoder_input.append(tar_line_in)\n",
        "      decoder_target.append(tar_line_out)\n",
        "\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "\n",
        "  return encoder_input, decoder_input, decoder_target\n"
      ],
      "metadata": {
        "id": "GKRgM57lEwe6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
        "print('인코더의 입력 :',sents_en_in[:5])\n",
        "print('디코더의 입력 :',sents_fra_in[:5])\n",
        "print('디코더의 레이블 :',sents_fra_out[:5])\n"
      ],
      "metadata": {
        "id": "2YNFqOGlE7mi",
        "outputId": "6859b5b7-62be-4cd2-fd5d-246285f6bd77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
            "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
            "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")\n"
      ],
      "metadata": {
        "id": "qEdJ2b5JFJaW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
        "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
        "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)\n"
      ],
      "metadata": {
        "id": "Cw5H5fYGFrnM",
        "outputId": "47f56461-473f-4872-d1cf-9bac065bb7e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력의 크기(shape) : (33000, 7)\n",
            "디코더의 입력의 크기(shape) : (33000, 16)\n",
            "디코더의 레이블의 크기(shape) : (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))\n"
      ],
      "metadata": {
        "id": "aB4g6Du5Ftah",
        "outputId": "73db6c77-a520-4be9-df68-71f6c8176af1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어 집합의 크기 : 4481, 프랑스어 단어 집합의 크기 : 7873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('랜덤 시퀀스 :',indices)\n"
      ],
      "metadata": {
        "id": "tRXCvOpzFwoW",
        "outputId": "86318a5b-7507-413c-d31a-1945cf9ba6ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시퀀스 : [23316 24063 22360 ... 22458  6958  2022]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]\n"
      ],
      "metadata": {
        "id": "M6RvM2orF1OG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input[30997]\n"
      ],
      "metadata": {
        "id": "f7nL9FdOF59Y",
        "outputId": "8db8b986-dd22-4f59-c336-7f247aba470d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([825,   1,   0,   0,   0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input[30997]\n"
      ],
      "metadata": {
        "id": "5y6Uqzy4F8yF",
        "outputId": "becbb439-103e-440c-c79c-cc4753dee194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 4729,    9,    1,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target[30997]\n"
      ],
      "metadata": {
        "id": "H2c-_S2oF_IY",
        "outputId": "ec34ab91-344a-4928-b744-346031195b57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4729,    9,    1,    3,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 이때 decoder_input과 decoder_target의 값은 같아야함 !! => 교사 강요 **"
      ],
      "metadata": {
        "id": "4f_Ugf37GFkb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(33000*0.1)\n",
        "print('검증 데이터의 개수 :',n_of_val)\n"
      ],
      "metadata": {
        "id": "A_2hBuucGSR8",
        "outputId": "f0cf6ebd-a346-4fa0-c268-188ed972414e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 데이터의 개수 : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n"
      ],
      "metadata": {
        "id": "2KbJSIFyGV6l"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)\n"
      ],
      "metadata": {
        "id": "oKZ_6iYhGXIM",
        "outputId": "97cd0893-1069-4af5-9cdf-0ce4e2e6ac60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (29700, 7)\n",
            "훈련 target 데이터의 크기 : (29700, 16)\n",
            "훈련 target 레이블의 크기 : (29700, 16)\n",
            "테스트 source 데이터의 크기 : (3300, 7)\n",
            "테스트 target 데이터의 크기 : (3300, 16)\n",
            "테스트 target 레이블의 크기 : (3300, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 설계\n",
        "- Masking은 패딩 토큰인 숫자 0의 경우에는 연산을 제외하는 역할\n",
        "- 인코더의 내부 상태를 디코더로 넘겨주어야 하기 때문에 return_state=True\n",
        "- 인코더에 입력을 넣으면 내부 상태를 리턴\n",
        "- LSTM에서 state_h, state_c를 리턴받는데, 이는 각각 RNN 챕터에서 LSTM을 처음 설명할 때 언급하였던 은닉 상태와 셀 상태에 해당. 이 두 가지 상태를 encoder_states에 저장, encoder_states를 디코더에 전달하므로서 이 두 가지 상태 모두를 디코더로 전달 => 컨텍스트 벡터"
      ],
      "metadata": {
        "id": "OLzNdaSoGavo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "9yRk_TuqGYMG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=64\n",
        "hidden_units=64"
      ],
      "metadata": {
        "id": "d3PIMW-EHDe2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#인코더 설계\n",
        "encoder_inputs=Input(shape=(None,))\n",
        "#임베딩 층\n",
        "enc_emb=Embedding(src_vocab_size,embedding_dim)(encoder_inputs)\n",
        "#패딩 0은 연산에서 제외\n",
        "enc_masking=Masking(mask_value=0.0)(enc_emb)\n",
        "#상태값 리턴을 위해 return_state 는 True\n",
        "encoder_lstm=LSTM(hidden_units, return_state=True)\n",
        "#은닉 상태와 셀 상태를 리턴\n",
        "encoder_outputs, state_h, state_c=encoder_lstm(enc_masking)\n",
        "#인코더의 은닉 상태와 셀 상태를 저장\n",
        "encoder_states=[state_h,state_c]"
      ],
      "metadata": {
        "id": "dgzuSl4KHGfN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#디코더 설계\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) #임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "dec_masking=Masking(mask_value=0.0)(dec_emb) #패딩0은 연산에서 제외\n",
        "\n",
        "#상태값 리턴을 위해 return_state= True, 모든 시점에 대해 단어를 예측하기 위해 return_sequences=True\n",
        "decoder_lstm=LSTM(hidden_units, return_sequences=True,return_state=True)\n",
        "\n",
        "#인코더의 은닉 상태를 초기 은닉 상태 (initial_state)로 사용\n",
        "decoder_outputs,_,_=decoder_lstm(dec_masking,initial_state=encoder_states)\n",
        "\n",
        "#모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense=Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs=decoder_dense(decoder_outputs)\n",
        "\n",
        "#모델의 입력과 출력을 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "806rfT7qIFeI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 훈련\n",
        "#batch_size = 128\n",
        "#epoch = 50\n",
        "\n",
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\\\n",
        "          validation_data=([encoder_input_test, decoder_input_test],\n",
        "                           decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "metadata": {
        "id": "ebpNTVMnKIsP",
        "outputId": "31db928f-a038-41f5-89bc-9c2bd91a92be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 41s 131ms/step - loss: 3.3225 - acc: 0.6137 - val_loss: 1.9527 - val_acc: 0.6262\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 1.8191 - acc: 0.6748 - val_loss: 1.7148 - val_acc: 0.7226\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 1.6445 - acc: 0.7425 - val_loss: 1.5740 - val_acc: 0.7545\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 10s 41ms/step - loss: 1.5244 - acc: 0.7560 - val_loss: 1.4723 - val_acc: 0.7658\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 9s 39ms/step - loss: 1.4241 - acc: 0.7652 - val_loss: 1.3918 - val_acc: 0.7735\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 1.3401 - acc: 0.7801 - val_loss: 1.3163 - val_acc: 0.7879\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 1.2658 - acc: 0.7910 - val_loss: 1.2589 - val_acc: 0.7941\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 1.2070 - acc: 0.8004 - val_loss: 1.2111 - val_acc: 0.8054\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 1.1558 - acc: 0.8103 - val_loss: 1.1690 - val_acc: 0.8136\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 1.1080 - acc: 0.8169 - val_loss: 1.1324 - val_acc: 0.8181\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 9s 37ms/step - loss: 1.0629 - acc: 0.8227 - val_loss: 1.0974 - val_acc: 0.8230\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 1.0214 - acc: 0.8280 - val_loss: 1.0660 - val_acc: 0.8278\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.9835 - acc: 0.8324 - val_loss: 1.0368 - val_acc: 0.8300\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.9476 - acc: 0.8364 - val_loss: 1.0124 - val_acc: 0.8333\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.9145 - acc: 0.8401 - val_loss: 0.9899 - val_acc: 0.8365\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.8843 - acc: 0.8436 - val_loss: 0.9710 - val_acc: 0.8382\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.8558 - acc: 0.8467 - val_loss: 0.9505 - val_acc: 0.8416\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.8286 - acc: 0.8498 - val_loss: 0.9344 - val_acc: 0.8433\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.8035 - acc: 0.8524 - val_loss: 0.9189 - val_acc: 0.8455\n",
            "Epoch 20/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.7801 - acc: 0.8552 - val_loss: 0.9078 - val_acc: 0.8463\n",
            "Epoch 21/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.7580 - acc: 0.8573 - val_loss: 0.8920 - val_acc: 0.8487\n",
            "Epoch 22/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.7359 - acc: 0.8597 - val_loss: 0.8808 - val_acc: 0.8492\n",
            "Epoch 23/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.7158 - acc: 0.8617 - val_loss: 0.8697 - val_acc: 0.8505\n",
            "Epoch 24/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.6960 - acc: 0.8641 - val_loss: 0.8602 - val_acc: 0.8522\n",
            "Epoch 25/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.6772 - acc: 0.8663 - val_loss: 0.8510 - val_acc: 0.8533\n",
            "Epoch 26/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.6593 - acc: 0.8681 - val_loss: 0.8435 - val_acc: 0.8537\n",
            "Epoch 27/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.6427 - acc: 0.8702 - val_loss: 0.8337 - val_acc: 0.8543\n",
            "Epoch 28/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.6260 - acc: 0.8723 - val_loss: 0.8250 - val_acc: 0.8563\n",
            "Epoch 29/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.6098 - acc: 0.8741 - val_loss: 0.8182 - val_acc: 0.8568\n",
            "Epoch 30/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.5943 - acc: 0.8758 - val_loss: 0.8121 - val_acc: 0.8578\n",
            "Epoch 31/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.5801 - acc: 0.8778 - val_loss: 0.8075 - val_acc: 0.8581\n",
            "Epoch 32/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5653 - acc: 0.8794 - val_loss: 0.8029 - val_acc: 0.8584\n",
            "Epoch 33/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.5525 - acc: 0.8813 - val_loss: 0.7989 - val_acc: 0.8584\n",
            "Epoch 34/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.5395 - acc: 0.8831 - val_loss: 0.7927 - val_acc: 0.8605\n",
            "Epoch 35/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.5262 - acc: 0.8849 - val_loss: 0.7867 - val_acc: 0.8602\n",
            "Epoch 36/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5137 - acc: 0.8868 - val_loss: 0.7844 - val_acc: 0.8609\n",
            "Epoch 37/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.5018 - acc: 0.8887 - val_loss: 0.7789 - val_acc: 0.8616\n",
            "Epoch 38/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4907 - acc: 0.8901 - val_loss: 0.7770 - val_acc: 0.8623\n",
            "Epoch 39/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.4795 - acc: 0.8919 - val_loss: 0.7755 - val_acc: 0.8623\n",
            "Epoch 40/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4695 - acc: 0.8933 - val_loss: 0.7722 - val_acc: 0.8631\n",
            "Epoch 41/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4584 - acc: 0.8951 - val_loss: 0.7690 - val_acc: 0.8635\n",
            "Epoch 42/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4479 - acc: 0.8971 - val_loss: 0.7691 - val_acc: 0.8639\n",
            "Epoch 43/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.4384 - acc: 0.8986 - val_loss: 0.7663 - val_acc: 0.8635\n",
            "Epoch 44/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4306 - acc: 0.8999 - val_loss: 0.7629 - val_acc: 0.8655\n",
            "Epoch 45/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.4199 - acc: 0.9019 - val_loss: 0.7622 - val_acc: 0.8650\n",
            "Epoch 46/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.4107 - acc: 0.9035 - val_loss: 0.7599 - val_acc: 0.8657\n",
            "Epoch 47/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.4022 - acc: 0.9050 - val_loss: 0.7615 - val_acc: 0.8655\n",
            "Epoch 48/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.3942 - acc: 0.9065 - val_loss: 0.7592 - val_acc: 0.8657\n",
            "Epoch 49/50\n",
            "233/233 [==============================] - 8s 36ms/step - loss: 0.3863 - acc: 0.9078 - val_loss: 0.7588 - val_acc: 0.8660\n",
            "Epoch 50/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.3786 - acc: 0.9093 - val_loss: 0.7577 - val_acc: 0.8669\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b930f5d2410>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기계 번역기 동작시키기"
      ],
      "metadata": {
        "id": "3fN6IH7VLdMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# 디코더 설계 시작\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# 수정된 디코더\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n"
      ],
      "metadata": {
        "id": "2OyU6pzSLa1V"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 정수 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 단어로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "    if (sampled_char == '<eos>' or\n",
        "        len(decoded_sentence) > 50):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence\n"
      ],
      "metadata": {
        "id": "rgRwVp-_ZhVn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_src(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0):\n",
        "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "  return sentence\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
        "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "DQqvridCaoi6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)\n"
      ],
      "metadata": {
        "id": "N_brFM0pawuu",
        "outputId": "a8ae2399-fcb3-45e3-80a3-1cff91976868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-e2ccbaad18e9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"입력문장 :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_to_src\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-971a67e995f7>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# <SOS>에 해당하는 정수 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mstop_condition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '<sos>'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)\n"
      ],
      "metadata": {
        "id": "RX7m5jOFaykW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vBCsyQxWa0II"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}