{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5540183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#케라스로 RNN구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ab39e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "model=Sequential()\n",
    "model.add(SimpleRNN(3,input_shape=(2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19a4fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(SimpleRNN(3,batch_input_shape=(8,2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57a1202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (8, 2, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(SimpleRNN(3,batch_input_shape=(8,2,10), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec9c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파이썬으로 RNN구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "576d42e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 은닉 상태: [0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps=10\n",
    "input_dim=4\n",
    "hidden_units=8\n",
    "\n",
    "#입력에 해당되는 2D텐서\n",
    "inputs=np.random.random((timesteps,input_dim))\n",
    "\n",
    "hidden_state_t= np.zeros((hidden_units,))\n",
    "\n",
    "print('초기 은닉 상태:', hidden_state_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d758db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 Wx의 크기(shape): (8, 4)\n",
      "가중치 Wh의 크기(shape): (8, 8)\n",
      "편향의 크기(shape): (8,)\n"
     ]
    }
   ],
   "source": [
    "Wx= np.random.random((hidden_units,input_dim))\n",
    "Wh=np.random.random((hidden_units,hidden_units))\n",
    "b=np.random.random((hidden_units,))\n",
    "\n",
    "print('가중치 Wx의 크기(shape):', np.shape(Wx))\n",
    "print('가중치 Wh의 크기(shape):', np.shape(Wh))\n",
    "print('편향의 크기(shape):', np.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d75036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든시점의 은닉상태:\n",
      "[[0.96476303 0.98432785 0.96712811 0.97826635 0.82825681 0.98389014\n",
      "  0.98708025 0.76640961]\n",
      " [0.99999786 0.9999661  0.9999973  0.99998415 0.99786221 0.9995871\n",
      "  0.99999344 0.99994014]\n",
      " [0.99999827 0.99993598 0.99999592 0.99998188 0.99813437 0.99903812\n",
      "  0.9999904  0.99990832]\n",
      " [0.99999891 0.9999628  0.9999973  0.99998973 0.99907135 0.99942139\n",
      "  0.99999492 0.99994351]\n",
      " [0.99999776 0.99994813 0.99999649 0.99998047 0.99830962 0.99909658\n",
      "  0.99999213 0.99993743]\n",
      " [0.99999785 0.9999642  0.99999549 0.99998652 0.99738387 0.99903357\n",
      "  0.99999212 0.99992748]\n",
      " [0.99999937 0.99997644 0.99999786 0.99999484 0.99903528 0.99966421\n",
      "  0.9999966  0.999942  ]\n",
      " [0.99999127 0.99992055 0.99999521 0.99993768 0.99668102 0.99809256\n",
      "  0.99998622 0.99994858]\n",
      " [0.99999907 0.99998767 0.99999875 0.99999518 0.99916535 0.99979108\n",
      "  0.99999823 0.99997605]\n",
      " [0.99999897 0.99997011 0.9999985  0.9999903  0.99939469 0.99966515\n",
      "  0.99999695 0.99996695]]\n"
     ]
    }
   ],
   "source": [
    "#RNN층 동작\n",
    "total_hidden_states=[]\n",
    "\n",
    "for input_t in inputs:\n",
    "    output_t=np.tanh(np.dot(Wx,input_t)+ np.dot(Wh,hidden_state_t)+b)\n",
    "    \n",
    "    total_hidden_states.append(list(output_t))\n",
    "    hidden_state_t= output_t\n",
    "    \n",
    "total_hidden_states = np.stack(total_hidden_states, axis=0)\n",
    "\n",
    "print('모든시점의 은닉상태:')\n",
    "print(total_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be2d409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#깊은 순환 신경망\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_units, input_length=10, input_dim=5, return_sequences=True))\n",
    "model.add(SimpleRNN(hidden_units, return_sequences=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbabd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#양방향 순환신경망\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "timesteps=10\n",
    "input_dim=5\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa5df06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8484209",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GRU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28016\\4112917046.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#케라스에서 GRU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'GRU' is not defined"
     ]
    }
   ],
   "source": [
    "#케라스에서 GRU\n",
    "model.add(GRU(hidden_size, input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55a92989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#케라스에서 SimpleRNN과 LTSM이해하기\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN , LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f00959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
    "print(np.shape(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "604b1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35ec5daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state: [[-0.9980013 -0.9663857 -0.0813536]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# SImpleRNN\n",
    "rnn=SimpleRNN(3)\n",
    "hidden_state= rnn(train_X)\n",
    "print('hidden state: {}, shape: {}'.format(hidden_state,hidden_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b315fa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[-0.48502576 -0.87370014 -0.97650576]\n",
      "  [-0.98270655 -0.9618492  -0.97284746]\n",
      "  [-0.9874757  -0.8638253  -0.98377   ]\n",
      "  [-0.9793333   0.659656   -0.3529194 ]]], shape: (1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True)\n",
    "hidden_states = rnn(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e428ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.99706477  0.94030434 -0.9713305 ]\n",
      "  [ 0.9980922   0.9560972  -0.96196353]\n",
      "  [ 0.9931357   0.97797775 -0.9922364 ]\n",
      "  [ 0.97120494  0.9609152  -0.9938699 ]]], shape: (1, 4, 3)\n",
      "last hidden state : [[ 0.97120494  0.9609152  -0.9938699 ]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2ab72d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[ 0.58851355 -0.989359    0.6749512 ]], shape: (1, 3)\n",
      "last hidden state : [[ 0.58851355 -0.989359    0.6749512 ]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=False, return_state=True)\n",
    "hidden_state, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd93721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state:[[-0.21902545 -0.08918695  0.13374394]], hape: (1, 3)\n",
      "last hidden state:[[-0.21902545 -0.08918695  0.13374394]], shape:(1, 3)\n",
      "last cell state: [[-0.5449333  -0.40312988  0.46886265]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "#LSTM \n",
    "lstm=LSTM(3,return_sequences=False, return_state=True)\n",
    "hidden_state,last_state,last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden state:{}, hape: {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state:{}, shape:{}'.format(last_state, last_state.shape))\n",
    "print('last cell state: {}, shape: {}'.format(last_cell_state,last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3654105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[-0.28946584 -0.35559174  0.318317  ]\n",
      "  [-0.28974527 -0.2723003   0.34903792]\n",
      "  [-0.24002561 -0.45638454  0.40264106]\n",
      "  [-0.3012215  -0.3124423   0.2639909 ]]], shape: (1, 4, 3)\n",
      "last hidden state : [[-0.3012215 -0.3124423  0.2639909]], shape: (1, 3)\n",
      "last cell state : [[-0.51159006 -1.6248031   0.87611765]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_hidden_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_hidden_state, last_hidden_state.shape))\n",
    "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69fc5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bidirectional\n",
    "k_init = tf.keras.initializers.Constant(value=0.1)\n",
    "b_init = tf.keras.initializers.Constant(value=0)\n",
    "r_init = tf.keras.initializers.Constant(value=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57111cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[0.6303138 0.6303138 0.6303138 0.7038734 0.7038734 0.7038734]], shape: (1, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\\n",
    "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f68e1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True, \\\n",
    "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fa304cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
      "  [0.55111325 0.55111325 0.55111325 0.58863586 0.58863586 0.58863586]\n",
      "  [0.59115744 0.59115744 0.59115744 0.3951699  0.3951699  0.3951699 ]\n",
      "  [0.6303138  0.6303138  0.6303138  0.21942244 0.21942244 0.21942244]]], shape: (1, 4, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "127b0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#06 RNN을 이용한 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f8f45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터에 대한 이해와 전처리\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "feca9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6774a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기: 12\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "print('단어 집합의 크기: %d' %vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70930796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b001f6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 11\n"
     ]
    }
   ],
   "source": [
    "sequences= list()\n",
    "for line in text.split('\\n'):\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(encoded)):\n",
    "        sequence=encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "print('학습에 사용할 샘플의 개수: %d' %len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e3538c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "136313cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이: 6\n"
     ]
    }
   ],
   "source": [
    "max_len=max(len(I) for I in sequences)\n",
    "print('샘플의 최대 길이: {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f46cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences= pad_sequences(sequences,maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce22c94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5d5ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=np.array(sequences)\n",
    "X=sequences[:,:-1]\n",
    "y=sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3ebbef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73bd1da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae0eb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y,num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d33d1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ebda1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1f452b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense,SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc58b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 2.4527 - accuracy: 0.0909 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4386 - accuracy: 0.1818 - 8ms/epoch - 8ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4243 - accuracy: 0.2727 - 6ms/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4098 - accuracy: 0.2727 - 7ms/epoch - 7ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.3949 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.3795 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.3637 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.3472 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3301 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3122 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.2936 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.2740 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.2536 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.2322 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.2100 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.1868 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.1627 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.1379 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.1125 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.0866 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.0604 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.0342 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.0083 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 1.9829 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 1.9585 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 1.9353 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 1.9136 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.8934 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.8747 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.8575 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.8414 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.8261 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.8111 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.7960 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.7806 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.7647 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.7482 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.7312 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.7137 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.6960 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.6781 - accuracy: 0.4545 - 3ms/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.6602 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.6423 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.6244 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.6064 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.5882 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.5699 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.5512 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.5321 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.5126 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.4927 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.4724 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.4518 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.4308 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.4097 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.3884 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.3670 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.3456 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.3242 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.3028 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.2816 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.2604 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.2394 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.2186 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.1980 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.1776 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.1575 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.1377 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.1182 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.0990 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.0802 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.0617 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.0437 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.0260 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.0087 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 0.9918 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 0.9753 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 0.9591 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 0.9433 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 0.9277 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.9125 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.8977 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.8830 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.8687 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.8546 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.8408 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.8272 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.8138 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.8006 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.7877 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.7749 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.7623 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.7499 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.7377 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.7257 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.7139 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.7023 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.6908 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.6796 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.6685 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.6576 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.6469 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.6364 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.6260 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.6159 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.6059 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.5961 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.5865 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.5771 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.5678 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.5587 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.5498 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.5410 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.5324 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.5239 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.5156 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.5075 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.4995 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.4916 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.4839 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.4763 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.4689 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.4616 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.4544 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.4473 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.4404 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.4336 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.4269 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.4203 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4138 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.4074 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.4012 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.3950 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.3889 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.3830 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.3771 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.3713 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.3656 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.3600 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.3545 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.3491 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.3438 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.3385 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3333 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.3282 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.3232 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.3183 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.3134 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.3086 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.3039 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.2992 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.2946 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.2901 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.2856 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.2813 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.2769 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2727 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.2684 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.2643 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.2602 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2562 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2522 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.2483 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.2444 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.2406 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.2369 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.2332 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.2296 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.2260 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.2225 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.2190 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.2156 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.2122 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.2089 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.2056 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.2024 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1992 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1960 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.1930 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.1899 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1870 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1840 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1811 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1783 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1755 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1727 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1700 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1673 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1647 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1621 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1596 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1571 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1546 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1522 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1499 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1475 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1452 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.1430 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.1408 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1386 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca3deba760>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim=10\n",
    "hidden_units=32\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4e8848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model,tokenizer,current_word,n):\n",
    "    init_word=current_word\n",
    "    sentence=''\n",
    "    for _ in range(n):\n",
    "        encoded =tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded=pad_sequences([encoded],maxlen=5, padding='pre')\n",
    "        \n",
    "        result=model.predict(encoded,verbose=0)\n",
    "        result= np.argmax(result, axis=1)\n",
    "        \n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index ==result:\n",
    "                break\n",
    "                \n",
    "        current_word = current_word+ ' ' + word\n",
    "        \n",
    "        sentence= sentence + ' '+ word\n",
    "        \n",
    "        \n",
    "    sentence= init_word+sentence\n",
    "    return sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "872bb8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model,tokenizer,'경마장에', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f767e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그의 말이 법이다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model,tokenizer,'그의',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e8f112b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model,tokenizer,'가는', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b7dc18f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fab741f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount  \\\n",
       "0  5adf6684068401528a2aa69b               781   \n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType  \\\n",
       "0                             By JOHN BRANCH      article   \n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ArticlesApril2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4df87c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열의 개수: 15\n",
      "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
      "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
      "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('열의 개수:', len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa992ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df['headline'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1dc44b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline=[]\n",
    "headline.extend(list(df.headline.values))\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0ba83582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수:1324\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수:{}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cba189f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노이즈 값 제거 후 샘플의 개수: 1214\n"
     ]
    }
   ],
   "source": [
    "headline=[word for word in headline if word  !='Unknown']\n",
    "print('노이즈 값 제거 후 샘플의 개수: {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "71e233dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f354e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repreprocessing(raw_sentence):\n",
    "    preprocesseed_sentence= raw_sentence.encode('utf8').decode('ascii','ignore')\n",
    "    return ''.join(word for word in preprocesseed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline =[repreprocessing(x) for x in headline]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53cbb9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기: 3494\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_headline)\n",
    "vocab_size= len(tokenizer.word_index)+1\n",
    "print('단어 집합의 크기: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "649cd729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences=list()\n",
    "for sentence in preprocessed_headline:\n",
    "    \n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1,len(encoded)):\n",
    "        sequence= encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9a1aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 582번 단어 : offer\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "for key, value in tokenizer.word_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
    "    index_to_word[value] = key\n",
    "\n",
    "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c313976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 24\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "278ca2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cfa9cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10a570c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  99]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  99 269]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  99 269 371]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6dbe1b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 269  371 1115]\n"
     ]
    }
   ],
   "source": [
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "835d34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7af4001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e6d327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "244/244 - 6s - loss: 7.6290 - accuracy: 0.0299 - 6s/epoch - 25ms/step\n",
      "Epoch 2/200\n",
      "244/244 - 4s - loss: 7.1144 - accuracy: 0.0282 - 4s/epoch - 15ms/step\n",
      "Epoch 3/200\n",
      "244/244 - 3s - loss: 6.9809 - accuracy: 0.0328 - 3s/epoch - 14ms/step\n",
      "Epoch 4/200\n",
      "244/244 - 3s - loss: 6.8570 - accuracy: 0.0397 - 3s/epoch - 14ms/step\n",
      "Epoch 5/200\n",
      "244/244 - 4s - loss: 6.7068 - accuracy: 0.0442 - 4s/epoch - 15ms/step\n",
      "Epoch 6/200\n",
      "244/244 - 4s - loss: 6.5333 - accuracy: 0.0477 - 4s/epoch - 16ms/step\n",
      "Epoch 7/200\n",
      "244/244 - 4s - loss: 6.3459 - accuracy: 0.0497 - 4s/epoch - 16ms/step\n",
      "Epoch 8/200\n",
      "244/244 - 4s - loss: 6.1506 - accuracy: 0.0584 - 4s/epoch - 16ms/step\n",
      "Epoch 9/200\n",
      "244/244 - 4s - loss: 5.9649 - accuracy: 0.0598 - 4s/epoch - 14ms/step\n",
      "Epoch 10/200\n",
      "244/244 - 3s - loss: 5.7851 - accuracy: 0.0616 - 3s/epoch - 14ms/step\n",
      "Epoch 11/200\n",
      "244/244 - 3s - loss: 5.6100 - accuracy: 0.0677 - 3s/epoch - 13ms/step\n",
      "Epoch 12/200\n",
      "244/244 - 3s - loss: 5.4466 - accuracy: 0.0761 - 3s/epoch - 14ms/step\n",
      "Epoch 13/200\n",
      "244/244 - 3s - loss: 5.2926 - accuracy: 0.0800 - 3s/epoch - 14ms/step\n",
      "Epoch 14/200\n",
      "244/244 - 3s - loss: 5.1442 - accuracy: 0.0875 - 3s/epoch - 14ms/step\n",
      "Epoch 15/200\n",
      "244/244 - 4s - loss: 5.0030 - accuracy: 0.0918 - 4s/epoch - 17ms/step\n",
      "Epoch 16/200\n",
      "244/244 - 4s - loss: 4.8679 - accuracy: 0.1033 - 4s/epoch - 15ms/step\n",
      "Epoch 17/200\n",
      "244/244 - 4s - loss: 4.7353 - accuracy: 0.1120 - 4s/epoch - 15ms/step\n",
      "Epoch 18/200\n",
      "244/244 - 4s - loss: 4.6095 - accuracy: 0.1253 - 4s/epoch - 14ms/step\n",
      "Epoch 19/200\n",
      "244/244 - 4s - loss: 4.4891 - accuracy: 0.1393 - 4s/epoch - 15ms/step\n",
      "Epoch 20/200\n",
      "244/244 - 4s - loss: 4.3690 - accuracy: 0.1580 - 4s/epoch - 14ms/step\n",
      "Epoch 21/200\n",
      "244/244 - 3s - loss: 4.2533 - accuracy: 0.1757 - 3s/epoch - 14ms/step\n",
      "Epoch 22/200\n",
      "244/244 - 4s - loss: 4.1430 - accuracy: 0.1910 - 4s/epoch - 16ms/step\n",
      "Epoch 23/200\n",
      "244/244 - 4s - loss: 4.0365 - accuracy: 0.2120 - 4s/epoch - 15ms/step\n",
      "Epoch 24/200\n",
      "244/244 - 4s - loss: 3.9300 - accuracy: 0.2281 - 4s/epoch - 15ms/step\n",
      "Epoch 25/200\n",
      "244/244 - 4s - loss: 3.8285 - accuracy: 0.2393 - 4s/epoch - 15ms/step\n",
      "Epoch 26/200\n",
      "244/244 - 4s - loss: 3.7289 - accuracy: 0.2586 - 4s/epoch - 15ms/step\n",
      "Epoch 27/200\n",
      "244/244 - 4s - loss: 3.6348 - accuracy: 0.2734 - 4s/epoch - 18ms/step\n",
      "Epoch 28/200\n",
      "244/244 - 4s - loss: 3.5394 - accuracy: 0.2908 - 4s/epoch - 16ms/step\n",
      "Epoch 29/200\n",
      "244/244 - 4s - loss: 3.4486 - accuracy: 0.3076 - 4s/epoch - 15ms/step\n",
      "Epoch 30/200\n",
      "244/244 - 4s - loss: 3.3614 - accuracy: 0.3219 - 4s/epoch - 15ms/step\n",
      "Epoch 31/200\n",
      "244/244 - 4s - loss: 3.2836 - accuracy: 0.3390 - 4s/epoch - 15ms/step\n",
      "Epoch 32/200\n",
      "244/244 - 4s - loss: 3.1975 - accuracy: 0.3490 - 4s/epoch - 18ms/step\n",
      "Epoch 33/200\n",
      "244/244 - 4s - loss: 3.1166 - accuracy: 0.3723 - 4s/epoch - 15ms/step\n",
      "Epoch 34/200\n",
      "244/244 - 4s - loss: 3.0401 - accuracy: 0.3856 - 4s/epoch - 15ms/step\n",
      "Epoch 35/200\n",
      "244/244 - 4s - loss: 2.9669 - accuracy: 0.4005 - 4s/epoch - 16ms/step\n",
      "Epoch 36/200\n",
      "244/244 - 4s - loss: 2.8975 - accuracy: 0.4118 - 4s/epoch - 17ms/step\n",
      "Epoch 37/200\n",
      "244/244 - 4s - loss: 2.8254 - accuracy: 0.4209 - 4s/epoch - 18ms/step\n",
      "Epoch 38/200\n",
      "244/244 - 4s - loss: 2.7617 - accuracy: 0.4365 - 4s/epoch - 16ms/step\n",
      "Epoch 39/200\n",
      "244/244 - 4s - loss: 2.6930 - accuracy: 0.4488 - 4s/epoch - 15ms/step\n",
      "Epoch 40/200\n",
      "244/244 - 4s - loss: 2.6320 - accuracy: 0.4571 - 4s/epoch - 15ms/step\n",
      "Epoch 41/200\n",
      "244/244 - 4s - loss: 2.5684 - accuracy: 0.4702 - 4s/epoch - 15ms/step\n",
      "Epoch 42/200\n",
      "244/244 - 4s - loss: 2.5098 - accuracy: 0.4852 - 4s/epoch - 15ms/step\n",
      "Epoch 43/200\n",
      "244/244 - 4s - loss: 2.4516 - accuracy: 0.4974 - 4s/epoch - 18ms/step\n",
      "Epoch 44/200\n",
      "244/244 - 5s - loss: 2.3955 - accuracy: 0.5085 - 5s/epoch - 19ms/step\n",
      "Epoch 45/200\n",
      "244/244 - 5s - loss: 2.3417 - accuracy: 0.5171 - 5s/epoch - 20ms/step\n",
      "Epoch 46/200\n",
      "244/244 - 5s - loss: 2.2868 - accuracy: 0.5275 - 5s/epoch - 20ms/step\n",
      "Epoch 47/200\n",
      "244/244 - 5s - loss: 2.2351 - accuracy: 0.5386 - 5s/epoch - 22ms/step\n",
      "Epoch 48/200\n",
      "244/244 - 5s - loss: 2.1871 - accuracy: 0.5531 - 5s/epoch - 20ms/step\n",
      "Epoch 49/200\n",
      "244/244 - 5s - loss: 2.1361 - accuracy: 0.5598 - 5s/epoch - 19ms/step\n",
      "Epoch 50/200\n",
      "244/244 - 4s - loss: 2.0882 - accuracy: 0.5764 - 4s/epoch - 15ms/step\n",
      "Epoch 51/200\n",
      "244/244 - 4s - loss: 2.0422 - accuracy: 0.5818 - 4s/epoch - 15ms/step\n",
      "Epoch 52/200\n",
      "244/244 - 4s - loss: 1.9926 - accuracy: 0.5913 - 4s/epoch - 16ms/step\n",
      "Epoch 53/200\n",
      "244/244 - 4s - loss: 1.9506 - accuracy: 0.5999 - 4s/epoch - 16ms/step\n",
      "Epoch 54/200\n",
      "244/244 - 4s - loss: 1.9085 - accuracy: 0.6071 - 4s/epoch - 17ms/step\n",
      "Epoch 55/200\n",
      "244/244 - 4s - loss: 1.8655 - accuracy: 0.6167 - 4s/epoch - 17ms/step\n",
      "Epoch 56/200\n",
      "244/244 - 4s - loss: 1.8203 - accuracy: 0.6323 - 4s/epoch - 17ms/step\n",
      "Epoch 57/200\n",
      "244/244 - 4s - loss: 1.7825 - accuracy: 0.6358 - 4s/epoch - 16ms/step\n",
      "Epoch 58/200\n",
      "244/244 - 4s - loss: 1.7402 - accuracy: 0.6448 - 4s/epoch - 16ms/step\n",
      "Epoch 59/200\n",
      "244/244 - 4s - loss: 1.7014 - accuracy: 0.6554 - 4s/epoch - 17ms/step\n",
      "Epoch 60/200\n",
      "244/244 - 4s - loss: 1.6638 - accuracy: 0.6649 - 4s/epoch - 16ms/step\n",
      "Epoch 61/200\n",
      "244/244 - 5s - loss: 1.6276 - accuracy: 0.6696 - 5s/epoch - 20ms/step\n",
      "Epoch 62/200\n",
      "244/244 - 4s - loss: 1.5875 - accuracy: 0.6796 - 4s/epoch - 17ms/step\n",
      "Epoch 63/200\n",
      "244/244 - 4s - loss: 1.5537 - accuracy: 0.6864 - 4s/epoch - 16ms/step\n",
      "Epoch 64/200\n",
      "244/244 - 4s - loss: 1.5183 - accuracy: 0.6941 - 4s/epoch - 15ms/step\n",
      "Epoch 65/200\n",
      "244/244 - 4s - loss: 1.4859 - accuracy: 0.7013 - 4s/epoch - 16ms/step\n",
      "Epoch 66/200\n",
      "244/244 - 4s - loss: 1.4484 - accuracy: 0.7081 - 4s/epoch - 16ms/step\n",
      "Epoch 67/200\n",
      "244/244 - 4s - loss: 1.4175 - accuracy: 0.7160 - 4s/epoch - 16ms/step\n",
      "Epoch 68/200\n",
      "244/244 - 4s - loss: 1.3858 - accuracy: 0.7220 - 4s/epoch - 16ms/step\n",
      "Epoch 69/200\n",
      "244/244 - 4s - loss: 1.3561 - accuracy: 0.7300 - 4s/epoch - 17ms/step\n",
      "Epoch 70/200\n",
      "244/244 - 4s - loss: 1.3223 - accuracy: 0.7324 - 4s/epoch - 17ms/step\n",
      "Epoch 71/200\n",
      "244/244 - 4s - loss: 1.2930 - accuracy: 0.7415 - 4s/epoch - 17ms/step\n",
      "Epoch 72/200\n",
      "244/244 - 4s - loss: 1.2819 - accuracy: 0.7439 - 4s/epoch - 16ms/step\n",
      "Epoch 73/200\n",
      "244/244 - 4s - loss: 1.2357 - accuracy: 0.7537 - 4s/epoch - 16ms/step\n",
      "Epoch 74/200\n",
      "244/244 - 4s - loss: 1.2067 - accuracy: 0.7605 - 4s/epoch - 16ms/step\n",
      "Epoch 75/200\n",
      "244/244 - 4s - loss: 1.1804 - accuracy: 0.7650 - 4s/epoch - 16ms/step\n",
      "Epoch 76/200\n",
      "244/244 - 4s - loss: 1.1538 - accuracy: 0.7705 - 4s/epoch - 16ms/step\n",
      "Epoch 77/200\n",
      "244/244 - 4s - loss: 1.1290 - accuracy: 0.7741 - 4s/epoch - 15ms/step\n",
      "Epoch 78/200\n",
      "244/244 - 4s - loss: 1.1041 - accuracy: 0.7834 - 4s/epoch - 15ms/step\n",
      "Epoch 79/200\n",
      "244/244 - 4s - loss: 1.0787 - accuracy: 0.7880 - 4s/epoch - 15ms/step\n",
      "Epoch 80/200\n",
      "244/244 - 4s - loss: 1.0555 - accuracy: 0.7926 - 4s/epoch - 15ms/step\n",
      "Epoch 81/200\n",
      "244/244 - 4s - loss: 1.0324 - accuracy: 0.7987 - 4s/epoch - 15ms/step\n",
      "Epoch 82/200\n",
      "244/244 - 4s - loss: 1.0073 - accuracy: 0.7993 - 4s/epoch - 15ms/step\n",
      "Epoch 83/200\n",
      "244/244 - 4s - loss: 0.9846 - accuracy: 0.8080 - 4s/epoch - 15ms/step\n",
      "Epoch 84/200\n",
      "244/244 - 4s - loss: 0.9621 - accuracy: 0.8096 - 4s/epoch - 15ms/step\n",
      "Epoch 85/200\n",
      "244/244 - 4s - loss: 0.9396 - accuracy: 0.8130 - 4s/epoch - 15ms/step\n",
      "Epoch 86/200\n",
      "244/244 - 4s - loss: 0.9199 - accuracy: 0.8189 - 4s/epoch - 15ms/step\n",
      "Epoch 87/200\n",
      "244/244 - 4s - loss: 0.9010 - accuracy: 0.8231 - 4s/epoch - 15ms/step\n",
      "Epoch 88/200\n",
      "244/244 - 4s - loss: 0.8780 - accuracy: 0.8265 - 4s/epoch - 15ms/step\n",
      "Epoch 89/200\n",
      "244/244 - 4s - loss: 0.8605 - accuracy: 0.8301 - 4s/epoch - 15ms/step\n",
      "Epoch 90/200\n",
      "244/244 - 4s - loss: 0.8394 - accuracy: 0.8340 - 4s/epoch - 15ms/step\n",
      "Epoch 91/200\n",
      "244/244 - 4s - loss: 0.8217 - accuracy: 0.8390 - 4s/epoch - 15ms/step\n",
      "Epoch 92/200\n",
      "244/244 - 4s - loss: 0.8031 - accuracy: 0.8420 - 4s/epoch - 16ms/step\n",
      "Epoch 93/200\n",
      "244/244 - 4s - loss: 0.7857 - accuracy: 0.8458 - 4s/epoch - 16ms/step\n",
      "Epoch 94/200\n",
      "244/244 - 4s - loss: 0.7673 - accuracy: 0.8506 - 4s/epoch - 15ms/step\n",
      "Epoch 95/200\n",
      "244/244 - 4s - loss: 0.7509 - accuracy: 0.8521 - 4s/epoch - 15ms/step\n",
      "Epoch 96/200\n",
      "244/244 - 4s - loss: 0.7357 - accuracy: 0.8553 - 4s/epoch - 15ms/step\n",
      "Epoch 97/200\n",
      "244/244 - 4s - loss: 0.7238 - accuracy: 0.8576 - 4s/epoch - 15ms/step\n",
      "Epoch 98/200\n",
      "244/244 - 4s - loss: 0.7070 - accuracy: 0.8613 - 4s/epoch - 16ms/step\n",
      "Epoch 99/200\n",
      "244/244 - 4s - loss: 0.6879 - accuracy: 0.8643 - 4s/epoch - 18ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "244/244 - 4s - loss: 0.6737 - accuracy: 0.8662 - 4s/epoch - 16ms/step\n",
      "Epoch 101/200\n",
      "244/244 - 4s - loss: 0.6587 - accuracy: 0.8693 - 4s/epoch - 16ms/step\n",
      "Epoch 102/200\n",
      "244/244 - 4s - loss: 0.6468 - accuracy: 0.8733 - 4s/epoch - 16ms/step\n",
      "Epoch 103/200\n",
      "244/244 - 4s - loss: 0.6323 - accuracy: 0.8747 - 4s/epoch - 16ms/step\n",
      "Epoch 104/200\n",
      "244/244 - 4s - loss: 0.6184 - accuracy: 0.8772 - 4s/epoch - 15ms/step\n",
      "Epoch 105/200\n",
      "244/244 - 4s - loss: 0.6057 - accuracy: 0.8775 - 4s/epoch - 16ms/step\n",
      "Epoch 106/200\n",
      "244/244 - 4s - loss: 0.5943 - accuracy: 0.8807 - 4s/epoch - 16ms/step\n",
      "Epoch 107/200\n",
      "244/244 - 4s - loss: 0.5815 - accuracy: 0.8811 - 4s/epoch - 16ms/step\n",
      "Epoch 108/200\n",
      "244/244 - 4s - loss: 0.5706 - accuracy: 0.8862 - 4s/epoch - 18ms/step\n",
      "Epoch 109/200\n",
      "244/244 - 4s - loss: 0.5593 - accuracy: 0.8861 - 4s/epoch - 18ms/step\n",
      "Epoch 110/200\n",
      "244/244 - 4s - loss: 0.5487 - accuracy: 0.8894 - 4s/epoch - 17ms/step\n",
      "Epoch 111/200\n",
      "244/244 - 4s - loss: 0.5377 - accuracy: 0.8902 - 4s/epoch - 18ms/step\n",
      "Epoch 112/200\n",
      "244/244 - 4s - loss: 0.5278 - accuracy: 0.8932 - 4s/epoch - 17ms/step\n",
      "Epoch 113/200\n",
      "244/244 - 4s - loss: 0.5162 - accuracy: 0.8930 - 4s/epoch - 17ms/step\n",
      "Epoch 114/200\n",
      "244/244 - 4s - loss: 0.5059 - accuracy: 0.8953 - 4s/epoch - 17ms/step\n",
      "Epoch 115/200\n",
      "244/244 - 4s - loss: 0.4969 - accuracy: 0.8972 - 4s/epoch - 16ms/step\n",
      "Epoch 116/200\n",
      "244/244 - 4s - loss: 0.4903 - accuracy: 0.8982 - 4s/epoch - 17ms/step\n",
      "Epoch 117/200\n",
      "244/244 - 4s - loss: 0.4770 - accuracy: 0.9012 - 4s/epoch - 16ms/step\n",
      "Epoch 118/200\n",
      "244/244 - 4s - loss: 0.4676 - accuracy: 0.9012 - 4s/epoch - 16ms/step\n",
      "Epoch 119/200\n",
      "244/244 - 4s - loss: 0.4583 - accuracy: 0.9013 - 4s/epoch - 16ms/step\n",
      "Epoch 120/200\n",
      "244/244 - 4s - loss: 0.4510 - accuracy: 0.9039 - 4s/epoch - 16ms/step\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28016\\2062142875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "957073c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "\n",
    "    # n번 반복\n",
    "    for _ in range(n):\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
    "\n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        current_word = current_word + ' '  + word\n",
    "\n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5667c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i disapprove of school vouchers can i still apply for them\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, 'i', 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e4bcab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how a landlord fit for dr king client over say just\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, 'how', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c7ade61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 데이터 로드\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
    "\n",
    "f = open('11-0.txt', 'rb')\n",
    "sentences = []\n",
    "for sentence in f: # 데이터로부터 한 줄씩 읽는다.\n",
    "    sentence = sentence.strip() # strip()을 통해 \\r, \\n을 제거한다.\n",
    "    sentence = sentence.lower() # 소문자화.\n",
    "    sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
    "    if len(sentence) > 0:\n",
    "        sentences.append(sentence)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "335c994d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and',\n",
       " 'most other parts of the world at no cost and with almost no restrictions',\n",
       " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
       " 'of the project gutenberg license included with this ebook or online at']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b866c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자열의 길이 또는 총 문자의 개수: 159484\n"
     ]
    }
   ],
   "source": [
    "total_data=' '.join(sentences)\n",
    "print('문자열의 길이 또는 총 문자의 개수: %d' %len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "745dfb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with\n"
     ]
    }
   ],
   "source": [
    "print(total_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1dd07577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기: 56\n"
     ]
    }
   ],
   "source": [
    "char_vocab= sorted(list(set(total_data)))\n",
    "vocab_size=len(char_vocab)\n",
    "print('문자 집합의 크기: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f2ffa662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 : {' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
     ]
    }
   ],
   "source": [
    "# 문자에 고유한 정수 부여\n",
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
    "print('문자 집합 :',char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdc42b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fb6239be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appl (입력 시퀀스) -> pple (예측해야하는 시퀀스)\n",
    "train_X = 'appl'\n",
    "train_y = 'pple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51605e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 수 : 2658\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60\n",
    "\n",
    "# 문자열의 길이를 seq_length로 나누면 전처리 후 생겨날 샘플 수\n",
    "n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n",
    "print ('샘플의 수 : {}'.format(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b5233f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 pick.\n",
    "    X_sample = total_data[i * seq_length: (i + 1) * seq_length]\n",
    "\n",
    "    # 정수 인코딩\n",
    "    X_encoded = [char_to_index[c] for c in X_sample]\n",
    "    train_X.append(X_encoded)\n",
    "\n",
    "    # 오른쪽으로 1칸 쉬프트\n",
    "    y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]\n",
    "    y_encoded = [char_to_index[c] for c in y_sample]\n",
    "    train_y.append(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "05e156e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터의 첫번째 샘플 : [49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
      "y 데이터의 첫번째 샘플 : [37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n",
      "--------------------------------------------------\n",
      "X 데이터의 첫번째 샘플 디코딩 : ['t', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a']\n",
      "y 데이터의 첫번째 샘플 디코딩 : ['h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a', 'n']\n"
     ]
    }
   ],
   "source": [
    "print('X 데이터의 첫번째 샘플 :',train_X[0])\n",
    "print('y 데이터의 첫번째 샘플 :',train_y[0])\n",
    "print('-'*50)\n",
    "print('X 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_X[0]])\n",
    "print('y 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_y[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab729d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "703647ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
     ]
    }
   ],
   "source": [
    "print(train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c518fb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X의 크기(shape) : (2658, 60, 56)\n",
      "train_y의 크기(shape) : (2658, 60, 56)\n"
     ]
    }
   ],
   "source": [
    "train_X = to_categorical(train_X)\n",
    "train_y = to_categorical(train_y)\n",
    "\n",
    "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
    "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "86658afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "84/84 - 24s - loss: 3.0675 - accuracy: 0.1832 - 24s/epoch - 286ms/step\n",
      "Epoch 2/80\n",
      "84/84 - 22s - loss: 2.7729 - accuracy: 0.2384 - 22s/epoch - 263ms/step\n",
      "Epoch 3/80\n",
      "84/84 - 25s - loss: 2.4230 - accuracy: 0.3208 - 25s/epoch - 300ms/step\n",
      "Epoch 4/80\n",
      "84/84 - 24s - loss: 2.2756 - accuracy: 0.3532 - 24s/epoch - 287ms/step\n",
      "Epoch 5/80\n",
      "84/84 - 24s - loss: 2.1757 - accuracy: 0.3777 - 24s/epoch - 283ms/step\n",
      "Epoch 6/80\n",
      "84/84 - 24s - loss: 2.0977 - accuracy: 0.3967 - 24s/epoch - 290ms/step\n",
      "Epoch 7/80\n",
      "84/84 - 26s - loss: 2.0375 - accuracy: 0.4123 - 26s/epoch - 304ms/step\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28016\\2889986680.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "\n",
    "hidden_units = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(hidden_units, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=80, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f37e0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, length):\n",
    "    # 문자에 대한 랜덤한 정수 생성\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "\n",
    "    # 랜덤한 정수로부터 맵핑되는 문자 생성\n",
    "    y_char = [index_to_char[ix[-1]]]\n",
    "    print(ix[-1],'번 문자',y_char[-1],'로 예측을 시작!')\n",
    "\n",
    "    # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "\n",
    "    for i in range(length):\n",
    "        # X[0][i][예측한 문자의 인덱스] = 1, 즉, 예측 문자를 다음 입력 시퀀스에 추가\n",
    "        X[0][i][ix[-1]] = 1\n",
    "        print(index_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(index_to_char[ix[-1]])\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "652d75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 번 문자 k 로 예측을 시작!\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 737ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "k the said the said the said the said the said the said the said the said the said the said the said \n"
     ]
    }
   ],
   "source": [
    "result = sentence_generation(model, 100)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1723d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b92519a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = '''\n",
    "I get on with life as a programmer,\n",
    "I like to contemplate beer.\n",
    "But when I start to daydream,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "Do I love wine more than beer?\n",
    "\n",
    "I like to use words about beer.\n",
    "But when I stop my talking,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "I hate bugs and errors.\n",
    "But I just think back to wine,\n",
    "And I'm happy once again.\n",
    "\n",
    "I like to hang out with programming and deep learning.\n",
    "But when left alone,\n",
    "My mind turns straight to wine.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "270a98b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
     ]
    }
   ],
   "source": [
    "tokens = raw_text.split()\n",
    "raw_text = ' '.join(tokens)\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9b371a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 : [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
      "문자 집합의 크기 : 33\n"
     ]
    }
   ],
   "source": [
    "# 중복을 제거한 문자 집합 생성\n",
    "char_vocab = sorted(list(set(raw_text)))\n",
    "vocab_size = len(char_vocab)\n",
    "print('문자 집합 :',char_vocab)\n",
    "print ('문자 집합의 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "965db31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab)) # 문자에 고유한 정수 인덱스 부여\n",
    "print(char_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "492b3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 훈련 샘플의 수: 426\n"
     ]
    }
   ],
   "source": [
    "length = 11\n",
    "sequences = []\n",
    "for i in range(length, len(raw_text)):\n",
    "    seq = raw_text[i-length:i] # 길이 11의 문자열을 지속적으로 만든다.\n",
    "    sequences.append(seq)\n",
    "print('총 훈련 샘플의 수: %d' % len(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "06c57fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I get on wi',\n",
       " ' get on wit',\n",
       " 'get on with',\n",
       " 'et on with ',\n",
       " 't on with l',\n",
       " ' on with li',\n",
       " 'on with lif',\n",
       " 'n with life',\n",
       " ' with life ',\n",
       " 'with life a']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "79d0c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = []\n",
    "for sequence in sequences: # 전체 데이터에서 문장 샘플을 1개씩 꺼낸다.\n",
    "    encoded_sequence = [char_to_index[char] for char in sequence] # 문장 샘플에서 각 문자에 대해서 정수 인코딩을 수행.\n",
    "    encoded_sequences.append(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3804781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18],\n",
       " [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28],\n",
       " [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17],\n",
       " [14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0],\n",
       " [28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8b8c6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = np.array(encoded_sequences)\n",
    "\n",
    "# 맨 마지막 위치의 문자를 분리\n",
    "X_data = encoded_sequences[:,:-1]\n",
    "# 맨 마지막 위치의 문자를 저장\n",
    "y_data = encoded_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "318ac116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0 16 14 28  0 24 23  0 31]\n",
      " [ 0 16 14 28  0 24 23  0 31 18]\n",
      " [16 14 28  0 24 23  0 31 18 28]\n",
      " [14 28  0 24 23  0 31 18 28 17]\n",
      " [28  0 24 23  0 31 18 28 17  0]]\n",
      "[18 28 17  0 21]\n"
     ]
    }
   ],
   "source": [
    "print(X_data[:5])\n",
    "print(y_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bde9af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
    "X_data_one_hot = np.array(X_data_one_hot)\n",
    "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2d9fa1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 10, 33)\n"
     ]
    }
   ],
   "source": [
    "print(X_data_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "97e05606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 3.4673 - accuracy: 0.1432 - 2s/epoch - 139ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 3.3698 - accuracy: 0.1972 - 139ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 3.1327 - accuracy: 0.1972 - 123ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 3.0024 - accuracy: 0.1972 - 122ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 2.9640 - accuracy: 0.1972 - 116ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 2.9393 - accuracy: 0.1972 - 88ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 2.9107 - accuracy: 0.1972 - 92ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 2.8901 - accuracy: 0.1972 - 120ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 2.8641 - accuracy: 0.1972 - 122ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 2.8309 - accuracy: 0.1972 - 92ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 2.8029 - accuracy: 0.1972 - 122ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 2.7715 - accuracy: 0.2066 - 144ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 2.7228 - accuracy: 0.2042 - 118ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 2.6774 - accuracy: 0.2113 - 137ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 2.6313 - accuracy: 0.2277 - 143ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 2.5822 - accuracy: 0.2535 - 113ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 2.5301 - accuracy: 0.2582 - 144ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 2.4826 - accuracy: 0.2840 - 134ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 2.4322 - accuracy: 0.2582 - 143ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 2.4009 - accuracy: 0.3239 - 136ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 2.3374 - accuracy: 0.3192 - 133ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 2.3003 - accuracy: 0.3380 - 143ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 2.2498 - accuracy: 0.3451 - 134ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 2.2186 - accuracy: 0.3545 - 128ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 2.1661 - accuracy: 0.3709 - 111ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 2.1462 - accuracy: 0.3920 - 127ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 2.1124 - accuracy: 0.3779 - 138ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 2.0638 - accuracy: 0.3991 - 138ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 2.0224 - accuracy: 0.4460 - 126ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.9867 - accuracy: 0.4343 - 123ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.9527 - accuracy: 0.4577 - 142ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.8941 - accuracy: 0.4906 - 137ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.8833 - accuracy: 0.4671 - 144ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.8315 - accuracy: 0.4695 - 139ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.8219 - accuracy: 0.4859 - 116ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.7644 - accuracy: 0.5094 - 138ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.7389 - accuracy: 0.5188 - 127ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6817 - accuracy: 0.5634 - 136ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6458 - accuracy: 0.5728 - 142ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6236 - accuracy: 0.5775 - 133ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.5752 - accuracy: 0.5962 - 148ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.5384 - accuracy: 0.6221 - 136ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.5012 - accuracy: 0.6291 - 139ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.4606 - accuracy: 0.6479 - 140ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.4277 - accuracy: 0.6526 - 148ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.3929 - accuracy: 0.6714 - 142ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.3735 - accuracy: 0.6737 - 145ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.3442 - accuracy: 0.6573 - 144ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.3093 - accuracy: 0.6761 - 138ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.2684 - accuracy: 0.7160 - 141ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.2260 - accuracy: 0.7089 - 124ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.2042 - accuracy: 0.7207 - 147ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.1616 - accuracy: 0.7418 - 141ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.1352 - accuracy: 0.7559 - 137ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.1025 - accuracy: 0.7606 - 147ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.0840 - accuracy: 0.7559 - 156ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.0403 - accuracy: 0.7793 - 141ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.0260 - accuracy: 0.7793 - 141ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.0046 - accuracy: 0.7817 - 146ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 0.9607 - accuracy: 0.7958 - 133ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 0.9399 - accuracy: 0.8052 - 131ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 0.9200 - accuracy: 0.8052 - 127ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 0.8863 - accuracy: 0.8099 - 138ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 0.8521 - accuracy: 0.8286 - 137ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 0.8335 - accuracy: 0.8146 - 137ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 0.8126 - accuracy: 0.8192 - 133ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 0.8057 - accuracy: 0.8333 - 135ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 0.7793 - accuracy: 0.8357 - 136ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 0.7553 - accuracy: 0.8451 - 141ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 0.7292 - accuracy: 0.8521 - 135ms/epoch - 10ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 0.7138 - accuracy: 0.8592 - 146ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 0.6705 - accuracy: 0.8779 - 134ms/epoch - 10ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 0.6557 - accuracy: 0.8873 - 133ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 0.6437 - accuracy: 0.8897 - 118ms/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 0.6202 - accuracy: 0.8897 - 111ms/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 0.6021 - accuracy: 0.8944 - 132ms/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 0.5787 - accuracy: 0.9038 - 109ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 0.5604 - accuracy: 0.9155 - 126ms/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 0.5430 - accuracy: 0.9131 - 128ms/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 0.5287 - accuracy: 0.9296 - 130ms/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 0.5105 - accuracy: 0.9319 - 101ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 0.5019 - accuracy: 0.9272 - 133ms/epoch - 10ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 0.4989 - accuracy: 0.9272 - 131ms/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 0.4772 - accuracy: 0.9390 - 136ms/epoch - 10ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 0.4518 - accuracy: 0.9390 - 129ms/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 0.4421 - accuracy: 0.9437 - 134ms/epoch - 10ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 0.4288 - accuracy: 0.9437 - 134ms/epoch - 10ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 0.4173 - accuracy: 0.9484 - 131ms/epoch - 9ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 0.4097 - accuracy: 0.9507 - 131ms/epoch - 9ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 0.3948 - accuracy: 0.9507 - 143ms/epoch - 10ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 0.3829 - accuracy: 0.9648 - 128ms/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 0.3685 - accuracy: 0.9601 - 127ms/epoch - 9ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 0.3491 - accuracy: 0.9695 - 115ms/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 0.3369 - accuracy: 0.9624 - 124ms/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 0.3338 - accuracy: 0.9577 - 134ms/epoch - 10ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 0.3351 - accuracy: 0.9648 - 131ms/epoch - 9ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 0.3138 - accuracy: 0.9624 - 140ms/epoch - 10ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 0.3000 - accuracy: 0.9695 - 99ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 0.2903 - accuracy: 0.9695 - 128ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 0.2801 - accuracy: 0.9742 - 134ms/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca58588490>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "hidden_units = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6723872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
    "\n",
    "    # 초기 시퀀스\n",
    "    init_text = seed_text\n",
    "    sentence = ''\n",
    "\n",
    "    # 다음 문자 예측은 총 n번만 반복.\n",
    "    for _ in range(n):\n",
    "        encoded = [char_to_index[char] for char in seed_text] # 현재 시퀀스에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') # 데이터에 대한 패딩\n",
    "        encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
    "\n",
    "        # 입력한 X(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 문자)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for char, index in char_to_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 시퀀스 + 예측 문자를 현재 시퀀스로 변경\n",
    "        seed_text = seed_text + char\n",
    "\n",
    "        # 예측 문자를 문장에 저장\n",
    "        sentence = sentence + char\n",
    "\n",
    "    # n번의 다음 문자 예측이 끝나면 최종 완성된 문장을 리턴.\n",
    "    sentence = init_text + sentence\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c6f6f0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on with life as a programmer, I like to hang out wihh sfr arsr t tut horrprmmm, ndgr\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18110c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afecafc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89107da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e50067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
