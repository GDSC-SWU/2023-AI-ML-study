{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 순환 신경망"
      ],
      "metadata": {
        "id": "V5nqVnAKTI6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스로 rnn 구현하기"
      ],
      "metadata": {
        "id": "ff_4lmqvTMEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
        "# model.add(SimpleRNN(3, input_length=2, input_dim=10))와 동일\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzyyy0f-TnsQ",
        "outputId": "d3ecfa13-9a26-4e9e-fe56-6bc3dd43e5e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 3)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42 (168.00 Byte)\n",
            "Trainable params: 42 (168.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Il790fiT1SQ",
        "outputId": "9068810f-d91c-4ffb-a30f-8a5796d4b9a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (8, 2, 3)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42 (168.00 Byte)\n",
            "Trainable params: 42 (168.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이썬으로 rnn 구현하기"
      ],
      "metadata": {
        "id": "sfjMNcRJUM2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 10\n",
        "input_dim = 4\n",
        "hidden_units = 8\n",
        "\n",
        "# 입력에 해당되는 2D 텐서\n",
        "inputs = np.random.random((timesteps, input_dim))\n",
        "\n",
        "# 초기 은닉 상태는 0(벡터)로 초기화\n",
        "hidden_state_t = np.zeros((hidden_units,))\n",
        "\n",
        "print('초기 은닉 상태 :',hidden_state_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssaf2GrLUO40",
        "outputId": "5c4e8c05-36cd-42a4-8292-abad7c62a603"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "초기 은닉 상태 : [0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치\n",
        "Wx = np.random.random((hidden_units, input_dim))\n",
        "# (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치\n",
        "Wh = np.random.random((hidden_units, hidden_units))\n",
        "# (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)\n",
        "b = np.random.random((hidden_units,))\n",
        "\n",
        "print('가중치 Wx의 크기(shape) :',np.shape(Wx))\n",
        "print('가중치 Wh의 크기(shape) :',np.shape(Wh))\n",
        "print('편향의 크기(shape) :',np.shape(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE6TTeptUSxf",
        "outputId": "89df6be7-dcb3-4903-bebd-cd9e52390bcc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가중치 Wx의 크기(shape) : (8, 4)\n",
            "가중치 Wh의 크기(shape) : (8, 8)\n",
            "편향의 크기(shape) : (8,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_hidden_states = []\n",
        "\n",
        "# 각 시점 별 입력값\n",
        "for input_t in inputs:\n",
        "\n",
        "  # Wx * Xt + Wh * Ht-1 + b(bias)\n",
        "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b)\n",
        "\n",
        "  # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep t, output_dim)\n",
        "  # 각 시점의 은닉 상태의 값을 계속해서 누적\n",
        "  total_hidden_states.append(list(output_t))\n",
        "  hidden_state_t = output_t\n",
        "\n",
        "# 출력 시 값을 깔끔하게 해주는 용도\n",
        "total_hidden_states = np.stack(total_hidden_states, axis = 0)\n",
        "\n",
        "# (timesteps, output_dim)\n",
        "print('모든 시점의 은닉 상태 :')\n",
        "print(total_hidden_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgAuJ_vVUUne",
        "outputId": "1315f21a-625e-4877-b7a6-b54d39446d8b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 시점의 은닉 상태 :\n",
            "[[0.77462407 0.95509826 0.96042884 0.85256872 0.99085602 0.95271973\n",
            "  0.98173185 0.95405677]\n",
            " [0.99997539 0.99995568 0.99998082 0.99999074 0.99999324 0.99998632\n",
            "  0.99999271 0.99999043]\n",
            " [0.9999759  0.99995214 0.99996401 0.99999374 0.99995698 0.99991263\n",
            "  0.99997259 0.99998456]\n",
            " [0.99997762 0.99995461 0.99997854 0.99999444 0.99998955 0.99997578\n",
            "  0.9999901  0.99999319]\n",
            " [0.99996665 0.99990173 0.99997171 0.99999165 0.9999917  0.99997288\n",
            "  0.99998964 0.9999942 ]\n",
            " [0.99998516 0.99998462 0.99999397 0.9999984  0.99999732 0.99999078\n",
            "  0.99999557 0.99999751]\n",
            " [0.99998392 0.99997805 0.9999861  0.99999728 0.99999608 0.99998493\n",
            "  0.99999169 0.99999495]\n",
            " [0.9999778  0.99996459 0.99998897 0.99999732 0.99999771 0.99998683\n",
            "  0.99999355 0.99999715]\n",
            " [0.99997733 0.999945   0.9999627  0.99999297 0.99999398 0.99997644\n",
            "  0.99998655 0.99999087]\n",
            " [0.99997377 0.99995469 0.99998698 0.99999684 0.99999497 0.99997578\n",
            "  0.99999082 0.99999639]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "점검 퀴즈"
      ],
      "metadata": {
        "id": "2FjCMQM1UHDH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqcWfu1DSd5o",
        "outputId": "d7470fbf-0f47-4660-a5c8-1d4f60a1d484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         500000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 128)               29312     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 529441 (2.02 MB)\n",
            "Trainable params: 529441 (2.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Embedding, Dense\n",
        "\n",
        "vocab_size = 5000\n",
        "embedding_dim = 100\n",
        "hidden_size = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_size))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케라스의 SimpleRNN과 LSTM 이해하기"
      ],
      "metadata": {
        "id": "Vmbls5l8UxTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**임의의 입력 생성**"
      ],
      "metadata": {
        "id": "wKP4RZrIUzx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import SimpleRNN, LSTM, Bidirectional\n",
        "\n",
        "# 임의의 입력 생성\n",
        "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
        "print(np.shape(train_X))\n",
        "\n",
        "# 단어 벡터의 차원은 5\n",
        "# 각 시점마다 5차원의 단어 벡터가 입력으로 사용됨\n",
        "# 문장의 길이가 4\n",
        "# = 4번의 시점(timesteps)이 존재"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28XPDIPtUgE2",
        "outputId": "1048958a-ec64-4371-e7bf-f2e6762d2ac1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN은 2D 텐서가 아니라 3D 텐서를 입력을 받음\n",
        "\n",
        "-> 배치 크기 1을 추가해주기\n"
      ],
      "metadata": {
        "id": "Lsb0XLBlVKQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
        "train_X = np.array(train_X, dtype=np.float32)\n",
        "print(train_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHcMIO3uVPOa",
        "outputId": "3cad63f4-9ac7-42b1-b841-3ba81a95a341"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SimpleRNN 이해하기**"
      ],
      "metadata": {
        "id": "2g3okUhiVSd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = SimpleRNN(3)\n",
        "# rnn = SimpleRNN(3, return_sequences=False, return_state=False)와 동일\n",
        "# return_sequences가 False : 마지막 시점의 은닉 상태만 출력\n",
        "hidden_state = rnn(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "# (1, 3) 텐서 : 마지막 시점의 은닉 상태"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW9ZkyA-VVnr",
        "outputId": "d02e3063-857a-46cb-e8b0-e704b3bc144f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[0.96543187 0.86557496 0.3948043 ]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = SimpleRNN(3, return_sequences=True)\n",
        "hidden_states = rnn(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "# (1, 4, 3) 크기의 텐서가 출력\n",
        "# 입력 데이터는 (1, 4, 5)의 크기를 가지는 3D 텐서\n",
        "# 4가 시점(timesteps)에 해당하는 값\n",
        "# 모든 시점에 대해서 은닉 상태의 값을 출력하여 (1, 4, 3) 크기의 텐서를 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOoEWzrBV6sp",
        "outputId": "5fa6e206-8a46-4c3f-a630-6d25b00d677d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[ 0.98571396  0.99987125 -0.93091774]\n",
            "  [ 0.9256597   0.9995669  -0.97179705]\n",
            "  [ 0.98234     0.9968591  -0.15468419]\n",
            "  [ 0.4763849   0.99961865 -0.06523784]]], shape: (1, 4, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences가 True이면서, return_state도 True\n",
        "\n",
        "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
        "hidden_states, last_state = rnn(train_X)\n",
        "\n",
        "# return_sequences=True로 인한 출력으로 모든 시점의 은닉 상태\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "# return_state=True로 인한 출력으로 마지막 시점의 은닉 상태\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggs_2v0IWISz",
        "outputId": "d43239e0-de7a-45ac-9df1-fe72136d9f8d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[ 0.27282393 -0.99085593  0.9999116 ]\n",
            "  [ 0.9966035  -0.99450266  0.99977386]\n",
            "  [ 0.7252435  -0.98867124  0.7976134 ]\n",
            "  [ 0.650951   -0.43902475  0.9332727 ]]], shape: (1, 4, 3)\n",
            "last hidden state : [[ 0.650951   -0.43902475  0.9332727 ]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences는 False인데, retun_state가 True인 경우\n",
        "rnn = SimpleRNN(3, return_sequences=False, return_state=True)\n",
        "hidden_state, last_state = rnn(train_X)\n",
        "\n",
        "# 마지막 시점의 은닉 상태를 출력\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "# 마지막 시점의 은닉 상태를 출력\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-C-RVJfWTme",
        "outputId": "cb5deee5-1c95-49e0-d858-74037c462040"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[-0.14727914  0.7841889   0.89722335]], shape: (1, 3)\n",
            "last hidden state : [[-0.14727914  0.7841889   0.89722335]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM 이해하기**"
      ],
      "metadata": {
        "id": "AmJa4REvWYrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "임의의 입력에 대해서 LSTM을 사용할 경우"
      ],
      "metadata": {
        "id": "PI8Mv3lVWcoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
        "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
        "\n",
        "#  return_sequences가 False -> 마지막 시점의 은닉 상태\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n",
        "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkoUc9aGWdWy",
        "outputId": "b6067846-8dfe-4121-c746-1af866742c4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[0.7444666  0.2772802  0.08013996]], shape: (1, 3)\n",
            "last hidden state : [[0.7444666  0.2772802  0.08013996]], shape: (1, 3)\n",
            "last cell state : [[1.5542498  0.66304785 1.1264948 ]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
        "hidden_states, last_hidden_state, last_cell_state = lstm(train_X)\n",
        "\n",
        "# 모든 시점의 은닉 상태 출력\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "# 마지막 은닉 상태 : 변함 없음\n",
        "print('last hidden state : {}, shape: {}'.format(last_hidden_state, last_hidden_state.shape))\n",
        "# 마지막 셀 상태 : 변함 없음\n",
        "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_d9ATwSWm9c",
        "outputId": "7528c844-4f79-4088-c2c8-63feb802a36f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[ 0.08351671  0.00886141  0.01109783]\n",
            "  [ 0.10525063 -0.00084127  0.03062511]\n",
            "  [ 0.12846053 -0.03663284  0.12857355]\n",
            "  [ 0.14715955 -0.07278625 -0.05700773]]], shape: (1, 4, 3)\n",
            "last hidden state : [[ 0.14715955 -0.07278625 -0.05700773]], shape: (1, 3)\n",
            "last cell state : [[ 0.6150256  -0.4470731  -0.19786358]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bidirectional(LSTM) 이해하기**"
      ],
      "metadata": {
        "id": "sCF50lB4WyPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력되는 은닉 상태의 값 고정\n",
        "k_init = tf.keras.initializers.Constant(value=0.1)\n",
        "b_init = tf.keras.initializers.Constant(value=0)\n",
        "r_init = tf.keras.initializers.Constant(value=0.1)"
      ],
      "metadata": {
        "id": "EPhrK2L6W0To"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences가 False이고, return_state가 True인 경우\n",
        "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\\n",
        "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
        "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
        "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6bi_mWHW4Al",
        "outputId": "f9045535-7663-4b90-c986-686e984b2bfd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[0.6303138 0.6303138 0.6303138 0.7038734 0.7038734 0.7038734]], shape: (1, 6)\n",
            "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
            "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정방향 LSTM의 마지막 시점의 은닉 상태값 : [0.6303139 0.6303139 0.6303139]\n",
        "\n",
        "역방향 LSTM의 첫번째 시점의 은닉 상태값 : [0.70387346 0.70387346 0.70387346]"
      ],
      "metadata": {
        "id": "wPrRSzNTj3ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences를 True\n",
        "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True, \\\n",
        "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
        "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
        "\n",
        "# 모든 시점의 은닉 상태가 출력\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
        "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))\n",
        "\n",
        "# 역방향 LSTM의 첫번째 시점의 은닉 상태\n",
        "# 정방향 LSTM의 마지막 시점의 은닉 상태와 연결 X\n",
        "# 정방향 LSTM의 첫번째 시점의 은닉 상태와 연결"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VILV2ShYj5h9",
        "outputId": "e06e3aa1-0140-40b8-fba9-6577023a590e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
            "  [0.55111325 0.55111325 0.55111325 0.58863586 0.58863586 0.58863586]\n",
            "  [0.59115744 0.59115744 0.59115744 0.3951699  0.3951699  0.3951699 ]\n",
            "  [0.6303138  0.6303138  0.6303138  0.21942244 0.21942244 0.21942244]]], shape: (1, 4, 6)\n",
            "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
            "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN을 이용한 텍스트 생성(Text Generation using RNN)"
      ],
      "metadata": {
        "id": "WN_1bMLfkNHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN을 이용하여 텍스트 생성**"
      ],
      "metadata": {
        "id": "l_mXkAsQkOFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "zDHi_CPfkRTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "# 패딩을 위한 0을 고려하여 +1\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvQzfOrxkQBL",
        "outputId": "e2a75034-3bc3-4955-db97-f4956ceb0313"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어와 단어에 부여된 정수 인덱스 출력\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ2WtQQCm2c5",
        "outputId": "2eda35c0-ca8a-40e0-c657-655eed619ad1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 만들기\n",
        "sequences = list()\n",
        "for line in text.split('\\n'): # 줄바꿈 문자를 기준으로 문장 토큰화\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cidLKldbm6Il",
        "outputId": "232ba7d3-ed17-4522-9262-4570176ea736"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 샘플 출력\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZfqwuHim-HW",
        "outputId": "6443d182-de98-4669-b0d2-ae8f1fde90d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 샘플에 대해서 길이 일치\n",
        "# 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcD-TdaAnBan",
        "outputId": "1696bf89-1e87-4d90-cf83-0975a947336a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 샘플의 길이를 6으로 패딩\n",
        "# pad_sequences() : 모든 샘플에 대해서 0을 사용하여 길이를 맞추기\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "MTw_04XwnHyM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 샘플의 마지막 단어를 레이블로 분리\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "Rq-80_9rnKAG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuidq-mQndhN",
        "outputId": "422bd20a-5183-412c-e7c7-8925c9deb2bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WYgeXtlnejF",
        "outputId": "bd200a75-dadb-4516-aec9-14d7383b1d6a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블에 대해서 원-핫 인코딩을 수행\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpyF06iwngLk",
        "outputId": "b0aade4d-5169-4c59-b08f-488d1ecab75c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 설계"
      ],
      "metadata": {
        "id": "ADU9gs9gnkyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN 모델에 데이터 훈련\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, SimpleRNN\n",
        "\n",
        "# 임베딩 벡터의 차원 : 10\n",
        "embedding_dim = 10\n",
        "# 은닉 상태의 크기 : 32\n",
        "hidden_units = 32\n",
        "\n",
        "# 다 대 일 구조의 RNN\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "# 전결합층(Fully Connected Layer) -> 출력층\n",
        "# 단어 집합 크기만큼의 뉴런을 배치\n",
        "# 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측 -> 다중 클래스 분류 문제\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# 200 에포크를 수행\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax5cF5zVnmI7",
        "outputId": "3a2eb4da-4034-4885-fc33-48c034b28d6c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 2s - loss: 2.5173 - accuracy: 0.0000e+00 - 2s/epoch - 2s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.5042 - accuracy: 0.0000e+00 - 9ms/epoch - 9ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4916 - accuracy: 0.0000e+00 - 9ms/epoch - 9ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4794 - accuracy: 0.0000e+00 - 10ms/epoch - 10ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4675 - accuracy: 0.0000e+00 - 11ms/epoch - 11ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.4558 - accuracy: 0.1818 - 11ms/epoch - 11ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.4441 - accuracy: 0.1818 - 10ms/epoch - 10ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.4323 - accuracy: 0.2727 - 8ms/epoch - 8ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.4204 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.4081 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.3955 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.3824 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.3687 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.3544 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.3394 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.3235 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.3069 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.2893 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.2708 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.2513 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.2308 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.2093 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.1868 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.1634 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 2.1393 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 2.1144 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 2.0891 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 2.0635 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 2.0378 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 2.0124 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.9875 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.9634 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.9402 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.9181 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.8970 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.8766 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.8568 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.8371 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.8171 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.7967 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.7755 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.7537 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.7314 - accuracy: 0.4545 - 12ms/epoch - 12ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.7087 - accuracy: 0.4545 - 11ms/epoch - 11ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.6858 - accuracy: 0.4545 - 14ms/epoch - 14ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.6631 - accuracy: 0.4545 - 11ms/epoch - 11ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.6405 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.6184 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.5965 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.5749 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.5535 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.5322 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.5109 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.4894 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.4680 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.4464 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.4249 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.4035 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.3823 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.3613 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.3405 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.3200 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.2997 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.2797 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.2599 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.2403 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.2208 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.2017 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.1827 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.1640 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.1457 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.1276 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.1099 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.0925 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.0754 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.0586 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 1.0421 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 1.0258 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 1.0099 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 0.9941 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 0.9786 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 0.9634 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.9483 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.9336 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.9190 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.9047 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.8906 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.8768 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.8631 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.8496 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.8363 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.8232 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.8102 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.7974 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.7848 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.7723 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.7600 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.7479 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.7359 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.7240 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.7123 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.7008 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.6894 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.6781 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.6669 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.6559 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.6450 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.6343 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.6236 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.6131 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.6027 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.5924 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.5823 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.5723 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.5624 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.5526 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.5429 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.5334 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.5239 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.5146 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.5054 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.4964 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.4874 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.4786 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.4699 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.4613 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.4528 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.4445 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4363 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.4281 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.4202 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.4123 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.4045 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.3969 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.3894 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.3820 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3747 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3675 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3605 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3536 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3468 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3401 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.3335 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.3270 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.3207 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.3144 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.3083 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.3023 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.2963 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2905 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2848 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2792 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2738 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2684 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2631 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2579 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2528 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2479 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2430 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2382 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2335 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2289 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2244 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2200 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2156 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.2114 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.2072 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.2032 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.1992 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.1953 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.1915 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1877 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1840 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1805 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1769 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1735 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1701 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1668 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1636 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1605 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1574 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1543 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1514 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1485 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1457 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1429 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1402 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1375 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1349 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1324 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1299 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.1275 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.1251 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.1228 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.1205 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.1183 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.1162 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.1140 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.1120 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.1100 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b070811d9f0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력된 단어로부터 다음 단어를 예측해서 문장을 생성하는 함수\n",
        "# # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "def sentence_generation(model, tokenizer, current_word, n):\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "BsDWLXaooEIP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '경마장에', 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUt3x5HPoM1-",
        "outputId": "a76d90c3-b8e9-435d-d1e3-ab0f54302656"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그의', 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCC1pfvjoONT",
        "outputId": "602269cc-a06f-4802-c8b3-e82d86ab2eec"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그의 말이 법이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '가는', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J1fDysvoPTl",
        "outputId": "79541655-3095-4569-eb2b-8384ced068dd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가는 말이 고와야 오는 말이 곱다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM을 이용하여 텍스트 생성하기**"
      ],
      "metadata": {
        "id": "y2myIMk4oSEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "sNUsUYDdoT9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/GDSC/AI ML study/ArticlesApril2018.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "sqNFL6A7oS2g",
        "outputId": "582ba655-c8f8-47e0-e3e3-3f289f2da2db"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  articleID  articleWordCount  \\\n",
              "0  5adf6684068401528a2aa69b               781   \n",
              "1  5adf653f068401528a2aa697               656   \n",
              "2  5adf4626068401528a2aa628              2427   \n",
              "3  5adf40d2068401528a2aa619               626   \n",
              "4  5adf3d64068401528a2aa60f               815   \n",
              "\n",
              "                                      byline documentType  \\\n",
              "0                             By JOHN BRANCH      article   \n",
              "1                           By LISA FRIEDMAN      article   \n",
              "2                              By PETE WELLS      article   \n",
              "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
              "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
              "\n",
              "                                            headline  \\\n",
              "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
              "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
              "2                            The New Noma, Explained   \n",
              "3                                            Unknown   \n",
              "4                                            Unknown   \n",
              "\n",
              "                                            keywords  multimedia     newDesk  \\\n",
              "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
              "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
              "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
              "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
              "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
              "\n",
              "   printPage              pubDate   sectionName  \\\n",
              "0          0  2018-04-24 17:16:49  Pro Football   \n",
              "1          0  2018-04-24 17:11:21       Unknown   \n",
              "2          0  2018-04-24 14:58:44       Unknown   \n",
              "3          0  2018-04-24 14:35:57        Europe   \n",
              "4          0  2018-04-24 14:21:21        Canada   \n",
              "\n",
              "                                             snippet              source  \\\n",
              "0  “I understand that they could meet with us, pa...  The New York Times   \n",
              "1  The agency plans to publish a new regulation T...  The New York Times   \n",
              "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
              "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
              "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
              "\n",
              "  typeOfMaterial                                             webURL  \n",
              "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
              "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
              "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
              "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
              "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3462fe0-6d5d-411e-b044-6da712cb3947\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3462fe0-6d5d-411e-b044-6da712cb3947')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3462fe0-6d5d-411e-b044-6da712cb3947 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3462fe0-6d5d-411e-b044-6da712cb3947');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acad5174-1bf2-4f18-a505-59bd1ecc93b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acad5174-1bf2-4f18-a505-59bd1ecc93b2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acad5174-1bf2-4f18-a505-59bd1ecc93b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline = []\n",
        "# headline 열에서 모든 신문 기사의 제목을 뽑아서 하나의 리스트로 저장\n",
        "headline.extend(list(df.headline.values))\n",
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vg33Gz_o0KB",
        "outputId": "a6359b1f-ec2d-44c7-91e1-9df05cd893e8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 노이즈 데이터 제거\n",
        "print('총 샘플의 개수 : {}'.format(len(headline)))\n",
        "\n",
        "headline = [word for word in headline if word != \"Unknown\"]\n",
        "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2OT40DQo8EA",
        "outputId": "b5d8c6ad-6d07-4379-cba0-8a377907101e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 1324\n",
            "노이즈값 제거 후 샘플의 개수 : 1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9bNGzvYpCQN",
        "outputId": "78845480-47b5-45d3-f21c-e296ae29fede"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
              " 'Is School a Place for Self-Expression?']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구두점 제거와 단어의 소문자화\n",
        "def repreprocessing(raw_sentence):\n",
        "    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    # 구두점 제거와 동시에 소문자화\n",
        "    return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n",
        "\n",
        "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
        "preprocessed_headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E66hh34spEFM",
        "outputId": "b20bd1c4-778b-4444-89bf-32231f9b4566"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합(vocabulary)을 만들고 크기 확인\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_headline)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UCFnCLPpJLO",
        "outputId": "4b8ec187-51c3-48c8-ee29-8fe9879fc7f1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 3494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3,494개의 단어가 존재\n",
        "# 정수 인코딩을 진행\n",
        "# 하나의 문장을 여러 줄로 분해\n",
        "sequences = list()\n",
        "\n",
        "for sentence in preprocessed_headline:\n",
        "\n",
        "    # 각 샘플에 대한 정수 인코딩\n",
        "    encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Llwq90vKpM3M",
        "outputId": "91be7fdc-489f-4251-fd50-d5dc3be26595"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[[99, 269], # former nfl\n",
        "\n",
        " [99, 269, 371], # former nfl cheerleaders\n",
        "\n",
        " [99, 269, 371, 1115], # former nfl cheerleaders settlement\n",
        "\n",
        " [99, 269, 371, 1115, 582], # former nfl cheerleaders settlement offer\n",
        "\n",
        " [99, 269, 371, 1115, 582, 52], # 'former nfl cheerleaders settlement offer 1\n",
        "\n",
        " [99, 269, 371, 1115, 582, 52, 7], # former nfl cheerleaders settlement offer 1 and\n",
        "\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2], # ... 이하 생략 ...\n",
        "\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
        "\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
        "\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116], # 모든 단어가 사용된 완전한 첫번째 문장\n",
        "\n",
        "바로 위의 줄은 : former nfl cheerleaders settlement offer 1 and a meeting with goodell\n",
        "\n",
        " [100, 3]] # epa to에 해당되며 두번째 문장이 시작됨."
      ],
      "metadata": {
        "id": "vBcLfPoEpUQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "CHgh1jDNpqDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "= 각 단어가 각 시점(time step)마다 하나씩 추가적으로 등장하는 형태\n",
        "\n",
        "예측할 단어에 해당되는 레이블을 분리하는 작업 X"
      ],
      "metadata": {
        "id": "DjJ4FK4kpwJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 어떤 정수가 어떤 단어를 의미하는지 알아보기\n",
        "# 인덱스로부터 단어를 찾는 index_to_word 만들기\n",
        "index_to_word = {}\n",
        "for key, value in tokenizer.word_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
        "    index_to_word[value] = key\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsZACYCypcCv",
        "outputId": "0ab8d84f-83ef-4969-bdee-63f8128103ed"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 582번 단어 : offer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 샘플의 길이를 동일하게 만드는 패딩 작업을 수행\n",
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))\n",
        "\n",
        "# 가장 긴 샘플의 길이인 24로 모든 샘플의 길이를 패딩\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozJLRj1rp-Sd",
        "outputId": "483061be-3617-42e3-d37d-3386b35fc698"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 24\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 우측 단어만 레이블로 분리\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]\n",
        "\n",
        "print(X[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOukHJM0qFtM",
        "outputId": "40fdcd22-f1cb-4076-b211-c11415da672c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  99 269]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  99 269 371]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plu1baDtqL4m",
        "outputId": "78218090-3872-4272-b12c-1377381f522b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 269  371 1115]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 데이터 y에 대해서 원-핫 인코딩을 수행\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "ya91CQGPrcvE"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> 기존 훈련 데이터에서 맨 우측에 있던 정수들이 별도로 저장됨"
      ],
      "metadata": {
        "id": "s9ptFGDHqN4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 설계"
      ],
      "metadata": {
        "id": "zIwLG0WUqQgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, LSTM\n",
        "\n",
        "# 임베딩 벡터의 차원은 10\n",
        "embedding_dim = 10\n",
        "# 은닉 상태의 크기는 128\n",
        "hidden_units = 128\n",
        "\n",
        "# 다 대 일 구조의 LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "# 전결합층(Fully Connected Layer) -> 출력층\n",
        "# 단어 집합 크기만큼의 뉴런을 배치\n",
        "# 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측 -> 다중 클래스 분류 문제\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upZExrmQqPb2",
        "outputId": "f504cf6f-1844-4dbd-a76f-8ed102f816f7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 16s - loss: 7.6395 - accuracy: 0.0279 - 16s/epoch - 66ms/step\n",
            "Epoch 2/200\n",
            "244/244 - 13s - loss: 7.1144 - accuracy: 0.0288 - 13s/epoch - 55ms/step\n",
            "Epoch 3/200\n",
            "244/244 - 12s - loss: 6.9761 - accuracy: 0.0361 - 12s/epoch - 50ms/step\n",
            "Epoch 4/200\n",
            "244/244 - 14s - loss: 6.8444 - accuracy: 0.0405 - 14s/epoch - 58ms/step\n",
            "Epoch 5/200\n",
            "244/244 - 11s - loss: 6.6867 - accuracy: 0.0452 - 11s/epoch - 46ms/step\n",
            "Epoch 6/200\n",
            "244/244 - 11s - loss: 6.5262 - accuracy: 0.0511 - 11s/epoch - 47ms/step\n",
            "Epoch 7/200\n",
            "244/244 - 11s - loss: 6.3414 - accuracy: 0.0523 - 11s/epoch - 46ms/step\n",
            "Epoch 8/200\n",
            "244/244 - 9s - loss: 6.1469 - accuracy: 0.0564 - 9s/epoch - 37ms/step\n",
            "Epoch 9/200\n",
            "244/244 - 11s - loss: 5.9661 - accuracy: 0.0627 - 11s/epoch - 46ms/step\n",
            "Epoch 10/200\n",
            "244/244 - 13s - loss: 5.7897 - accuracy: 0.0632 - 13s/epoch - 52ms/step\n",
            "Epoch 11/200\n",
            "244/244 - 11s - loss: 5.6195 - accuracy: 0.0684 - 11s/epoch - 47ms/step\n",
            "Epoch 12/200\n",
            "244/244 - 12s - loss: 5.4492 - accuracy: 0.0751 - 12s/epoch - 48ms/step\n",
            "Epoch 13/200\n",
            "244/244 - 13s - loss: 5.2897 - accuracy: 0.0827 - 13s/epoch - 53ms/step\n",
            "Epoch 14/200\n",
            "244/244 - 14s - loss: 5.1365 - accuracy: 0.0886 - 14s/epoch - 58ms/step\n",
            "Epoch 15/200\n",
            "244/244 - 15s - loss: 4.9895 - accuracy: 0.0983 - 15s/epoch - 62ms/step\n",
            "Epoch 16/200\n",
            "244/244 - 13s - loss: 4.8463 - accuracy: 0.1064 - 13s/epoch - 52ms/step\n",
            "Epoch 17/200\n",
            "244/244 - 11s - loss: 4.7118 - accuracy: 0.1180 - 11s/epoch - 46ms/step\n",
            "Epoch 18/200\n",
            "244/244 - 12s - loss: 4.5818 - accuracy: 0.1323 - 12s/epoch - 49ms/step\n",
            "Epoch 19/200\n",
            "244/244 - 11s - loss: 4.4553 - accuracy: 0.1485 - 11s/epoch - 47ms/step\n",
            "Epoch 20/200\n",
            "244/244 - 17s - loss: 4.3356 - accuracy: 0.1607 - 17s/epoch - 70ms/step\n",
            "Epoch 21/200\n",
            "244/244 - 9s - loss: 4.2175 - accuracy: 0.1781 - 9s/epoch - 38ms/step\n",
            "Epoch 22/200\n",
            "244/244 - 11s - loss: 4.1039 - accuracy: 0.1974 - 11s/epoch - 46ms/step\n",
            "Epoch 23/200\n",
            "244/244 - 17s - loss: 3.9916 - accuracy: 0.2149 - 17s/epoch - 69ms/step\n",
            "Epoch 24/200\n",
            "244/244 - 13s - loss: 3.8846 - accuracy: 0.2311 - 13s/epoch - 54ms/step\n",
            "Epoch 25/200\n",
            "244/244 - 13s - loss: 3.7808 - accuracy: 0.2488 - 13s/epoch - 53ms/step\n",
            "Epoch 26/200\n",
            "244/244 - 13s - loss: 3.6813 - accuracy: 0.2644 - 13s/epoch - 54ms/step\n",
            "Epoch 27/200\n",
            "244/244 - 12s - loss: 3.5818 - accuracy: 0.2860 - 12s/epoch - 50ms/step\n",
            "Epoch 28/200\n",
            "244/244 - 12s - loss: 3.4868 - accuracy: 0.3004 - 12s/epoch - 48ms/step\n",
            "Epoch 29/200\n",
            "244/244 - 16s - loss: 3.3952 - accuracy: 0.3168 - 16s/epoch - 67ms/step\n",
            "Epoch 30/200\n",
            "244/244 - 13s - loss: 3.3065 - accuracy: 0.3336 - 13s/epoch - 52ms/step\n",
            "Epoch 31/200\n",
            "244/244 - 13s - loss: 3.2201 - accuracy: 0.3464 - 13s/epoch - 55ms/step\n",
            "Epoch 32/200\n",
            "244/244 - 15s - loss: 3.1375 - accuracy: 0.3619 - 15s/epoch - 60ms/step\n",
            "Epoch 33/200\n",
            "244/244 - 15s - loss: 3.0558 - accuracy: 0.3737 - 15s/epoch - 63ms/step\n",
            "Epoch 34/200\n",
            "244/244 - 12s - loss: 2.9787 - accuracy: 0.3897 - 12s/epoch - 49ms/step\n",
            "Epoch 35/200\n",
            "244/244 - 14s - loss: 2.9046 - accuracy: 0.4045 - 14s/epoch - 56ms/step\n",
            "Epoch 36/200\n",
            "244/244 - 15s - loss: 2.8297 - accuracy: 0.4136 - 15s/epoch - 60ms/step\n",
            "Epoch 37/200\n",
            "244/244 - 15s - loss: 2.7592 - accuracy: 0.4339 - 15s/epoch - 63ms/step\n",
            "Epoch 38/200\n",
            "244/244 - 13s - loss: 2.6894 - accuracy: 0.4462 - 13s/epoch - 53ms/step\n",
            "Epoch 39/200\n",
            "244/244 - 15s - loss: 2.6253 - accuracy: 0.4565 - 15s/epoch - 62ms/step\n",
            "Epoch 40/200\n",
            "244/244 - 14s - loss: 2.5565 - accuracy: 0.4753 - 14s/epoch - 55ms/step\n",
            "Epoch 41/200\n",
            "244/244 - 12s - loss: 2.4967 - accuracy: 0.4842 - 12s/epoch - 48ms/step\n",
            "Epoch 42/200\n",
            "244/244 - 16s - loss: 2.4369 - accuracy: 0.4942 - 16s/epoch - 65ms/step\n",
            "Epoch 43/200\n",
            "244/244 - 11s - loss: 2.3775 - accuracy: 0.5084 - 11s/epoch - 46ms/step\n",
            "Epoch 44/200\n",
            "244/244 - 13s - loss: 2.3197 - accuracy: 0.5243 - 13s/epoch - 54ms/step\n",
            "Epoch 45/200\n",
            "244/244 - 18s - loss: 2.2621 - accuracy: 0.5351 - 18s/epoch - 73ms/step\n",
            "Epoch 46/200\n",
            "244/244 - 13s - loss: 2.2094 - accuracy: 0.5433 - 13s/epoch - 52ms/step\n",
            "Epoch 47/200\n",
            "244/244 - 16s - loss: 2.1554 - accuracy: 0.5562 - 16s/epoch - 65ms/step\n",
            "Epoch 48/200\n",
            "244/244 - 14s - loss: 2.1036 - accuracy: 0.5671 - 14s/epoch - 56ms/step\n",
            "Epoch 49/200\n",
            "244/244 - 14s - loss: 2.0521 - accuracy: 0.5775 - 14s/epoch - 59ms/step\n",
            "Epoch 50/200\n",
            "244/244 - 13s - loss: 2.0043 - accuracy: 0.5914 - 13s/epoch - 52ms/step\n",
            "Epoch 51/200\n",
            "244/244 - 15s - loss: 1.9562 - accuracy: 0.5985 - 15s/epoch - 62ms/step\n",
            "Epoch 52/200\n",
            "244/244 - 15s - loss: 1.9089 - accuracy: 0.6112 - 15s/epoch - 62ms/step\n",
            "Epoch 53/200\n",
            "244/244 - 12s - loss: 1.8629 - accuracy: 0.6242 - 12s/epoch - 49ms/step\n",
            "Epoch 54/200\n",
            "244/244 - 16s - loss: 1.8223 - accuracy: 0.6277 - 16s/epoch - 67ms/step\n",
            "Epoch 55/200\n",
            "244/244 - 15s - loss: 1.7782 - accuracy: 0.6385 - 15s/epoch - 63ms/step\n",
            "Epoch 56/200\n",
            "244/244 - 14s - loss: 1.7348 - accuracy: 0.6485 - 14s/epoch - 56ms/step\n",
            "Epoch 57/200\n",
            "244/244 - 13s - loss: 1.6964 - accuracy: 0.6531 - 13s/epoch - 53ms/step\n",
            "Epoch 58/200\n",
            "244/244 - 14s - loss: 1.6536 - accuracy: 0.6665 - 14s/epoch - 58ms/step\n",
            "Epoch 59/200\n",
            "244/244 - 14s - loss: 1.6157 - accuracy: 0.6758 - 14s/epoch - 59ms/step\n",
            "Epoch 60/200\n",
            "244/244 - 16s - loss: 1.5786 - accuracy: 0.6886 - 16s/epoch - 67ms/step\n",
            "Epoch 61/200\n",
            "244/244 - 14s - loss: 1.5376 - accuracy: 0.6928 - 14s/epoch - 58ms/step\n",
            "Epoch 62/200\n",
            "244/244 - 13s - loss: 1.5065 - accuracy: 0.6954 - 13s/epoch - 54ms/step\n",
            "Epoch 63/200\n",
            "244/244 - 14s - loss: 1.4695 - accuracy: 0.7056 - 14s/epoch - 57ms/step\n",
            "Epoch 64/200\n",
            "244/244 - 15s - loss: 1.4337 - accuracy: 0.7165 - 15s/epoch - 61ms/step\n",
            "Epoch 65/200\n",
            "244/244 - 9s - loss: 1.4022 - accuracy: 0.7215 - 9s/epoch - 38ms/step\n",
            "Epoch 66/200\n",
            "244/244 - 11s - loss: 1.3682 - accuracy: 0.7281 - 11s/epoch - 46ms/step\n",
            "Epoch 67/200\n",
            "244/244 - 11s - loss: 1.3353 - accuracy: 0.7351 - 11s/epoch - 46ms/step\n",
            "Epoch 68/200\n",
            "244/244 - 11s - loss: 1.3036 - accuracy: 0.7413 - 11s/epoch - 44ms/step\n",
            "Epoch 69/200\n",
            "244/244 - 9s - loss: 1.2730 - accuracy: 0.7465 - 9s/epoch - 38ms/step\n",
            "Epoch 70/200\n",
            "244/244 - 11s - loss: 1.2453 - accuracy: 0.7532 - 11s/epoch - 46ms/step\n",
            "Epoch 71/200\n",
            "244/244 - 11s - loss: 1.2139 - accuracy: 0.7612 - 11s/epoch - 46ms/step\n",
            "Epoch 72/200\n",
            "244/244 - 10s - loss: 1.1877 - accuracy: 0.7650 - 10s/epoch - 41ms/step\n",
            "Epoch 73/200\n",
            "244/244 - 10s - loss: 1.1579 - accuracy: 0.7709 - 10s/epoch - 43ms/step\n",
            "Epoch 74/200\n",
            "244/244 - 11s - loss: 1.1295 - accuracy: 0.7773 - 11s/epoch - 46ms/step\n",
            "Epoch 75/200\n",
            "244/244 - 11s - loss: 1.1040 - accuracy: 0.7810 - 11s/epoch - 47ms/step\n",
            "Epoch 76/200\n",
            "244/244 - 9s - loss: 1.0773 - accuracy: 0.7891 - 9s/epoch - 38ms/step\n",
            "Epoch 77/200\n",
            "244/244 - 11s - loss: 1.0505 - accuracy: 0.7917 - 11s/epoch - 47ms/step\n",
            "Epoch 78/200\n",
            "244/244 - 11s - loss: 1.0287 - accuracy: 0.7957 - 11s/epoch - 47ms/step\n",
            "Epoch 79/200\n",
            "244/244 - 11s - loss: 1.0035 - accuracy: 0.8002 - 11s/epoch - 46ms/step\n",
            "Epoch 80/200\n",
            "244/244 - 9s - loss: 0.9791 - accuracy: 0.8073 - 9s/epoch - 38ms/step\n",
            "Epoch 81/200\n",
            "244/244 - 11s - loss: 0.9586 - accuracy: 0.8082 - 11s/epoch - 46ms/step\n",
            "Epoch 82/200\n",
            "244/244 - 11s - loss: 0.9388 - accuracy: 0.8143 - 11s/epoch - 46ms/step\n",
            "Epoch 83/200\n",
            "244/244 - 11s - loss: 0.9150 - accuracy: 0.8176 - 11s/epoch - 43ms/step\n",
            "Epoch 84/200\n",
            "244/244 - 10s - loss: 0.8913 - accuracy: 0.8228 - 10s/epoch - 40ms/step\n",
            "Epoch 85/200\n",
            "244/244 - 11s - loss: 0.8707 - accuracy: 0.8251 - 11s/epoch - 46ms/step\n",
            "Epoch 86/200\n",
            "244/244 - 11s - loss: 0.8525 - accuracy: 0.8298 - 11s/epoch - 46ms/step\n",
            "Epoch 87/200\n",
            "244/244 - 9s - loss: 0.8326 - accuracy: 0.8322 - 9s/epoch - 39ms/step\n",
            "Epoch 88/200\n",
            "244/244 - 11s - loss: 0.8187 - accuracy: 0.8375 - 11s/epoch - 45ms/step\n",
            "Epoch 89/200\n",
            "244/244 - 11s - loss: 0.7949 - accuracy: 0.8428 - 11s/epoch - 46ms/step\n",
            "Epoch 90/200\n",
            "244/244 - 11s - loss: 0.7781 - accuracy: 0.8401 - 11s/epoch - 46ms/step\n",
            "Epoch 91/200\n",
            "244/244 - 9s - loss: 0.7589 - accuracy: 0.8495 - 9s/epoch - 37ms/step\n",
            "Epoch 92/200\n",
            "244/244 - 11s - loss: 0.7437 - accuracy: 0.8513 - 11s/epoch - 46ms/step\n",
            "Epoch 93/200\n",
            "244/244 - 11s - loss: 0.7255 - accuracy: 0.8549 - 11s/epoch - 46ms/step\n",
            "Epoch 94/200\n",
            "244/244 - 11s - loss: 0.7111 - accuracy: 0.8557 - 11s/epoch - 44ms/step\n",
            "Epoch 95/200\n",
            "244/244 - 10s - loss: 0.6956 - accuracy: 0.8615 - 10s/epoch - 39ms/step\n",
            "Epoch 96/200\n",
            "244/244 - 11s - loss: 0.6826 - accuracy: 0.8625 - 11s/epoch - 46ms/step\n",
            "Epoch 97/200\n",
            "244/244 - 11s - loss: 0.6667 - accuracy: 0.8662 - 11s/epoch - 46ms/step\n",
            "Epoch 98/200\n",
            "244/244 - 10s - loss: 0.6523 - accuracy: 0.8663 - 10s/epoch - 41ms/step\n",
            "Epoch 99/200\n",
            "244/244 - 10s - loss: 0.6374 - accuracy: 0.8685 - 10s/epoch - 43ms/step\n",
            "Epoch 100/200\n",
            "244/244 - 11s - loss: 0.6300 - accuracy: 0.8721 - 11s/epoch - 46ms/step\n",
            "Epoch 101/200\n",
            "244/244 - 11s - loss: 0.6128 - accuracy: 0.8756 - 11s/epoch - 46ms/step\n",
            "Epoch 102/200\n",
            "244/244 - 10s - loss: 0.6029 - accuracy: 0.8747 - 10s/epoch - 39ms/step\n",
            "Epoch 103/200\n",
            "244/244 - 11s - loss: 0.5858 - accuracy: 0.8780 - 11s/epoch - 46ms/step\n",
            "Epoch 104/200\n",
            "244/244 - 12s - loss: 0.5752 - accuracy: 0.8812 - 12s/epoch - 47ms/step\n",
            "Epoch 105/200\n",
            "244/244 - 11s - loss: 0.5624 - accuracy: 0.8815 - 11s/epoch - 47ms/step\n",
            "Epoch 106/200\n",
            "244/244 - 9s - loss: 0.5504 - accuracy: 0.8854 - 9s/epoch - 37ms/step\n",
            "Epoch 107/200\n",
            "244/244 - 11s - loss: 0.5392 - accuracy: 0.8872 - 11s/epoch - 46ms/step\n",
            "Epoch 108/200\n",
            "244/244 - 11s - loss: 0.5304 - accuracy: 0.8897 - 11s/epoch - 47ms/step\n",
            "Epoch 109/200\n",
            "244/244 - 11s - loss: 0.5210 - accuracy: 0.8918 - 11s/epoch - 46ms/step\n",
            "Epoch 110/200\n",
            "244/244 - 9s - loss: 0.5070 - accuracy: 0.8926 - 9s/epoch - 37ms/step\n",
            "Epoch 111/200\n",
            "244/244 - 11s - loss: 0.4986 - accuracy: 0.8927 - 11s/epoch - 46ms/step\n",
            "Epoch 112/200\n",
            "244/244 - 11s - loss: 0.4900 - accuracy: 0.8949 - 11s/epoch - 45ms/step\n",
            "Epoch 113/200\n",
            "244/244 - 10s - loss: 0.4820 - accuracy: 0.8958 - 10s/epoch - 40ms/step\n",
            "Epoch 114/200\n",
            "244/244 - 11s - loss: 0.4739 - accuracy: 0.8968 - 11s/epoch - 43ms/step\n",
            "Epoch 115/200\n",
            "244/244 - 11s - loss: 0.4649 - accuracy: 0.8972 - 11s/epoch - 46ms/step\n",
            "Epoch 116/200\n",
            "244/244 - 11s - loss: 0.4591 - accuracy: 0.9003 - 11s/epoch - 46ms/step\n",
            "Epoch 117/200\n",
            "244/244 - 9s - loss: 0.4521 - accuracy: 0.9018 - 9s/epoch - 37ms/step\n",
            "Epoch 118/200\n",
            "244/244 - 11s - loss: 0.4725 - accuracy: 0.8986 - 11s/epoch - 45ms/step\n",
            "Epoch 119/200\n",
            "244/244 - 11s - loss: 0.4465 - accuracy: 0.9022 - 11s/epoch - 46ms/step\n",
            "Epoch 120/200\n",
            "244/244 - 11s - loss: 0.4259 - accuracy: 0.9048 - 11s/epoch - 45ms/step\n",
            "Epoch 121/200\n",
            "244/244 - 9s - loss: 0.4185 - accuracy: 0.9053 - 9s/epoch - 39ms/step\n",
            "Epoch 122/200\n",
            "244/244 - 11s - loss: 0.4094 - accuracy: 0.9077 - 11s/epoch - 46ms/step\n",
            "Epoch 123/200\n",
            "244/244 - 11s - loss: 0.4044 - accuracy: 0.9084 - 11s/epoch - 46ms/step\n",
            "Epoch 124/200\n",
            "244/244 - 10s - loss: 0.4012 - accuracy: 0.9085 - 10s/epoch - 40ms/step\n",
            "Epoch 125/200\n",
            "244/244 - 11s - loss: 0.3944 - accuracy: 0.9076 - 11s/epoch - 43ms/step\n",
            "Epoch 126/200\n",
            "244/244 - 11s - loss: 0.3939 - accuracy: 0.9102 - 11s/epoch - 47ms/step\n",
            "Epoch 127/200\n",
            "244/244 - 11s - loss: 0.3882 - accuracy: 0.9088 - 11s/epoch - 46ms/step\n",
            "Epoch 128/200\n",
            "244/244 - 9s - loss: 0.3790 - accuracy: 0.9099 - 9s/epoch - 37ms/step\n",
            "Epoch 129/200\n",
            "244/244 - 11s - loss: 0.3752 - accuracy: 0.9122 - 11s/epoch - 45ms/step\n",
            "Epoch 130/200\n",
            "244/244 - 11s - loss: 0.3692 - accuracy: 0.9122 - 11s/epoch - 46ms/step\n",
            "Epoch 131/200\n",
            "244/244 - 11s - loss: 0.3638 - accuracy: 0.9129 - 11s/epoch - 46ms/step\n",
            "Epoch 132/200\n",
            "244/244 - 9s - loss: 0.3603 - accuracy: 0.9116 - 9s/epoch - 37ms/step\n",
            "Epoch 133/200\n",
            "244/244 - 11s - loss: 0.3547 - accuracy: 0.9150 - 11s/epoch - 47ms/step\n",
            "Epoch 134/200\n",
            "244/244 - 11s - loss: 0.3511 - accuracy: 0.9132 - 11s/epoch - 47ms/step\n",
            "Epoch 135/200\n",
            "244/244 - 11s - loss: 0.3468 - accuracy: 0.9134 - 11s/epoch - 44ms/step\n",
            "Epoch 136/200\n",
            "244/244 - 10s - loss: 0.3449 - accuracy: 0.9143 - 10s/epoch - 40ms/step\n",
            "Epoch 137/200\n",
            "244/244 - 11s - loss: 0.3507 - accuracy: 0.9135 - 11s/epoch - 46ms/step\n",
            "Epoch 138/200\n",
            "244/244 - 11s - loss: 0.3710 - accuracy: 0.9113 - 11s/epoch - 46ms/step\n",
            "Epoch 139/200\n",
            "244/244 - 10s - loss: 0.3457 - accuracy: 0.9138 - 10s/epoch - 40ms/step\n",
            "Epoch 140/200\n",
            "244/244 - 11s - loss: 0.3323 - accuracy: 0.9163 - 11s/epoch - 44ms/step\n",
            "Epoch 141/200\n",
            "244/244 - 11s - loss: 0.3279 - accuracy: 0.9146 - 11s/epoch - 46ms/step\n",
            "Epoch 142/200\n",
            "244/244 - 11s - loss: 0.3224 - accuracy: 0.9154 - 11s/epoch - 47ms/step\n",
            "Epoch 143/200\n",
            "244/244 - 10s - loss: 0.3205 - accuracy: 0.9144 - 10s/epoch - 40ms/step\n",
            "Epoch 144/200\n",
            "244/244 - 11s - loss: 0.3212 - accuracy: 0.9158 - 11s/epoch - 45ms/step\n",
            "Epoch 145/200\n",
            "244/244 - 11s - loss: 0.3175 - accuracy: 0.9164 - 11s/epoch - 47ms/step\n",
            "Epoch 146/200\n",
            "244/244 - 12s - loss: 0.3133 - accuracy: 0.9155 - 12s/epoch - 47ms/step\n",
            "Epoch 147/200\n",
            "244/244 - 9s - loss: 0.3117 - accuracy: 0.9161 - 9s/epoch - 37ms/step\n",
            "Epoch 148/200\n",
            "244/244 - 11s - loss: 0.3136 - accuracy: 0.9170 - 11s/epoch - 46ms/step\n",
            "Epoch 149/200\n",
            "244/244 - 11s - loss: 0.3108 - accuracy: 0.9154 - 11s/epoch - 46ms/step\n",
            "Epoch 150/200\n",
            "244/244 - 11s - loss: 0.3061 - accuracy: 0.9164 - 11s/epoch - 45ms/step\n",
            "Epoch 151/200\n",
            "244/244 - 9s - loss: 0.3029 - accuracy: 0.9175 - 9s/epoch - 38ms/step\n",
            "Epoch 152/200\n",
            "244/244 - 11s - loss: 0.3024 - accuracy: 0.9164 - 11s/epoch - 46ms/step\n",
            "Epoch 153/200\n",
            "244/244 - 11s - loss: 0.3026 - accuracy: 0.9164 - 11s/epoch - 46ms/step\n",
            "Epoch 154/200\n",
            "244/244 - 10s - loss: 0.3031 - accuracy: 0.9173 - 10s/epoch - 40ms/step\n",
            "Epoch 155/200\n",
            "244/244 - 11s - loss: 0.2993 - accuracy: 0.9168 - 11s/epoch - 44ms/step\n",
            "Epoch 156/200\n",
            "244/244 - 11s - loss: 0.2952 - accuracy: 0.9168 - 11s/epoch - 46ms/step\n",
            "Epoch 157/200\n",
            "244/244 - 11s - loss: 0.2944 - accuracy: 0.9158 - 11s/epoch - 46ms/step\n",
            "Epoch 158/200\n",
            "244/244 - 9s - loss: 0.2919 - accuracy: 0.9161 - 9s/epoch - 37ms/step\n",
            "Epoch 159/200\n",
            "244/244 - 11s - loss: 0.2903 - accuracy: 0.9168 - 11s/epoch - 46ms/step\n",
            "Epoch 160/200\n",
            "244/244 - 11s - loss: 0.2903 - accuracy: 0.9163 - 11s/epoch - 46ms/step\n",
            "Epoch 161/200\n",
            "244/244 - 11s - loss: 0.3009 - accuracy: 0.9132 - 11s/epoch - 44ms/step\n",
            "Epoch 162/200\n",
            "244/244 - 10s - loss: 0.3004 - accuracy: 0.9157 - 10s/epoch - 39ms/step\n",
            "Epoch 163/200\n",
            "244/244 - 11s - loss: 0.2890 - accuracy: 0.9167 - 11s/epoch - 47ms/step\n",
            "Epoch 164/200\n",
            "244/244 - 11s - loss: 0.2844 - accuracy: 0.9162 - 11s/epoch - 46ms/step\n",
            "Epoch 165/200\n",
            "244/244 - 10s - loss: 0.2830 - accuracy: 0.9154 - 10s/epoch - 41ms/step\n",
            "Epoch 166/200\n",
            "244/244 - 10s - loss: 0.2814 - accuracy: 0.9157 - 10s/epoch - 42ms/step\n",
            "Epoch 167/200\n",
            "244/244 - 11s - loss: 0.2815 - accuracy: 0.9162 - 11s/epoch - 46ms/step\n",
            "Epoch 168/200\n",
            "244/244 - 11s - loss: 0.2808 - accuracy: 0.9158 - 11s/epoch - 46ms/step\n",
            "Epoch 169/200\n",
            "244/244 - 9s - loss: 0.2801 - accuracy: 0.9163 - 9s/epoch - 37ms/step\n",
            "Epoch 170/200\n",
            "244/244 - 11s - loss: 0.2787 - accuracy: 0.9175 - 11s/epoch - 46ms/step\n",
            "Epoch 171/200\n",
            "244/244 - 11s - loss: 0.2779 - accuracy: 0.9153 - 11s/epoch - 46ms/step\n",
            "Epoch 172/200\n",
            "244/244 - 11s - loss: 0.2765 - accuracy: 0.9159 - 11s/epoch - 45ms/step\n",
            "Epoch 173/200\n",
            "244/244 - 9s - loss: 0.2758 - accuracy: 0.9163 - 9s/epoch - 38ms/step\n",
            "Epoch 174/200\n",
            "244/244 - 11s - loss: 0.2754 - accuracy: 0.9158 - 11s/epoch - 46ms/step\n",
            "Epoch 175/200\n",
            "244/244 - 11s - loss: 0.2746 - accuracy: 0.9172 - 11s/epoch - 46ms/step\n",
            "Epoch 176/200\n",
            "244/244 - 10s - loss: 0.2730 - accuracy: 0.9167 - 10s/epoch - 41ms/step\n",
            "Epoch 177/200\n",
            "244/244 - 10s - loss: 0.2759 - accuracy: 0.9153 - 10s/epoch - 42ms/step\n",
            "Epoch 178/200\n",
            "244/244 - 11s - loss: 0.2874 - accuracy: 0.9150 - 11s/epoch - 46ms/step\n",
            "Epoch 179/200\n",
            "244/244 - 11s - loss: 0.2897 - accuracy: 0.9136 - 11s/epoch - 46ms/step\n",
            "Epoch 180/200\n",
            "244/244 - 9s - loss: 0.2770 - accuracy: 0.9153 - 9s/epoch - 38ms/step\n",
            "Epoch 181/200\n",
            "244/244 - 12s - loss: 0.2708 - accuracy: 0.9161 - 12s/epoch - 47ms/step\n",
            "Epoch 182/200\n",
            "244/244 - 11s - loss: 0.2699 - accuracy: 0.9168 - 11s/epoch - 46ms/step\n",
            "Epoch 183/200\n",
            "244/244 - 11s - loss: 0.2682 - accuracy: 0.9161 - 11s/epoch - 47ms/step\n",
            "Epoch 184/200\n",
            "244/244 - 9s - loss: 0.2672 - accuracy: 0.9179 - 9s/epoch - 38ms/step\n",
            "Epoch 185/200\n",
            "244/244 - 11s - loss: 0.2691 - accuracy: 0.9163 - 11s/epoch - 46ms/step\n",
            "Epoch 186/200\n",
            "244/244 - 11s - loss: 0.2665 - accuracy: 0.9162 - 11s/epoch - 47ms/step\n",
            "Epoch 187/200\n",
            "244/244 - 11s - loss: 0.2674 - accuracy: 0.9150 - 11s/epoch - 43ms/step\n",
            "Epoch 188/200\n",
            "244/244 - 10s - loss: 0.2673 - accuracy: 0.9170 - 10s/epoch - 40ms/step\n",
            "Epoch 189/200\n",
            "244/244 - 11s - loss: 0.2670 - accuracy: 0.9170 - 11s/epoch - 47ms/step\n",
            "Epoch 190/200\n",
            "244/244 - 11s - loss: 0.2666 - accuracy: 0.9166 - 11s/epoch - 46ms/step\n",
            "Epoch 191/200\n",
            "244/244 - 9s - loss: 0.2657 - accuracy: 0.9150 - 9s/epoch - 38ms/step\n",
            "Epoch 192/200\n",
            "244/244 - 11s - loss: 0.2645 - accuracy: 0.9175 - 11s/epoch - 44ms/step\n",
            "Epoch 193/200\n",
            "244/244 - 11s - loss: 0.2668 - accuracy: 0.9157 - 11s/epoch - 46ms/step\n",
            "Epoch 194/200\n",
            "244/244 - 11s - loss: 0.2654 - accuracy: 0.9153 - 11s/epoch - 46ms/step\n",
            "Epoch 195/200\n",
            "244/244 - 9s - loss: 0.2665 - accuracy: 0.9168 - 9s/epoch - 37ms/step\n",
            "Epoch 196/200\n",
            "244/244 - 11s - loss: 0.2647 - accuracy: 0.9161 - 11s/epoch - 46ms/step\n",
            "Epoch 197/200\n",
            "244/244 - 11s - loss: 0.2644 - accuracy: 0.9168 - 11s/epoch - 46ms/step\n",
            "Epoch 198/200\n",
            "244/244 - 10s - loss: 0.2789 - accuracy: 0.9148 - 10s/epoch - 42ms/step\n",
            "Epoch 199/200\n",
            "244/244 - 10s - loss: 0.2679 - accuracy: 0.9167 - 10s/epoch - 41ms/step\n",
            "Epoch 200/200\n",
            "244/244 - 11s - loss: 0.2626 - accuracy: 0.9168 - 11s/epoch - 46ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b070070db10>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 생성하는 함수\n",
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "q4Hts6LVrilp"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, 'i', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrLjChMRrmF4",
        "outputId": "48b14b5f-7181-4de2-eefd-703a4fbb7315"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i cant jump ship from facebook yet them of syria slippery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, 'how', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pygs15CKrnGl",
        "outputId": "4986544c-1364-4755-cc6e-8e7104f17290"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how to make a crossword puzzle come to the furor koreas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문자 단위 RNN(Char RNN)"
      ],
      "metadata": {
        "id": "3Ek1Ha_OrpaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문자 단위 RNN 언어 모델(Char RNNLM)**"
      ],
      "metadata": {
        "id": "T-rjxI5jrrCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "GiPN6R2qrsI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "\n",
        "f = open('11-0.txt', 'rb')\n",
        "sentences = []\n",
        "for sentence in f: # 데이터로부터 한 줄씩 읽기\n",
        "    sentence = sentence.strip() # strip()을 통해 \\r, \\n을 제거\n",
        "    sentence = sentence.lower() # 소문자화\n",
        "    sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "beLR2hwcrtMx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymwwkdc2sHTG",
        "outputId": "5fe96968-2019-4ffc-9fbe-ab3a29b00eed"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 문자열로 통합\n",
        "total_data = ' '.join(sentences)\n",
        "print('문자열의 길이 또는 총 문자의 개수: %d' % len(total_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pps1R6jsJBD",
        "outputId": "0894b2d3-df8d-4718-9f02-dd2bf5e8f0a1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자열의 길이 또는 총 문자의 개수: 159484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자 집합을 만들기\n",
        "char_vocab = sorted(list(set(total_data)))\n",
        "vocab_size = len(char_vocab)\n",
        "print ('문자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLwg1BvsMbk",
        "outputId": "516556f3-0771-47cb-d577-5324e1218ac0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합의 크기 : 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자에 고유한 정수 부여\n",
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
        "print('문자 집합 :',char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpfXMhlfsVeP",
        "outputId": "cd357961-6633-46eb-f8d4-b9f269494734"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 : {' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수로부터 문자 리턴\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key"
      ],
      "metadata": {
        "id": "E0N1ge4rsY_w"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 구성\n",
        "# appl (입력 시퀀스) -> pple (예측해야하는 시퀀스)\n",
        "train_X = 'appl'\n",
        "train_y = 'pple'"
      ],
      "metadata": {
        "id": "uH40arq4sbki"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 샘플의 길이 정하기\n",
        "# 길이만큼 문자열 전체를 등분\n",
        "\n",
        "seq_length = 60\n",
        "\n",
        "# 문자열의 길이를 seq_length로 나누면 전처리 후 생겨날 샘플 수\n",
        "n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n",
        "print ('샘플의 수 : {}'.format(n_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0kLf_HCsj2b",
        "outputId": "63019a0f-0828-451b-f75d-f7f919a55290"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 수 : 2658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 총 샘플의 수 2,658개\n",
        "# 전처리 진행\n",
        "train_X = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 pick.\n",
        "    X_sample = total_data[i * seq_length: (i + 1) * seq_length]\n",
        "\n",
        "    # 정수 인코딩\n",
        "    X_encoded = [char_to_index[c] for c in X_sample]\n",
        "    train_X.append(X_encoded)\n",
        "\n",
        "    # 오른쪽으로 1칸 쉬프트\n",
        "    y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]\n",
        "    y_encoded = [char_to_index[c] for c in y_sample]\n",
        "    train_y.append(y_encoded)\n",
        "\n",
        "print('X 데이터의 첫번째 샘플 :',train_X[0])\n",
        "print('y 데이터의 첫번째 샘플 :',train_y[0])\n",
        "print('-'*50)\n",
        "print('X 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_X[0]])\n",
        "print('y 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_y[0]])\n",
        "\n",
        "# train_y[0]은 train_X[0]에서 오른쪽으로 한 칸 쉬프트 된 문장"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5hWTUXusr7I",
        "outputId": "dfb6b45c-802e-4e8c-fafe-0fdd5a09c96b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터의 첫번째 샘플 : [49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
            "y 데이터의 첫번째 샘플 : [37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n",
            "--------------------------------------------------\n",
            "X 데이터의 첫번째 샘플 디코딩 : ['t', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a']\n",
            "y 데이터의 첫번째 샘플 디코딩 : ['h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a', 'n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[1])\n",
        "print(\"---------------------------------------------------------------\")\n",
        "print(train_y[1])\n",
        "\n",
        "# train_y[1]은 train_X[1]에서 오른쪽으로 한 칸 쉬프트 된 문장"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjfhIRts2cl",
        "outputId": "411b6674-6685-4232-8c66-7280017b3dd5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n",
            "---------------------------------------------------------------\n",
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_X와 train_y에 대해서 원-핫 인코딩 수행\n",
        "# 문자 단위 RNN -> 입력 시퀀스에 대해서 워드 임베딩을 하지 않음\n",
        "# 임베딩층 사용 X -> 입력 시퀀스인 train_X에 대해서도 원-핫 인코딩 수행\n",
        "\n",
        "train_X = to_categorical(train_X)\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
        "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGjUq8yIs9Y0",
        "outputId": "902b644b-0110-4433-b393-6ca05470b216"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_X의 크기(shape) : (2658, 60, 56)\n",
            "train_y의 크기(shape) : (2658, 60, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YESVfqoWtLby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플의 수(No. of samples)가 2,658개, 입력 시퀀스의 길이(input_length)가 60, 각 벡터의 차원(input_dim)이 55"
      ],
      "metadata": {
        "id": "BzUtSt5wtMXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`모델 설계`"
      ],
      "metadata": {
        "id": "g4NfdeVMtPnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, TimeDistributed\n",
        "\n",
        "# 은닉 상태의 크기는 256\n",
        "hidden_units = 256\n",
        "\n",
        "# 다 대 다 구조의 LSTM\n",
        "model = Sequential()\n",
        "# 은닉층 두 개\n",
        "model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(hidden_units, return_sequences=True))\n",
        "# 전결합층(Fully Connected Layer)을 출력층으로 문자 집합 크기만큼의 뉴런을 배치\n",
        "# 모든 시점에서 모든 가능한 문자 중 하나의 문자를 예측하는 다중 클래스 분류 문제\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# 80 에포크를 수행\n",
        "model.fit(train_X, train_y, epochs=80, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrN9Y43ytRc7",
        "outputId": "5eb0b54a-0532-40af-f0d6-92d51b61b380"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "84/84 - 47s - loss: 3.0627 - accuracy: 0.1852 - 47s/epoch - 562ms/step\n",
            "Epoch 2/80\n",
            "84/84 - 44s - loss: 2.7645 - accuracy: 0.2395 - 44s/epoch - 519ms/step\n",
            "Epoch 3/80\n",
            "84/84 - 43s - loss: 2.4360 - accuracy: 0.3183 - 43s/epoch - 509ms/step\n",
            "Epoch 4/80\n",
            "84/84 - 44s - loss: 2.3095 - accuracy: 0.3435 - 44s/epoch - 526ms/step\n",
            "Epoch 5/80\n",
            "84/84 - 43s - loss: 2.2210 - accuracy: 0.3676 - 43s/epoch - 509ms/step\n",
            "Epoch 6/80\n",
            "84/84 - 43s - loss: 2.1495 - accuracy: 0.3876 - 43s/epoch - 508ms/step\n",
            "Epoch 7/80\n",
            "84/84 - 43s - loss: 2.0888 - accuracy: 0.4018 - 43s/epoch - 511ms/step\n",
            "Epoch 8/80\n",
            "84/84 - 42s - loss: 2.0361 - accuracy: 0.4151 - 42s/epoch - 503ms/step\n",
            "Epoch 9/80\n",
            "84/84 - 41s - loss: 1.9908 - accuracy: 0.4254 - 41s/epoch - 493ms/step\n",
            "Epoch 10/80\n",
            "84/84 - 41s - loss: 1.9518 - accuracy: 0.4357 - 41s/epoch - 485ms/step\n",
            "Epoch 11/80\n",
            "84/84 - 42s - loss: 1.9185 - accuracy: 0.4442 - 42s/epoch - 499ms/step\n",
            "Epoch 12/80\n",
            "84/84 - 42s - loss: 1.8826 - accuracy: 0.4529 - 42s/epoch - 500ms/step\n",
            "Epoch 13/80\n",
            "84/84 - 42s - loss: 1.8509 - accuracy: 0.4618 - 42s/epoch - 504ms/step\n",
            "Epoch 14/80\n",
            "84/84 - 43s - loss: 1.8201 - accuracy: 0.4690 - 43s/epoch - 508ms/step\n",
            "Epoch 15/80\n",
            "84/84 - 43s - loss: 1.7934 - accuracy: 0.4771 - 43s/epoch - 507ms/step\n",
            "Epoch 16/80\n",
            "84/84 - 43s - loss: 1.7634 - accuracy: 0.4852 - 43s/epoch - 509ms/step\n",
            "Epoch 17/80\n",
            "84/84 - 43s - loss: 1.7426 - accuracy: 0.4911 - 43s/epoch - 508ms/step\n",
            "Epoch 18/80\n",
            "84/84 - 44s - loss: 1.7137 - accuracy: 0.4998 - 44s/epoch - 518ms/step\n",
            "Epoch 19/80\n",
            "84/84 - 42s - loss: 1.6879 - accuracy: 0.5064 - 42s/epoch - 502ms/step\n",
            "Epoch 20/80\n",
            "84/84 - 42s - loss: 1.6649 - accuracy: 0.5131 - 42s/epoch - 501ms/step\n",
            "Epoch 21/80\n",
            "84/84 - 43s - loss: 1.6405 - accuracy: 0.5184 - 43s/epoch - 507ms/step\n",
            "Epoch 22/80\n",
            "84/84 - 42s - loss: 1.6208 - accuracy: 0.5238 - 42s/epoch - 505ms/step\n",
            "Epoch 23/80\n",
            "84/84 - 43s - loss: 1.5936 - accuracy: 0.5316 - 43s/epoch - 515ms/step\n",
            "Epoch 24/80\n",
            "84/84 - 42s - loss: 1.5728 - accuracy: 0.5367 - 42s/epoch - 501ms/step\n",
            "Epoch 25/80\n",
            "84/84 - 42s - loss: 1.5523 - accuracy: 0.5416 - 42s/epoch - 502ms/step\n",
            "Epoch 26/80\n",
            "84/84 - 42s - loss: 1.5285 - accuracy: 0.5471 - 42s/epoch - 497ms/step\n",
            "Epoch 27/80\n",
            "84/84 - 41s - loss: 1.5084 - accuracy: 0.5532 - 41s/epoch - 489ms/step\n",
            "Epoch 28/80\n",
            "84/84 - 42s - loss: 1.4887 - accuracy: 0.5584 - 42s/epoch - 495ms/step\n",
            "Epoch 29/80\n",
            "84/84 - 43s - loss: 1.4640 - accuracy: 0.5651 - 43s/epoch - 508ms/step\n",
            "Epoch 30/80\n",
            "84/84 - 43s - loss: 1.4477 - accuracy: 0.5703 - 43s/epoch - 508ms/step\n",
            "Epoch 31/80\n",
            "84/84 - 42s - loss: 1.4230 - accuracy: 0.5768 - 42s/epoch - 504ms/step\n",
            "Epoch 32/80\n",
            "84/84 - 43s - loss: 1.4024 - accuracy: 0.5820 - 43s/epoch - 512ms/step\n",
            "Epoch 33/80\n",
            "84/84 - 43s - loss: 1.3825 - accuracy: 0.5880 - 43s/epoch - 506ms/step\n",
            "Epoch 34/80\n",
            "84/84 - 42s - loss: 1.3645 - accuracy: 0.5925 - 42s/epoch - 497ms/step\n",
            "Epoch 35/80\n",
            "84/84 - 40s - loss: 1.3418 - accuracy: 0.5993 - 40s/epoch - 478ms/step\n",
            "Epoch 36/80\n",
            "84/84 - 41s - loss: 1.3221 - accuracy: 0.6042 - 41s/epoch - 484ms/step\n",
            "Epoch 37/80\n",
            "84/84 - 41s - loss: 1.3045 - accuracy: 0.6098 - 41s/epoch - 493ms/step\n",
            "Epoch 38/80\n",
            "84/84 - 41s - loss: 1.2815 - accuracy: 0.6155 - 41s/epoch - 487ms/step\n",
            "Epoch 39/80\n",
            "84/84 - 40s - loss: 1.2651 - accuracy: 0.6202 - 40s/epoch - 477ms/step\n",
            "Epoch 40/80\n",
            "84/84 - 40s - loss: 1.2412 - accuracy: 0.6279 - 40s/epoch - 471ms/step\n",
            "Epoch 41/80\n",
            "84/84 - 41s - loss: 1.2220 - accuracy: 0.6331 - 41s/epoch - 486ms/step\n",
            "Epoch 42/80\n",
            "84/84 - 41s - loss: 1.2035 - accuracy: 0.6386 - 41s/epoch - 486ms/step\n",
            "Epoch 43/80\n",
            "84/84 - 40s - loss: 1.1874 - accuracy: 0.6424 - 40s/epoch - 481ms/step\n",
            "Epoch 44/80\n",
            "84/84 - 41s - loss: 1.1643 - accuracy: 0.6508 - 41s/epoch - 485ms/step\n",
            "Epoch 45/80\n",
            "84/84 - 42s - loss: 1.1428 - accuracy: 0.6561 - 42s/epoch - 496ms/step\n",
            "Epoch 46/80\n",
            "84/84 - 42s - loss: 1.1267 - accuracy: 0.6609 - 42s/epoch - 496ms/step\n",
            "Epoch 47/80\n",
            "84/84 - 43s - loss: 1.1020 - accuracy: 0.6687 - 43s/epoch - 511ms/step\n",
            "Epoch 48/80\n",
            "84/84 - 43s - loss: 1.0815 - accuracy: 0.6747 - 43s/epoch - 506ms/step\n",
            "Epoch 49/80\n",
            "84/84 - 43s - loss: 1.0637 - accuracy: 0.6789 - 43s/epoch - 512ms/step\n",
            "Epoch 50/80\n",
            "84/84 - 42s - loss: 1.0413 - accuracy: 0.6880 - 42s/epoch - 505ms/step\n",
            "Epoch 51/80\n",
            "84/84 - 42s - loss: 1.0225 - accuracy: 0.6923 - 42s/epoch - 498ms/step\n",
            "Epoch 52/80\n",
            "84/84 - 41s - loss: 1.0004 - accuracy: 0.6993 - 41s/epoch - 494ms/step\n",
            "Epoch 53/80\n",
            "84/84 - 42s - loss: 0.9757 - accuracy: 0.7073 - 42s/epoch - 495ms/step\n",
            "Epoch 54/80\n",
            "84/84 - 41s - loss: 0.9563 - accuracy: 0.7135 - 41s/epoch - 494ms/step\n",
            "Epoch 55/80\n",
            "84/84 - 41s - loss: 0.9433 - accuracy: 0.7162 - 41s/epoch - 492ms/step\n",
            "Epoch 56/80\n",
            "84/84 - 42s - loss: 0.9141 - accuracy: 0.7258 - 42s/epoch - 496ms/step\n",
            "Epoch 57/80\n",
            "84/84 - 40s - loss: 0.8915 - accuracy: 0.7332 - 40s/epoch - 477ms/step\n",
            "Epoch 58/80\n",
            "84/84 - 41s - loss: 0.8796 - accuracy: 0.7360 - 41s/epoch - 492ms/step\n",
            "Epoch 59/80\n",
            "84/84 - 42s - loss: 0.8552 - accuracy: 0.7442 - 42s/epoch - 503ms/step\n",
            "Epoch 60/80\n",
            "84/84 - 42s - loss: 0.8299 - accuracy: 0.7529 - 42s/epoch - 499ms/step\n",
            "Epoch 61/80\n",
            "84/84 - 41s - loss: 0.8153 - accuracy: 0.7566 - 41s/epoch - 493ms/step\n",
            "Epoch 62/80\n",
            "84/84 - 41s - loss: 0.7889 - accuracy: 0.7654 - 41s/epoch - 482ms/step\n",
            "Epoch 63/80\n",
            "84/84 - 41s - loss: 0.7739 - accuracy: 0.7689 - 41s/epoch - 483ms/step\n",
            "Epoch 64/80\n",
            "84/84 - 41s - loss: 0.7506 - accuracy: 0.7778 - 41s/epoch - 490ms/step\n",
            "Epoch 65/80\n",
            "84/84 - 41s - loss: 0.7423 - accuracy: 0.7796 - 41s/epoch - 487ms/step\n",
            "Epoch 66/80\n",
            "84/84 - 41s - loss: 0.7193 - accuracy: 0.7868 - 41s/epoch - 492ms/step\n",
            "Epoch 67/80\n",
            "84/84 - 41s - loss: 0.7029 - accuracy: 0.7913 - 41s/epoch - 483ms/step\n",
            "Epoch 68/80\n",
            "84/84 - 41s - loss: 0.6727 - accuracy: 0.8028 - 41s/epoch - 483ms/step\n",
            "Epoch 69/80\n",
            "84/84 - 41s - loss: 0.6613 - accuracy: 0.8053 - 41s/epoch - 490ms/step\n",
            "Epoch 70/80\n",
            "84/84 - 41s - loss: 0.6466 - accuracy: 0.8094 - 41s/epoch - 488ms/step\n",
            "Epoch 71/80\n",
            "84/84 - 40s - loss: 0.6353 - accuracy: 0.8132 - 40s/epoch - 477ms/step\n",
            "Epoch 72/80\n",
            "84/84 - 40s - loss: 0.6035 - accuracy: 0.8252 - 40s/epoch - 473ms/step\n",
            "Epoch 73/80\n",
            "84/84 - 41s - loss: 0.5966 - accuracy: 0.8259 - 41s/epoch - 489ms/step\n",
            "Epoch 74/80\n",
            "84/84 - 42s - loss: 0.5756 - accuracy: 0.8336 - 42s/epoch - 498ms/step\n",
            "Epoch 75/80\n",
            "84/84 - 42s - loss: 0.5580 - accuracy: 0.8387 - 42s/epoch - 498ms/step\n",
            "Epoch 76/80\n",
            "84/84 - 40s - loss: 0.5367 - accuracy: 0.8463 - 40s/epoch - 476ms/step\n",
            "Epoch 77/80\n",
            "84/84 - 40s - loss: 0.5275 - accuracy: 0.8491 - 40s/epoch - 478ms/step\n",
            "Epoch 78/80\n",
            "84/84 - 41s - loss: 0.5186 - accuracy: 0.8509 - 41s/epoch - 488ms/step\n",
            "Epoch 79/80\n",
            "84/84 - 42s - loss: 0.4917 - accuracy: 0.8615 - 42s/epoch - 495ms/step\n",
            "Epoch 80/80\n",
            "84/84 - 41s - loss: 0.4803 - accuracy: 0.8645 - 41s/epoch - 492ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b06f359d840>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 문자를 주면 다음 문자를 계속해서 생성\n",
        "def sentence_generation(model, length):\n",
        "    # 문자에 대한 랜덤한 정수 생성\n",
        "    ix = [np.random.randint(vocab_size)]\n",
        "\n",
        "    # 랜덤한 정수로부터 맵핑되는 문자 생성\n",
        "    y_char = [index_to_char[ix[-1]]]\n",
        "    print(ix[-1],'번 문자',y_char[-1],'로 예측을 시작!')\n",
        "\n",
        "    # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "    X = np.zeros((1, length, vocab_size))\n",
        "\n",
        "    for i in range(length):\n",
        "        # X[0][i][예측한 문자의 인덱스] = 1, 즉, 예측 문자를 다음 입력 시퀀스에 추가\n",
        "        X[0][i][ix[-1]] = 1\n",
        "        print(index_to_char[ix[-1]], end=\"\")\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    return ('').join(y_char)"
      ],
      "metadata": {
        "id": "pjte1ni4tj2T"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sentence_generation(model, 100)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY76jGYCtowU",
        "outputId": "79bba376-7766-430e-bd17-6b6b7f067476"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 번 문자 p 로 예측을 시작!\n",
            "1/1 [==============================] - 1s 801ms/step\n",
            "1/1 [==============================] - 1s 818ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "per that say down at her added sighing as her. i drippice topes, you knowally, and she tried to say w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문자 단위 RNN(Char RNN)으로 텍스트 생성하기**"
      ],
      "metadata": {
        "id": "VcHGjXUktq0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "UaIXiXDctuxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# 엉터리 노래 가사\n",
        "raw_text = '''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''"
      ],
      "metadata": {
        "id": "dG8d0PeytwNq"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단락 구분을 없애고 하나의 문자열로 재저장\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "print(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV51Oxtdt2Ou",
        "outputId": "1156f16b-3746-4822-8f60-85369d3e88bf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복을 제거한 문자 집합 생성\n",
        "char_vocab = sorted(list(set(raw_text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('문자 집합 :',char_vocab)\n",
        "print ('문자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neCfgWA0t6rR",
        "outputId": "11efba7d-c76a-42be-9fad-cb03905262b6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 : [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "문자 집합의 크기 : 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab)) # 문자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoC5Wfhit_0U",
        "outputId": "fc9e4aca-1eb5-4e2e-8574-9753543be976"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 시퀀스의 길이가 10가 되도록 데이터를 구성\n",
        "# 예측 대상인 문자도 필요 -> 길이 11\n",
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(raw_text)):\n",
        "    seq = raw_text[i-length:i] # 길이 11의 문자열을 지속적으로 만든다.\n",
        "    sequences.append(seq)\n",
        "print('총 훈련 샘플의 수: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAiggXfVuCkA",
        "outputId": "f1942385-76f6-4b10-eed9-0c3150405769"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 훈련 샘플의 수: 426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플의 수는 426개\n",
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgyWFxlHuH13",
        "outputId": "ca2fa5c4-27f5-41e4-c985-9a3028545cfb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I get on wi',\n",
              " ' get on wit',\n",
              " 'get on with',\n",
              " 'et on with ',\n",
              " 't on with l',\n",
              " ' on with li',\n",
              " 'on with lif',\n",
              " 'n with life',\n",
              " ' with life ',\n",
              " 'with life a']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# char_to_index를 사용하여 전체 데이터에 대해서 정수 인코딩을 수행\n",
        "encoded_sequences = []\n",
        "for sequence in sequences: # 전체 데이터에서 문장 샘플을 1개씩 꺼낸다.\n",
        "    encoded_sequence = [char_to_index[char] for char in sequence] # 문장 샘플에서 각 문자에 대해서 정수 인코딩을 수행.\n",
        "    encoded_sequences.append(encoded_sequence)\n",
        "\n",
        "# 정수 인코딩 결과가 X에 저장\n",
        "encoded_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyt1GObzuMQX",
        "outputId": "9e0f5ad6-a9dc-4634-c791-9f8185ec0499"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18],\n",
              " [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28],\n",
              " [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17],\n",
              " [14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0],\n",
              " [28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 대상 문자 분리\n",
        "encoded_sequences = np.array(encoded_sequences)\n",
        "\n",
        "# 맨 마지막 위치의 문자를 분리\n",
        "X_data = encoded_sequences[:,:-1]\n",
        "# 맨 마지막 위치의 문자를 저장\n",
        "y_data = encoded_sequences[:,-1]"
      ],
      "metadata": {
        "id": "hLB7SLQ-uReB"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
        "X_data_one_hot = np.array(X_data_one_hot)\n",
        "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)\n",
        "\n",
        "print(X_data_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vapoyj4uZEV",
        "outputId": "3a6ffcd5-8c24-4b88-cac1-dc2029e145d4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(426, 10, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYwAAAD0CAIAAAAHXYYFAAAgAElEQVR4Ae19T2hcV5Z+LbLopRZeCFoLQfVCC4O98KIXgniwidzghSHx4DAefiItz7hCDJqQ+eFf42Bou+lUQrd/NG0K7En8JyGVKEl70jHxjN1jxalO3KRC3BlPOk7cZQW1g0yUUMZyISPJvKF9hsOdd+85dY5ePem9p+NFeHXud7977nfrfrn31ntPpcj+mQKmgCmQYQVKGc7NUjMFTAFTIDKTsi+BKWAKZFoBM6lMD48lZwqYAmZS9h0wBUyBTCtgJpXp4bHkTAFTwEzKvgOmgCmQaQXMpDI9PJacKWAKmEnZd8AUMAUyrYCZVKaHx5IzBUwBMyn7DpgCpkCmFTCTyvTwWHKmgClgJmXfAVPAFMi0AmZSmR4eS84UMAXMpOw7YAqYAplWwEwq08NjyZkCpoCZlH0HTAFTINMKmEllengsOVPAFCiySdUmmht21jbsrNUmmsu+PvGvV/L+LTl48OD3vve9wcHB9evXb9++ff/+/ZOTk3nvlOW/dhQorEndW1g6fOzS9Mzt5Y3lbLvz9z/5zb7n3v3Vq3+IMQDzcy810nDAHpL/40/fwczn5+enpqauXr06OTn5wgsvbNy4sV6vY6ldmAJZVqCYJoUW05lfWIb60zO3r09/d+zNj6Mo2rCz5jIkZAYqINmwsxZLr4fk+557N5a524uDD/65Ebs2BTKrQAFNyrWYZeg+cf6z4dGXZtsdqOtO9YTMQIgkLnMURRhfRs5YxSWJ8SMmiiIzKVcNu864AkUzqZjFaNV/e/LajvH6jZttrFibaMJ1QmafBJmjKOo5eRRFLj92By7MpGKC2McsK1Aok/ItRi79rW/vPnv0YvvOfGwLBlM9CTPmECNBE4nFEa+68EmQ3+cxk/I1sUhmFSiISVEWI9T90y9vbdlzKjirN+ysBc1LyAywYHobdtaCcRVzFEUUiW33tEoaPpsKFMGkGIuRiD49c/vs+19c+vgrH/zpl7fgDga/SB6h0tuws0Y5Y3Jy/8jf5bSVlKuGXWdcgdybFGMxXaVfWrr/7NGLj+9/M4gE5n/5zSfBUmGQSm965vY/vfBvQWcUMsNZO2WvdiYll9GQGVcgxybFW4xE92ePXtz33LuxQ6goipIzMySpkru9Du5eAWArKVcou864Ajk2KcpiJIo3/+vrX7/2Ed5nEKuShBmpKBIqjhUlFxISO5OSKGmY7CuQS5PiLaar6G/97k/Doy8Ft1oJmaFpioSKd03YBchJzKRc3ew6vwrkz6QYi+k6DPcWlr7+5k5touneCYW1kjB3JUmVHFt3L2y756ph1/lVIE8mxVtM1zGYbXce3//mz19s+MiEzEBIkVBxPw0msgwSMylGTyvKkQK5MSnGYiRyLy3d377v1V+/9tHS0v0YPiEzsFEkVDyWA/8RSP7u/73Fw2Kltt2LCWIfc6pAPkyKsRiJ7m9PXnvrd3+69e1dH5yQGQgpEirup8FEkIQxnWB1Bm+/7gUVs2A2FciBSTEW01XTpaX7vzz94fZ9r16f/s4HJ2FGNoqEimNFyYVLwphOkMq2e0FZLJg7BTJtUrzFdNX6zt17s+3O4WOX7ty9FwMnZAY2ioSKx3LgP/okjOkEqRi8raSCilkwmwpk16QYi5FIeX36u+37Xj1/ueWDEzIDIUVCxf00mEiQhDGdIBWz8jKTCipmwWwqkFGTYixGouP0zO0te04FHSohM7ROkVBxSc6IoUgY08G67gWDN5NyhbLrjCuQRZNiLKarmktL92sTzevT3wWPyZMwY9MUCRXHipILhoQxnSAzs/IykwoqZsFsKpAtk+ItpquCd+7ee/JnZ5/82dngIRRjXl2ZAUClR8WFtDw5kjCmgxj3gsGbSblC2XXGFciQSTEWIxHx1rd3r03N1iaa/p1QCZmhdYqEiktyRoyEhDEd5HEvmJWXmZQrlF1nXIGsmBRjMRIFz19ubdlz6utv7vjghMxASJFQcT8NJiIkYUwnSM7gzaSCilkwmwpkwqQYi5Godu7316k7oRIyQ+sUCRWX5IwYOQljOsjmXjArLzMpVyi7zrgCq29SjMV01a4zv/D8yQ9m2x3/ECqKoiTM2DRFQsWxouRCRcKYTrAtBm8mFVTMgtlUYDVNireYrnrduNneMV7/5ekP/UOohMzQNEVCxbsm7AKA5BenPwzaq4vEa8Z0EONeMCsvMylXKLvOuAKrZlKMxUgkm213zl9unX3/Cx+ckBkIKRIq7qfBRJCE8RG/ugps7zj3BbRIThVYHZNiLEaiY22i+ejTr/sLqCiKEjJD6xQJFZfkjBiXROU7KrC94xwFt4u8K7AKJsVYjETN509+8A8/fad9Z94HJ2QGQoqEivtpMJEYiWoHpwKbSTGjYEX5UmClTYqxmK7C3bjZrk0023fmg2uoJMzYNEVCxbGi5MInUfmOCmzbPcmIGCYXCqycSfEW01WsSx9/tWXPKeoQijGvrswAoNKj4kJanly1g1OBzaRUA2TgLCuwQibFWIxEndl2pzbRvDY164MTMgMhRULF/TSYCEOi8h0V2LZ7zIhYUb4UWAmTYiymq1id+YV9z717+NilIDIJMxJSJFQcK0oueBLVDk4FNpOSjI5hcqFAuibFW0xXgZaW7j++/83Dxy75h1AJmaFpioSKd03YBUhIVL6jAtt2zx0Lu861AimaFGMxEskuffzV2fe/CD6Ol5AZWqdIqLgkZ8QISVQ7OBXYTArHwi7yrkBaJsVYjESy2kRzy55Tn355ywcnZAZCioSK+2kwETmJyndUYNvuMQNkRflSIBWTYiymqzqd+YXZdufZoxeDb61LwoxNUyRUHCtKLn588G3KXv3qqh2cCmwm5attkZwq0GOT4i2mq0bTM7cfffr1V85+6iMTMgMhRULF/TSYCJBs2FkL2muwosp3VGDb7gUFt2AeFeilSTEWI5Hm1rd3H37iRNChEjJD6xQJFZfkjBgkUW3K0gObSeHQ2EXeFeiZSTEWI9HoxTOffPbnb6ZnbvvghMxASJFQcT8NJuKSqNY7qZoUk4m9BYEZTSvKmgK9MSnGYrp2uDO/8Mwv/v1v//mN4A95SZixaYqEimNFyUWMhLEGny09sJ1J+WpbJKcKJDUp3mK6ijLb7ty42T587NK9haUYOCEzsFEkVDyWA/8xSKJaHKVqUkwmtpLiR9ZKM6VAIpNiLEbSyd9fmX74iROf/fkbH5yQGQgpEirup8FEKBLGGny29MB2JuWrbZGcKrB8k2IsRqLFxY9uPLL39B/+8y8+OCEzEFIkVNxPg4kwJKrFUaomxWRiKylmcK0oawos06QYi+naQ3z9bvCn+iTM2DRFQsWxouSCJ2GswSdPD2xnUr7aFsmpAmqT4i2mqwrwU/1PfvUfnfmFGDghM7BRJFQ8lgP/UUKiWhylalJMJraS4gfaSjOlgM6kGIuR9Gq23Tn7/hf1c1d9cEJmIKRIqLifBhMRkjDW4JOnB7YzKV9ti+RUAYVJMRYj6fzJ3/7xkb2n/V/x4MXklHlJmAFDpUfF5cyqDFWLo1RNisnEVlKq0Tfw6iogNSnGYiQdgHd7B++ESsgMrVMkVFySM2JUJIw1ICFepAe2MykU2S7yroDIpH588O0NO2sbdtZqE83aRHN517969Q++WMiWkPzRp1/3HbA20fybH59cXrZuT4Pkfl8golocpWpSTCa2kqKGz+IZVEBkUr84/aF/zq3tTHBCzrY7zFwSNkGlN9vuBJ1RSAswipwiUXUnPbCdSVEDZPHcKSAyKdVcoiSgSILmRZEE4wwD1WiQJxhkyJPjVempwLbdC46OBfOoQBFMipm9TJFwtLQMKlNLD2wmJRxfg2VfAZFJqeYS1WeKROsCPj/DQDXqk1ARhjxYRYVXpacCp7Tdq9frpVKp1WoF+97DYKPRKJVKjUajWq2WSqJvaQ9bN6pMKSAafu30CPaQIlHNahUzv5oIUvlBKm0fCRFVd9IDZ9mkJE5nJkV9wdZgXGRSqrlEiUiRaF3A52cYqEZ9EirCkAerqPCq9FRg3qBX99c9WBzxyzE0qaDIFlxTChTBpJjZyxQJh1nLoDKp9MApmRQugsBoRkZGSg/+NRqNKIpKpRJGyuVyFEWuH42MjJTLZWCAWvV6PTYKWFqpVGLbPYggv4uMkdjHgikgMinVXKIEoki0LuDzMwxUoz4JFWHIg1VUeFV6KnDa2z1wH3CZcrk8MjICJgXe1Gq1SqVS9cE/PMMCk4o5l6sh1oqiiDKpRqMBMNcEXRK7Lp4CRTApZvYyRcKx1DKoTCo98MqYFGzZ0H3AmEBYcC5/JcWYFC7ToijC7R4woG0BealUqlQqURS5VYQDarDcKSAyKdVcoiSgSLQu4PMzDFSjPgkVYciDVVR4VXoq8Mps98ykgt8BC/ZWgSKYFDN7mSKhjloGlUmlB14tk4JdGKyD6g/+wdGSuxmklj9YC9dN7i0IsAGEUbOVlPDbWwyYyKRUc4nShSLRuoDPzzBQjfokVIQhD1ZR4VXpqcCrtd0rl8twKA7bsSiKMIK7QjCsUqnkH5zD5g48KHhwDpqbSQW/e0UNFsGkmNnLFAlHVMugMqn0wCmZFC8aegcPs1JTQKWAyKRUc4lqniLRuoDPzzBQjfokVIQhD1ZR4VXpqcBdt3vj4+PB/JMEtSaF6yb3PoYkCVjdQipQBJNiZi9TJBxOLYPKpNID8yY1MzOzadOmgYGB7du3j46Owr2d7n8nJyeF+rgwrUm5de3aFKAUEJmUai5RLVEkWhfw+RkGqlGfhIow5MEqKrwqPRWY3+7Nzc1t3769r69v8+bNjz322Ojo6P79+5ObVFAQC5oCCRUogkkxs5cpEgqnZVCZVHpg3qQOHTo0Pj6+uLgoFCE5DO7A9E/Ks8CM92RRPztqkwTCNJ6LrlQq8PupNqWM4JensMikVHOJkoMi0bqAz88wUI36JFSEIQ9WUeFV6anA/HYv1Wf38Oc8OGmCe6lyZ1Llchl/oAwONBNMUpehhTszsmlSfJexdO2aFDN7mSL+24ClWgaVSaUHXl2Tgqdk3NudUM8MXuBKys0tyfmae+e9y5n8OrMrKV4uvrSrLKKVlGouUU1SJFoX8PkZBqpRn4SKMOTBKiq8Kj0VmN/upb2SQpOC+6RGRkZwJQUX+JxwpVLBa1hz4U9+7tN5iIEnmRHjMuPDNO7Ty7HHkqEJXOu5t542Gg38/zwCvv/977uOE/QIaA7nIX50lzyQMHxhyg/+RVEEUmC7UBE6iGkDCXbfT8DVs16vw0ekckvh8W98LAk48WOpVIK2XAZ8ogAIYWkJDzxBBKqgXPARirA5txQVdtvFpzt9ZlCsCCbFzF6mKGgxflDLoDKp9MDpmRR+5+C7WK1WY6Lh88YQh3kFX32cReBiMBXhoAq8AL7EULFcLuMjyu6TzEgFMPwIF5AP8DQaDWgCX9IQ28HBDaW4knKnEJrOyIN/0JZ/Ayp21m3d9TWoiE0ADKZlvV4vl8tQBB0EL2u1Wm7aGHTv2gdadDr8vwJmWK1Wy+UyNAel2BAQQou+4G5/YS0M1YGq0WjAFwD/l4DDF9MW8ZA2lKLCOEC43Mb7fmPMf62OvWUuVHOJ4qFItC7g8zMMVKM+CRVhyINVVHhVeipwRrZ7eIwCX1k0KbASd/rBsQVMTvd/xS4G71kHAEwPZMYJAOMCTgGEEEFDcX22Wq2ig7gMaFIYBJg76Ng0BHF6+yYFM7BardbrdXBtuKhUKtBBYEBCN22kRTH9HEBPyBDVK5VK7733HtoWmoUrqS84RND1XK2gXygjZAtNo1zQCuYQszAU010Sov5B5oKYFDN7mSJ3pJlrLYPKpNIDp2dS/rc2ph5+1SAO7oPTz/1mu7MFTQq2DMjpYtCk8H+/uFjA5wRhhwJTpVqturMdEsN5ghicJLEiXBqg32EE0sNOwUd0k6BJwca2UqmAPcFKp16v99ykYNkYzBCsxJXUNQvUHM0O1k2xXuP4ukOJJoXdccXBUlTYbRf1DzJLTUo1l7CrsQuKROsCMVp+X0M16pNQEW16KrwqPRWYl2XFzqTw4AO/su43250tYFLwJYZpVq/X8QFjPBxxLQyrw2IBm3Bf4eKbFNaCtqiVFOQD34pqtQodcec/FCHMbT1oUtAcuGq9XkdlcIriMQ1aMDThdgFPjvDr6uoJtoueUqlUoBSWRagtKoBCuYIDM3bHbR2Yg1aCOiAeWoGVFJZCDq1WCy/c5WGQuSAmxcxepgiHmb/QMqhMKj3w6poUrvbRU/BL704qd7bg9xi+5fj/XhcDKylgwB0fMuNZBhTBxMM5g0f4MJOBH9wEbcKdOdAu5A9N4A4o9oXBzsLGB/jx2gWjxcQIoV3gATt208bDGsgZJQVmoMLmcBEEd2lBKS5+AeZKioaIgoN74rG32zo6jntK5XLiwhblhSoopq8w9Br6ksikVHPJHRX3miLRuoDLCdcMA9WoT0JFGPJgFRVelZ4KnN52L9jrwgfhxce562bMwnKXPyRchINzZvYyRcIB0zKoTCo9sJmUcHwlMPj/vwSZNcwaMinVXKLGiSLRuoDPzzBQjfokVIQhD1ZR4VXpqcCruN0LypLTIExyfG9f7nphJqUbMmqOqWZ1sEmKmV9NBKn8IEPug3lr8PGqvqvAfCapHpz73bSIKZBEgSJs9xgf0U5sX0qG3AdrbVGVngrMZ2ImFRw7C2ZTgSKYFDN7mSLheGgZVKaWHthMSji+Bsu+AiKTUs0lqs8UidYFfH6GgWrUJ6EiDHmwigqvSk8Ftu1ecHQsmEcFimBSzOxlioSjpWVQmVR6YDMp4fgaLPsKiExKNZeoPlMkWhfw+RkGqlGfhIow5MEqKrwqPRXYtnvB0bFgHhUogkkxs5cpEo6WlkFlUumBzaSE42uw7CsgMinVXKL6TJFoXcDnZxioRn0SKsKQB6uo8Kr0VGDb7gVHx4J5VKAIJsXMXqZIOFpaBpVJpQc2kxKOr8Gyr4DIpFRzieozRaJ1AZ+fYaAa9UmoCEMerKLCq9JTgW27FxwdC+ZRgSKYFDN7mSLhaGkZVCaVHthMSji+Bsu+AiKTUs0lqs8UidYFfH6GgWrUJ6EiDHmwigqvSk8Ftu1ecHQsmEcFimBSzOxlioSjpWVQmVR6YDMp4fgaLPsKiExKNZeoPlMkWhfw+RkGqlGfhIow5MEqKrwqPRXYtnvB0bFgHhUogkkxs5cpEo6WlkFlUumBzaSE42uw7CsgMinVXKL6TJFoXcDnZxioRn0SKsKQB6uo8Kr0VGDb7gVHx4J5VKAIJsXMXqZIOFpaBpVJpQc2kxKOr8Gyr4DIpFRzieozRaJ1AZ+fYaAa9UmoCEMerKLCq9JTgW27FxwdC+ZRgSKYFDN7mSLhaGkZVCaVHthMSji+Bsu+AiKTUs0lqs8UidYFfH6GgWrUJ6EiDHmwigqvSk8Ftu1ecHQsmEcFimBSzOxlioSjpWVQmVR6YDMp4fgaLPsKiExKNZeoPlMkWhfw+RkGqlGfhIow5MEqKrwqPRXYtnvB0bFgHhUogkkxs5cpEo6WlkFlUumBzaSE42uw7CsgMinVXKL6TJFoXcDnZxioRn0SKsKQB6uo8Kr0VGDb7gVHx4J5VKAIJsXMXqZIOFpaBpVJpQc2kxKOr8Gyr4DIpFRzieozRaJ1AZ+fYaAa9UmoCEMerKLCq9JTgW27FxwdC+ZRgSKYFDN7mSLhaGkZVCaVHthMSji+Bsu+AiKTUs0lqs8UidYFfH6GgWrUJ6EiDHmwigqvSk8Ftu1ecHQsmEcFimBSzOxlioSjpWVQmVR6YDMp4fgaLPsKiExKNZeoPlMkWhfw+RkGqlGfhIow5MEqKrwqPRXYtnvB0bFgHhUogkkxs5cpEo6WlkFlUumBzaSE42uw7CsgMinVXKL6TJFoXcDnZxioRn0SKsKQB6uo8Kr0VGDb7gVHx4J5VKAIJsXMXqZIOFpaBpVJpQc2kxKOr8Gyr4DIpFRzieozRaJ1AZ+fYaAa9UmoCEMerKLCq9JTgW27FxwdC+ZRgSKYFDN7mSLhaGkZVCaVHthMSji+Bsu+AiKTUs0lqs8UidYFfH6GgWrUJ6EiDHmwigqvSk8Ftu1ecHQsmEcFimBSzOxlioSjpWVQmVR6YDMp4fgaLPsKiExKNZeoPlMkWhfw+RkGqlGfhIow5MEqKrwqPRXYtnvB0bFgHhUogkkxs5cpEo6WlkFlUumBzaSE42uw7CsgMinVXKL6TJFoXcDnZxioRn0SKsKQB6uo8Kr0VGDb7gVHx4J5VKAIJsXMXqZIOFpaBpVJpQc2kxKOr8Gyr4DIpFRzieozRaJ1AZ+fYaAa9UmoCEMerKLCq9JTgW27FxwdC+ZRgSKYFDN7mSLhaGkZVCaVHthMSji+Bsu+AiKTUs0lqs8UidYFfH6GgWrUJ6EiDHmwigqvSk8Ftu1ecHQsmEcFimBSzOxlioSjpWVQmVR6YDMp4fgaLPsKiExKNZeoPlMkWhfw+RkGqlGfhIow5MEqKrwqPRXYtnvB0bFgHhUogkkxs5cpEo6WlkFlUumBzaSE42uw7CsgMinVXKL6TJFoXcDnZxioRn0SKsKQB6uo8Kr0VGDb7gVHx4J5VKAIJsXMXqZIOFpaBpVJpQc2kxKOr8Gyr4DIpFRzieozRaJ1AZ+fYaAa9UmoCEMerKLCq9JTgW27FxwdC+ZRgSKYFDN7mSLhaGkZVCaVHthMSji+Bsu+AiKTUs0lqs8UidYFfH6GgWrUJ6EiDHmwigqvSk8FDm73pqamms3m8ePHN23aVK/Xg/lb0BTImgJFMClm9jJFwpHQMqhMKj2wa1IHDx4sPfg3MDAwPDy8d+/ed955R9h9g5kCq66AyKRUc4nqEkWidQGfn2GgGvVJqAhDHqyiwqvSk4PvLSwdPnap+lIjmKEFTYF8KVAEk2JmL1MkHCctg8qk0gDPtjt//5Pf7Hvu3c78grCPBjMFsqyAyKRUc4nqLUWidQGfn2GgGvVJqAhDHqyiwqvSk4CnZ25fn/7u2Jsfu7nNzMzMzc25Ebs2BXKkQBFMipm9TJFwkLQMKpPqLXji/GfDoy/Ntjuxro2Pj+/atSsWtI+mQF4UEJmUai5RPadItC7g8zMMVKM+CRVhyINVVHhVejz47clrO8brN262/azm5uY2btx44sQJv8gipkD2FSiCSTGzlykSjo2WQWVSPQHf+vbus0cvtu/MM4dQV65cWbduXbsdsDChDgYzBVZLAZFJqeYS1ROKROsCPj/DQDXqk1ARhjxYRYVXpRcEf/rlrS17TgWLYumNjY0dOXIkFrSPpkD2FSiCSTFTlCkSjo2WQWVSCcHTM7fPvv/FpY+/6tqXM2fO9PX1XbhwoSvSAKZA1hQQmZRqLlE9pEi0LuDzMwxUoz4JFWHIg1VUeFV6Lnhp6f6zRy8+vv/NYA6x4KFDh9atWzc5ORmL20dTIBcKFMGk3NkbE50piiGpj1oGlUktG/zs0YuSO6EWFxd37949NDR0/fp1qoMWNwUyroDIpFRzieowRaJ1AZ+fYaAa9UmoCEMerKLCq9IDcPO/vv71ax/59xn4yczMzAwPD2/dutXOy31xLJIjBYpgUsxUZ4qEg6RlUJmUFvzW7/40PPqS5BDq6tWrg4ODe/fuXVxcFPbUYKZANhUQmZRqLlH9pEi0LuDzMwxUoz4JFWHIg1VUeHl69xaWHvnH07WJZvBOqFgm586d6+vrq9Vqsbh9NAXyqEARTIqZ6kyRcLS0DCqTEoJn253H97/58xdFDwwfOXLEfsgTDq7BcqGAyKSEc4nvMEWidQG/FYaBatQnoSIMebCKCi9Jb2np/vZ9r/76tY+Wlu4HW8Tg4uLi2NjYD37wg88//xyDdmEK5F2BIpgUM9WZIuHIaRlUJtUV/Pbktbd+96db397tmm273d784N/s7GxXsAFMgRwpIDKprnNJ0mGKROsCflsMA9WoT0JFGPJgFRWeSW9p6f4vT3+4fd+r16e/CzbkBj///POhoaGxsTE7JndlsetiKFAEk2KmOlMkHD8tg8qkKPCdu/dm253Dxy7duXuva54XLlxYt27dCy+80BVpAFMgjwqITIqaS6oOUyRaF/AbZRioRn0SKsKQB6uo8MH0rk9/t33fq+cvt4L8seDx48f7+vrsdcAxWexjkRQogkkFpzoMElMkHEUtg8qkfPD0zO0te05JHGpxcXF8fHxwcPDq1avCvhjMFMijAiKT8ufSMrpKkWhdwG+aYaAa9UmoCEMerKLCu+ktLd2vTTSvT38nOSafm5vbtm3b8PDwzMxMMA0LmgKFUaAIJuVO9djAMEUxJPVRy6AyKQTfuXvvyZ+dffJnZyWHUFNTU0NDQ6Ojo3ZMTo2axYukgMikcC4l6TlFonUBPweGgWrUJ6EiDHmwigoP6d369u61qdnaRLPrnVBRFDUajf7+/kOHDgVbt6ApUDwFimBSjBMxRcKx1DKoTGrDztr5y60te059/c0dST4nTpzo6+s7c+aMBGwYU6AYCohMSjXxKF0oEq0L+PwMA9WoT0JFGPJgFRV+849PCu+EiqLowIEDAwMDV65cCbZrQVOgqAoUwaQYJ2KKhCOqZRCaVGd+4fmTH8y2O5JDqLm5uR07dvzwhz+0Y3LhqBmsSAqITEo48XhdKBKtC/itMAxUoz4JFWHIg1Uk+Bs32zvG6788/aHkEGpmZmbjxo27du2yv50XFNyChVegCCbFOBFTJBxaLUNXk5ptd85fbp19/wtJAs1ms7+//+DBgxKwYUyBQiogMqmuE08iDUWidQG/LYaBatQnoSIMebAKj69NNB99+nXJAiqKonq93t/fX6/Xgw1Z0BRYIwoUwaQYJ2KKhAOsZWBM6vmTH/zDT99p35mXNH3w4MH+/v5msykBG8YUKLACIpNiJp5cGopE6wJ+i4ajId4AAA2pSURBVAwD1ahPQkUY8mCVIP7GzXZtotm+My9ZQ83Pz+/evXvjxo1/+ctfgk1Y0BRYUwoUwaQYJ2KKhMOsZfBN6tLHX23Zc0p4CBVF0djY2I4dO+yYXDhABiu8AiKT8ifeMnShSLQu4DfNMFCN+iRUhCEPVonhZ9ud2kTz2pToRXTXr18fHh7u6+t76qmnguQWNAXWoAJFMCnGiZgi4WBrGdCkOvML+5579/CxS8KGJicn+/v7jx8/PjY2ViqV7G95CnUzWOEVEJkUTrwkclAkWhfwc2AYqEZ9EirCkAerAH5p6f7j+988fOyS5BAqiqLjx48PDAw0Gv/zpxbgHSz2IuCgwhZcawoUwaQYJ2KKhCOtZfjRk69c+virs+9/IXwcb3Fxcf/+/UNDQ1NTU25KY2Nj27Zti73noF6vl0qlVkv0PjyXTXLdarVKpVKv7ngAtmq1KmnaMKYAo4DIpLSriWB7FInWBXxyhoFq1CehIgx5sEptorllz6lPv7wVLI0F5+bmtm/fvm3bNv+YfHFxcevWrXv37nWr9MSkGo1GqVTCVRvy98SkKpVKuVyOoshMCoW1i4QKFMGkGCdiioTCyRk68wuz7c6zRy9K3loXRdHU1NT69evHx8djyyVMrN1uDw0N9fzl5eB0KZnUyMiImRSOoF30RAGRSWlXE8HMKBK5CwRpoyhiGKhGKSo/zpC74OmZ248+/forZz91g8z15cuXBwYGjh8/zmCiKII/A9NutwGGKym4GBkZKT34B3u0crmMkVLpryPr+lGlUoEFFFQplUqxvZi7koLVFiBbrVawOcCXSqVyuQxs0ATUeu+990qlEuZTqVT4nlqpKUApUASTYpyIKaIUicUlDLe+vfvwEyfkDvXyyy/39/dfuHAh1lbwo7vOipkUuAwuXsAsgKRUKlUqFd+kYs7ltogmBRew1KpUKiMjI8DjNzcyMoKEsVIgAUC1WgXTdJuza1NAqIDIpISrCb5JikTiAjwzw0A1yhO6pQw5wF4888lnf/5meua2W4u5PnDgwNDQ0PL+yHDMpNBHwALK5TIuWMC5lmdSUAsXXHCajsdYsFxCR4Oe4roMHRMA4FyYNiOLFZkClAJFMCnGiZgiSpFYnGHozC8884t//9t/fkP4Q97c3NyuXbs2b96M27dYW10/4mwPuk9vTcr9DdFvzkyq62AZoFcKiEyq62pCkg1FwriAhJY6k7pz996zRy8eefmykISCUenNtjs3brYPH7t0b2GJquvGZ2ZmNm3alPCPDHc1KVhS4SoGjpbwxApKu/66h9XhR7pqteqbVBRFcOQU2+4Ff93DtF1B7NoUECqwmiZ18aMbL575hHIBYQeiKPLtD/6+5vMnPzj62kdyniDSJ4+i6PdXph9+4sRnf/4mWMUPNpvNgYGBI0eO+EWqCM72oGuUH/yDbRocBkVRhEfXcAHN4VG327q7OAJ+OBRHG4rtLvFwHTaAsLPDIByc23bPVdiul6eAyKSS+4i/3rn40Y1H9p7+5POZoAuoOhNjuDY1e+Nm+9zvr/uNqmgBHCOPoggy/8N/Sl9RcObMmf7+/nPnzi2jdVUV+HVPVaUnYNfdekJoJKaAq8AqmBS+3hverOS7gJuf5Nr10NpE80dPvjLb7kBFt0hC5WNcBsxceCdUFEWHDh1asT8yrDUpXC7B4kt7rzku1vAo3VfPIqZAcgVEJpXcR3BTBvcT/fzFBj7U5rrA8vqDDCd/+8fYW+WSZ47kkPlPfvUfnfkFSZ6Li4u7d+9eyT8yrDUpSS8YDCygwODcU3amihWZAstQYEVNCl7v/fbkNTdRdAE3qLquTTRv3GyPP/9vnfkF9D5gSG5SwDDb7px9/4v6uavCxGZmZoaHh3fv3u3e5SSsazBTwBRwFRCZVHIfgeOhHz35iv9bWHIf+b////zDT5yIeR90MnnmtYnmyd/+8ZG9p/3MXR3d66tXrw4ODmbhjwy7NyW4GfbwmvqtsIdNGNUaV0BqUrWJZm2iuWFnbcPO2jKu/8+BMxt21oJHOUlosS71Q1tyk9qws/bo068L74SKoujcuXP9/f2r+EeG8RfAKIrMpNb49C5G90Umlbyrs+2O8CgneVsuwzL8FI0P68ozP3LkyMDAwOr+9QR4BsUOidyvgV3nWoEVMqlcayRJfnFxcWxsbNOmTav7R4bdH+zq9TqupNxnj8vlMhgZvj0Kb27Cl1Xh3VVwoxPi4Q0H8BEw7nYvBoMbPuFk3X/pgkRVw5gCf/0WSVRY43+csmv32+325s2bV+aPDMN9mDDz8Yk5dxDBKWAl5ZoU3G4OLgaP+I08+Ac/0uGNmvg4Ma7FoAo0AQYHTcAtC2hSPgzvPnfTs2tTQKuAyKT6+vqW/biZNqEM4mF6R1G0uLjov9IX3qZy4MCBjGROmRTc1gSeAv4CJuIuvnDV495Y4L6ABR6FcZtAk6JgsPjKiDiWRh4VEJnU4OBg7OW2eezq8nKenZ3t6+uDumfOnBkaGnI3dBcuXOjv73/55ZeXR76MWsteSfEmhesmTAkaqjz4FzMayqRiMHw/J+4rkdwuTAG5AiKT2rx58+XLSZ/UleeUKSS8PxNTOnToEPoU/PWErCkDKyN/u0eZFGz34Oyp1WrBBfQX9oNACPvBer3eaDSCJuXDULTgthRL7cIU4BUQmdTevXtXcrHAZ7zCpW+88cZjjz3mNvrMM88MDg6Ojo6uX78+mwtM2Kz5B+dRFPnbPXx+OPY4cXDHB4dZQZOKogh3fADDj/4Ky9XTrk0BXgGRSU1OTj700EPwrV35/27evHnbtm0r3y60+NBDD73xxhsxEScnJ/fv3+//9YQYzD6aAqZAcgVEJpW8mSQMQ0NDg4OD9nxJEg2trimQXwVyYFK7d+/eunVrfiW2zE0BUyCJAjkwqaeeemp0dDRJJ62uKWAK5FeBHJjUwYMHx8fH8yvxKmaON3OuYg7WtCmQUIF8mFTXe74TqlCk6sFbEBJ20MwuoYBWPYkCZlJJ1MtiXff+gF7lB3/Fr1dsxmMKqBQwk1LJlXUwLKPg5gn/PimIax8wxnvc4XYnt4koisAT8YFk94E+aC7rkll+mVfATCrzQ/S/E0TLAAtwbxAHoLuSwm0a1ML7NlUPGMPLDKAK3AsKt7OPjIxUKhVoDh8GhOccsd3/nbt9MgWWo0AOTGrywb/ldG5N1qFMinosxl0ZgfGBE+FrW1yTAnKAwR3qEAGlgarRaMDCCnxtTQ6CdbqXCuTApHrZ3fxzLXslxZsU84Cxb1KuikGTwiWb63RuLbs2BeQKZNek4P/G/nZG3jcJsnjPvsJypocPGLuvIXYf/Ws0GvV6HUwKtnsjIyPuY3oAttfdSb6HhmEU6IFJweIf/1cM31r8yLTNFLkzjYElLyqeScHCB96OgmdD+NeuXJfBl9Lhjs8/GodxhDGFUrjGv7GORe7XAJd7tuNL/hU1hp6ZFOwm8OeehCYFX/0VGJ5CmtQK6IZNwEglHG5kswtTwFegNyYFL+WANb/7rcVfpt1dgJ8EvtMDfhsCBvg/M3BiFSSsVqvuH6eE/2NDRcTgAgEMFDYj+D95mFdoUnhajMcoyJP2lhN7l8cLd7jzmL/lnH0FemZS8GV1V1JgPSABbjd8RdxvOR5qIJuLp/aA4C/wwjZ8CSR4HJ7gtlotMB3wJswHTKrre77dNOzaVcAdPjdu16ZArxTomUnB8erIyAh+a/FABJ0rmDS8/hGK0IaCJoWLHTAadyVVKpVib4xEG4Ja8Ls47knRQMGkcM0F1gZs7iFLMHMLmgKmwAoo0EuTAjvABUvPTQrkgP2a++5ttCH0R3RMfBelxKT8gxVsawVGwpowBUyBoAK9NClcMcGxDv54hL9hu6/TxmzcRROuqtwgIvECYLg3hGWRZCWF5034MJq73YOzp+B7vrFpuzAFTIEVVqDHJgV+hF6AZ8+wzwqalPtubDxfD5qUuylrtVq4+5ObFJ6aY0N4cI7kUIQfsS8rPDDWnClgCoACPTCpvEiJK6+8JGx5mgKmwF/v+1s7KphJrZ2xtp4WSQEzqSKNpvXFFCigAmvIpAo4etYlU2ANKLASJpVwn0Udt1OjA/jYreoU2OKmgCmQcQUyZFLufVWuamZSrhp2bQqsNQUyZFJ471JsDLQmFatuH00BUyDXCqycSeE9Svj0HDx3AvclYWnwNiV4MQjgg2//gPuqAIbbPQziAy5QBB/tPUe5/uJa8mtHgR6YFNxLCTMfXzPkKogPyrhPqyDAfSQYDAju0sR3D4CzwO2gwZs80ZWAM/bRZcO2qtUq3s+JmdiFKWAKZFCBHphU117hwy5wc3ls6YT3fON2L+ZEYDrgWXAjuP+QHVgkHJbHTKr84B8+xIdmareSdx04A5gCWVCgByYlWUm5rx8ol8uu1/TEpPDZmnK57JoU+B3s7PA55CzobjmYAqaAUIEemFTXltztHiyXwDtarRa4FayS8Nc9cBO8h0CykoIckBa2de5GDwC4WANT65q5AUwBU2DVFVghk4qdi+N7uGEVBiYFFkMdnDPbPXAx3PHhSgobhSL3mWR4Beiqq28JmAKmQFcFVsKkuiZhAFPAFDAFKAVyaVLue1TwBzuqhxY3BUyBXCuQS5PKteKWvClgCqgUMJNSyWVgU8AUWGkF/htXuLhuLgcVAAAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "sYB56S_yub9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플의 수(No. of samples)가 426개, 입력 시퀀스의 길이(input_length)가 10, 각 벡터의 차원(input_dim)이 33"
      ],
      "metadata": {
        "id": "igXUiahAucip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 설계"
      ],
      "metadata": {
        "id": "Rpyr6w3Yuez1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 은닉 상태의 크기는 64\n",
        "hidden_units = 64\n",
        "\n",
        "# 다 대 일 구조의 LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
        "# 전결합층(Fully Connected Layer)을 출력층으로 문자 집합 크기만큼의 뉴런을 배치\n",
        "# 마지막 시점에서 모든 가능한 문자 중 하나의 문자를 예측하는 다중 클래스 분류 문제\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# 100 에포크를 수행\n",
        "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKOXbDKdufL4",
        "outputId": "a75ee5a2-6405-4152-ac87-80ddbf92c49f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 - 3s - loss: 3.4749 - accuracy: 0.0986 - 3s/epoch - 194ms/step\n",
            "Epoch 2/100\n",
            "14/14 - 0s - loss: 3.3956 - accuracy: 0.1972 - 104ms/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "14/14 - 0s - loss: 3.1905 - accuracy: 0.1972 - 96ms/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "14/14 - 0s - loss: 3.0021 - accuracy: 0.1972 - 104ms/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "14/14 - 0s - loss: 2.9593 - accuracy: 0.1972 - 106ms/epoch - 8ms/step\n",
            "Epoch 6/100\n",
            "14/14 - 0s - loss: 2.9407 - accuracy: 0.1972 - 146ms/epoch - 10ms/step\n",
            "Epoch 7/100\n",
            "14/14 - 0s - loss: 2.9179 - accuracy: 0.1972 - 159ms/epoch - 11ms/step\n",
            "Epoch 8/100\n",
            "14/14 - 0s - loss: 2.9046 - accuracy: 0.1972 - 154ms/epoch - 11ms/step\n",
            "Epoch 9/100\n",
            "14/14 - 0s - loss: 2.8923 - accuracy: 0.1972 - 157ms/epoch - 11ms/step\n",
            "Epoch 10/100\n",
            "14/14 - 0s - loss: 2.8759 - accuracy: 0.1972 - 158ms/epoch - 11ms/step\n",
            "Epoch 11/100\n",
            "14/14 - 0s - loss: 2.8516 - accuracy: 0.1972 - 158ms/epoch - 11ms/step\n",
            "Epoch 12/100\n",
            "14/14 - 0s - loss: 2.8286 - accuracy: 0.1972 - 150ms/epoch - 11ms/step\n",
            "Epoch 13/100\n",
            "14/14 - 0s - loss: 2.7919 - accuracy: 0.1972 - 171ms/epoch - 12ms/step\n",
            "Epoch 14/100\n",
            "14/14 - 0s - loss: 2.7581 - accuracy: 0.1972 - 170ms/epoch - 12ms/step\n",
            "Epoch 15/100\n",
            "14/14 - 0s - loss: 2.7176 - accuracy: 0.2042 - 158ms/epoch - 11ms/step\n",
            "Epoch 16/100\n",
            "14/14 - 0s - loss: 2.6694 - accuracy: 0.2089 - 154ms/epoch - 11ms/step\n",
            "Epoch 17/100\n",
            "14/14 - 0s - loss: 2.6208 - accuracy: 0.2300 - 152ms/epoch - 11ms/step\n",
            "Epoch 18/100\n",
            "14/14 - 0s - loss: 2.5880 - accuracy: 0.2606 - 157ms/epoch - 11ms/step\n",
            "Epoch 19/100\n",
            "14/14 - 0s - loss: 2.5225 - accuracy: 0.2746 - 155ms/epoch - 11ms/step\n",
            "Epoch 20/100\n",
            "14/14 - 0s - loss: 2.4707 - accuracy: 0.2981 - 153ms/epoch - 11ms/step\n",
            "Epoch 21/100\n",
            "14/14 - 0s - loss: 2.4393 - accuracy: 0.3075 - 154ms/epoch - 11ms/step\n",
            "Epoch 22/100\n",
            "14/14 - 0s - loss: 2.4181 - accuracy: 0.2981 - 159ms/epoch - 11ms/step\n",
            "Epoch 23/100\n",
            "14/14 - 0s - loss: 2.3539 - accuracy: 0.3380 - 151ms/epoch - 11ms/step\n",
            "Epoch 24/100\n",
            "14/14 - 0s - loss: 2.3006 - accuracy: 0.3239 - 157ms/epoch - 11ms/step\n",
            "Epoch 25/100\n",
            "14/14 - 0s - loss: 2.2399 - accuracy: 0.3404 - 159ms/epoch - 11ms/step\n",
            "Epoch 26/100\n",
            "14/14 - 0s - loss: 2.1855 - accuracy: 0.3756 - 158ms/epoch - 11ms/step\n",
            "Epoch 27/100\n",
            "14/14 - 0s - loss: 2.1470 - accuracy: 0.3756 - 151ms/epoch - 11ms/step\n",
            "Epoch 28/100\n",
            "14/14 - 0s - loss: 2.0988 - accuracy: 0.3662 - 162ms/epoch - 12ms/step\n",
            "Epoch 29/100\n",
            "14/14 - 0s - loss: 2.0647 - accuracy: 0.4014 - 160ms/epoch - 11ms/step\n",
            "Epoch 30/100\n",
            "14/14 - 0s - loss: 2.0317 - accuracy: 0.4202 - 146ms/epoch - 10ms/step\n",
            "Epoch 31/100\n",
            "14/14 - 0s - loss: 1.9617 - accuracy: 0.4366 - 157ms/epoch - 11ms/step\n",
            "Epoch 32/100\n",
            "14/14 - 0s - loss: 1.9294 - accuracy: 0.4460 - 164ms/epoch - 12ms/step\n",
            "Epoch 33/100\n",
            "14/14 - 0s - loss: 1.8672 - accuracy: 0.4953 - 164ms/epoch - 12ms/step\n",
            "Epoch 34/100\n",
            "14/14 - 0s - loss: 1.8235 - accuracy: 0.5047 - 162ms/epoch - 12ms/step\n",
            "Epoch 35/100\n",
            "14/14 - 0s - loss: 1.7975 - accuracy: 0.5047 - 98ms/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "14/14 - 0s - loss: 1.7397 - accuracy: 0.5188 - 100ms/epoch - 7ms/step\n",
            "Epoch 37/100\n",
            "14/14 - 0s - loss: 1.7101 - accuracy: 0.5352 - 96ms/epoch - 7ms/step\n",
            "Epoch 38/100\n",
            "14/14 - 0s - loss: 1.6702 - accuracy: 0.5563 - 106ms/epoch - 8ms/step\n",
            "Epoch 39/100\n",
            "14/14 - 0s - loss: 1.6425 - accuracy: 0.5704 - 92ms/epoch - 7ms/step\n",
            "Epoch 40/100\n",
            "14/14 - 0s - loss: 1.5935 - accuracy: 0.5610 - 93ms/epoch - 7ms/step\n",
            "Epoch 41/100\n",
            "14/14 - 0s - loss: 1.5589 - accuracy: 0.6103 - 93ms/epoch - 7ms/step\n",
            "Epoch 42/100\n",
            "14/14 - 0s - loss: 1.5247 - accuracy: 0.5751 - 113ms/epoch - 8ms/step\n",
            "Epoch 43/100\n",
            "14/14 - 0s - loss: 1.4756 - accuracy: 0.6385 - 97ms/epoch - 7ms/step\n",
            "Epoch 44/100\n",
            "14/14 - 0s - loss: 1.4342 - accuracy: 0.6408 - 96ms/epoch - 7ms/step\n",
            "Epoch 45/100\n",
            "14/14 - 0s - loss: 1.3813 - accuracy: 0.6925 - 95ms/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "14/14 - 0s - loss: 1.3383 - accuracy: 0.6714 - 105ms/epoch - 8ms/step\n",
            "Epoch 47/100\n",
            "14/14 - 0s - loss: 1.3236 - accuracy: 0.6714 - 97ms/epoch - 7ms/step\n",
            "Epoch 48/100\n",
            "14/14 - 0s - loss: 1.2973 - accuracy: 0.6925 - 98ms/epoch - 7ms/step\n",
            "Epoch 49/100\n",
            "14/14 - 0s - loss: 1.2274 - accuracy: 0.6995 - 94ms/epoch - 7ms/step\n",
            "Epoch 50/100\n",
            "14/14 - 0s - loss: 1.2107 - accuracy: 0.6948 - 106ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "14/14 - 0s - loss: 1.1744 - accuracy: 0.7277 - 100ms/epoch - 7ms/step\n",
            "Epoch 52/100\n",
            "14/14 - 0s - loss: 1.1352 - accuracy: 0.7535 - 100ms/epoch - 7ms/step\n",
            "Epoch 53/100\n",
            "14/14 - 0s - loss: 1.0877 - accuracy: 0.7559 - 97ms/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "14/14 - 0s - loss: 1.0585 - accuracy: 0.7535 - 106ms/epoch - 8ms/step\n",
            "Epoch 55/100\n",
            "14/14 - 0s - loss: 1.0316 - accuracy: 0.7817 - 98ms/epoch - 7ms/step\n",
            "Epoch 56/100\n",
            "14/14 - 0s - loss: 0.9972 - accuracy: 0.7817 - 102ms/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "14/14 - 0s - loss: 0.9780 - accuracy: 0.8005 - 97ms/epoch - 7ms/step\n",
            "Epoch 58/100\n",
            "14/14 - 0s - loss: 0.9579 - accuracy: 0.7770 - 108ms/epoch - 8ms/step\n",
            "Epoch 59/100\n",
            "14/14 - 0s - loss: 0.9283 - accuracy: 0.8099 - 94ms/epoch - 7ms/step\n",
            "Epoch 60/100\n",
            "14/14 - 0s - loss: 0.8901 - accuracy: 0.8357 - 95ms/epoch - 7ms/step\n",
            "Epoch 61/100\n",
            "14/14 - 0s - loss: 0.8599 - accuracy: 0.8216 - 114ms/epoch - 8ms/step\n",
            "Epoch 62/100\n",
            "14/14 - 0s - loss: 0.8298 - accuracy: 0.8380 - 99ms/epoch - 7ms/step\n",
            "Epoch 63/100\n",
            "14/14 - 0s - loss: 0.8015 - accuracy: 0.8357 - 96ms/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "14/14 - 0s - loss: 0.7821 - accuracy: 0.8451 - 99ms/epoch - 7ms/step\n",
            "Epoch 65/100\n",
            "14/14 - 0s - loss: 0.7743 - accuracy: 0.8451 - 109ms/epoch - 8ms/step\n",
            "Epoch 66/100\n",
            "14/14 - 0s - loss: 0.7309 - accuracy: 0.8498 - 95ms/epoch - 7ms/step\n",
            "Epoch 67/100\n",
            "14/14 - 0s - loss: 0.7027 - accuracy: 0.8592 - 98ms/epoch - 7ms/step\n",
            "Epoch 68/100\n",
            "14/14 - 0s - loss: 0.6821 - accuracy: 0.8592 - 95ms/epoch - 7ms/step\n",
            "Epoch 69/100\n",
            "14/14 - 0s - loss: 0.6790 - accuracy: 0.8638 - 105ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "14/14 - 0s - loss: 0.6371 - accuracy: 0.8850 - 96ms/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "14/14 - 0s - loss: 0.6249 - accuracy: 0.8826 - 109ms/epoch - 8ms/step\n",
            "Epoch 72/100\n",
            "14/14 - 0s - loss: 0.6000 - accuracy: 0.8967 - 98ms/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "14/14 - 0s - loss: 0.5758 - accuracy: 0.9061 - 109ms/epoch - 8ms/step\n",
            "Epoch 74/100\n",
            "14/14 - 0s - loss: 0.5556 - accuracy: 0.9131 - 98ms/epoch - 7ms/step\n",
            "Epoch 75/100\n",
            "14/14 - 0s - loss: 0.5440 - accuracy: 0.9061 - 104ms/epoch - 7ms/step\n",
            "Epoch 76/100\n",
            "14/14 - 0s - loss: 0.5217 - accuracy: 0.9178 - 100ms/epoch - 7ms/step\n",
            "Epoch 77/100\n",
            "14/14 - 0s - loss: 0.5070 - accuracy: 0.9319 - 98ms/epoch - 7ms/step\n",
            "Epoch 78/100\n",
            "14/14 - 0s - loss: 0.5007 - accuracy: 0.9249 - 95ms/epoch - 7ms/step\n",
            "Epoch 79/100\n",
            "14/14 - 0s - loss: 0.4974 - accuracy: 0.9390 - 96ms/epoch - 7ms/step\n",
            "Epoch 80/100\n",
            "14/14 - 0s - loss: 0.4843 - accuracy: 0.9319 - 95ms/epoch - 7ms/step\n",
            "Epoch 81/100\n",
            "14/14 - 0s - loss: 0.4450 - accuracy: 0.9484 - 116ms/epoch - 8ms/step\n",
            "Epoch 82/100\n",
            "14/14 - 0s - loss: 0.4286 - accuracy: 0.9531 - 95ms/epoch - 7ms/step\n",
            "Epoch 83/100\n",
            "14/14 - 0s - loss: 0.4226 - accuracy: 0.9413 - 95ms/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "14/14 - 0s - loss: 0.4087 - accuracy: 0.9366 - 113ms/epoch - 8ms/step\n",
            "Epoch 85/100\n",
            "14/14 - 0s - loss: 0.3860 - accuracy: 0.9554 - 92ms/epoch - 7ms/step\n",
            "Epoch 86/100\n",
            "14/14 - 0s - loss: 0.3707 - accuracy: 0.9601 - 97ms/epoch - 7ms/step\n",
            "Epoch 87/100\n",
            "14/14 - 0s - loss: 0.3648 - accuracy: 0.9554 - 94ms/epoch - 7ms/step\n",
            "Epoch 88/100\n",
            "14/14 - 0s - loss: 0.3473 - accuracy: 0.9601 - 102ms/epoch - 7ms/step\n",
            "Epoch 89/100\n",
            "14/14 - 0s - loss: 0.3378 - accuracy: 0.9624 - 99ms/epoch - 7ms/step\n",
            "Epoch 90/100\n",
            "14/14 - 0s - loss: 0.3298 - accuracy: 0.9671 - 102ms/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "14/14 - 0s - loss: 0.3155 - accuracy: 0.9671 - 104ms/epoch - 7ms/step\n",
            "Epoch 92/100\n",
            "14/14 - 0s - loss: 0.3087 - accuracy: 0.9695 - 100ms/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "14/14 - 0s - loss: 0.3040 - accuracy: 0.9695 - 94ms/epoch - 7ms/step\n",
            "Epoch 94/100\n",
            "14/14 - 0s - loss: 0.2927 - accuracy: 0.9695 - 100ms/epoch - 7ms/step\n",
            "Epoch 95/100\n",
            "14/14 - 0s - loss: 0.2821 - accuracy: 0.9718 - 97ms/epoch - 7ms/step\n",
            "Epoch 96/100\n",
            "14/14 - 0s - loss: 0.2693 - accuracy: 0.9718 - 106ms/epoch - 8ms/step\n",
            "Epoch 97/100\n",
            "14/14 - 0s - loss: 0.2621 - accuracy: 0.9742 - 99ms/epoch - 7ms/step\n",
            "Epoch 98/100\n",
            "14/14 - 0s - loss: 0.2489 - accuracy: 0.9789 - 95ms/epoch - 7ms/step\n",
            "Epoch 99/100\n",
            "14/14 - 0s - loss: 0.2468 - accuracy: 0.9695 - 98ms/epoch - 7ms/step\n",
            "Epoch 100/100\n",
            "14/14 - 0s - loss: 0.2390 - accuracy: 0.9765 - 113ms/epoch - 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b07018fc7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 생성하는 함수\n",
        "# 문자열을 입력하면, 해당 문자열로부터 다음 문자를 예측하는 것을 반복\n",
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "\n",
        "    # 초기 시퀀스\n",
        "    init_text = seed_text\n",
        "    sentence = ''\n",
        "\n",
        "    # 다음 문자 예측은 총 n번만 반복.\n",
        "    for _ in range(n):\n",
        "        encoded = [char_to_index[char] for char in seed_text] # 현재 시퀀스에 대한 정수 인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') # 데이터에 대한 패딩\n",
        "        encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "\n",
        "        # 입력한 X(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 문자)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for char, index in char_to_index.items():\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 시퀀스 + 예측 문자를 현재 시퀀스로 변경\n",
        "        seed_text = seed_text + char\n",
        "\n",
        "        # 예측 문자를 문장에 저장\n",
        "        sentence = sentence + char\n",
        "\n",
        "    # n번의 다음 문자 예측이 끝나면 최종 완성된 문장을 리턴.\n",
        "    sentence = init_text + sentence\n",
        "    return sentence\n",
        "\n",
        "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-OIE1w9utMB",
        "outputId": "aca6b6a5-031a-4ba5-a6c6-44924bc20f7b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to use words about beer. But when I start to da\n"
          ]
        }
      ]
    }
  ]
}