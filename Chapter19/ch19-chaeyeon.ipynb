{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c73eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5334f87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM의 크기(shape) : (4, 9)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])\n",
    "print('DTM의 크기(shape) :', np.shape(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563750fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 U :\n",
      "[[-0.24  0.75  0.   -0.62]\n",
      " [-0.51  0.44 -0.    0.74]\n",
      " [-0.83 -0.49 -0.   -0.27]\n",
      " [-0.   -0.    1.    0.  ]]\n",
      "행렬 U의 크기(shape) : (4, 4)\n"
     ]
    }
   ],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices = True)\n",
    "print('행렬 U :')\n",
    "print(U.round(2))\n",
    "print('행렬 U의 크기(shape) :',np.shape(U))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d17aa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특이값 벡터 :\n",
      "[2.69 2.05 1.73 0.77]\n",
      "특이값 벡터의 크기(shape) : (4,)\n"
     ]
    }
   ],
   "source": [
    "print('특이값 벡터 :')\n",
    "print(s.round(2))\n",
    "print('특이값 벡터의 크기(shape) :',np.shape(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b63e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대각 행렬 S :\n",
      "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n",
      "대각 행렬의 크기(shape) :\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "# 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
    "S = np.zeros((4, 9))\n",
    "\n",
    "# 특이값을 대각행렬에 삽입\n",
    "S[:4, :4] = np.diag(s)\n",
    "\n",
    "print('대각 행렬 S :')\n",
    "print(S.round(2))\n",
    "\n",
    "print('대각 행렬의 크기(shape) :')\n",
    "print(np.shape(S))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f475440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "직교행렬 VT :\n",
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n",
      "직교 행렬 VT의 크기(shape) :\n",
      "(9, 9)\n"
     ]
    }
   ],
   "source": [
    "print('직교행렬 VT :')\n",
    "print(VT.round(2))\n",
    "\n",
    "print('직교 행렬 VT의 크기(shape) :')\n",
    "print(np.shape(VT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e57a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8c59a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대각 행렬 S :\n",
      "[[2.69 0.  ]\n",
      " [0.   2.05]]\n"
     ]
    }
   ],
   "source": [
    "# 특이값 상위 2개만 보존\n",
    "S = S[:2,:2]\n",
    "\n",
    "print('대각 행렬 S :')\n",
    "print(S.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ee5268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 U :\n",
      "[[-0.24  0.75]\n",
      " [-0.51  0.44]\n",
      " [-0.83 -0.49]\n",
      " [-0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "U = U[:,:2]\n",
    "print('행렬 U :')\n",
    "print(U.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a402436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "직교행렬 VT :\n",
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "VT = VT[:2,:]\n",
    "print('직교행렬 VT :')\n",
    "print(VT.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be89e575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n",
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "A_prime = np.dot(np.dot(U,S), VT)\n",
    "print(A)\n",
    "print(A_prime.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db35cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe2fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 수 : 11314\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "print('샘플의 수 :',len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "362c8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68123c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aeb072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae27a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yeah, expect people read faq, etc. actually accept hard atheism? need little leap faith, jimmy. your logic runs steam! jim, sorry can't pity you, jim. sorry that have these feelings denial about faith need well, just pretend that will happily ever after anyway. maybe start newsgroup, alt.atheist.hard, won't bummin' much? bye-bye, jim. don't forget your flintstone's chewables! bake timmons,\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e2f0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK로부터 불용어를 받아온다.\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "# 불용어를 제거합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fdbc6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah,', 'expect', 'people', 'read', 'faq,', 'etc.', 'actually', 'accept', 'hard', 'atheism?', 'need', 'little', 'leap', 'faith,', 'jimmy.', 'logic', 'runs', 'steam!', 'jim,', 'sorry', \"can't\", 'pity', 'you,', 'jim.', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well,', 'pretend', 'happily', 'ever', 'anyway.', 'maybe', 'start', 'newsgroup,', 'alt.atheist.hard,', \"bummin'\", 'much?', 'bye-bye,', 'jim.', 'forget', \"flintstone's\", 'chewables!', 'bake', 'timmons,']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_doc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "348ce23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역토큰화 (토큰화 작업을 역으로 되돌림)\n",
    "detokenized_doc = []\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "news_df['clean_doc'] = detokenized_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f64eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yeah, expect people read faq, etc. actually accept hard atheism? need little leap faith, jimmy. logic runs steam! jim, sorry can't pity you, jim. sorry feelings denial faith need well, pretend happily ever anyway. maybe start newsgroup, alt.atheist.hard, bummin' much? bye-bye, jim. forget flintstone's chewables! bake timmons,\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "607ec6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬의 크기 : (11314, 1000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000, # 상위 1,000개의 단어를 보존 \n",
    "max_df = 0.5, smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "\n",
    "# TF-IDF 행렬의 크기 확인\n",
    "print('TF-IDF 행렬의 크기 :',X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74bf9897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0417a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(svd_model.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b15567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('like', 0.2085), ('know', 0.19656), ('people', 0.1912), ('think', 0.17523), ('good', 0.14902)]\n",
      "Topic 2: [('thanks', 0.31338), ('windows', 0.27934), ('card', 0.17289), ('drive', 0.16141), ('mail', 0.14507)]\n",
      "Topic 3: [('game', 0.36553), ('team', 0.3133), ('year', 0.28465), ('games', 0.23048), ('season', 0.17026)]\n",
      "Topic 4: [('edu', 0.50341), ('thanks', 0.25409), ('mail', 0.1758), ('com', 0.11498), ('email', 0.11166)]\n",
      "Topic 5: [('edu', 0.49934), ('drive', 0.24972), ('com', 0.10645), ('sale', 0.10616), ('soon', 0.09199)]\n",
      "Topic 6: [('drive', 0.40102), ('thanks', 0.34667), ('know', 0.27592), ('scsi', 0.13765), ('mail', 0.11332)]\n",
      "Topic 7: [('chip', 0.21565), ('government', 0.20249), ('like', 0.17148), ('encryption', 0.14654), ('clipper', 0.14478)]\n",
      "Topic 8: [('like', 0.64668), ('edu', 0.31439), ('bike', 0.12683), ('know', 0.12403), ('think', 0.11547)]\n",
      "Topic 9: [('card', 0.3572), ('sale', 0.17543), ('00', 0.17496), ('video', 0.16994), ('good', 0.15574)]\n",
      "Topic 10: [('card', 0.45093), ('people', 0.35248), ('know', 0.26213), ('video', 0.20438), ('edu', 0.18018)]\n",
      "Topic 11: [('like', 0.53784), ('people', 0.29344), ('windows', 0.14585), ('drive', 0.14199), ('game', 0.138)]\n",
      "Topic 12: [('think', 0.73098), ('thanks', 0.19253), ('people', 0.12027), ('mail', 0.11436), ('good', 0.11292)]\n",
      "Topic 13: [('know', 0.21625), ('chip', 0.21482), ('jesus', 0.19227), ('game', 0.1597), ('think', 0.15475)]\n",
      "Topic 14: [('know', 0.33277), ('good', 0.31777), ('people', 0.22055), ('windows', 0.21856), ('file', 0.20588)]\n",
      "Topic 15: [('good', 0.38909), ('chip', 0.22814), ('people', 0.15098), ('clipper', 0.14368), ('encryption', 0.14025)]\n",
      "Topic 16: [('com', 0.6569), ('ve', 0.34058), ('people', 0.20544), ('seen', 0.0979), ('list', 0.09405)]\n",
      "Topic 17: [('ve', 0.38594), ('space', 0.30952), ('people', 0.28754), ('seen', 0.13734), ('heard', 0.13676)]\n",
      "Topic 18: [('good', 0.32101), ('israel', 0.25517), ('card', 0.24702), ('com', 0.1984), ('israeli', 0.13667)]\n",
      "Topic 19: [('ve', 0.54441), ('israel', 0.20771), ('seen', 0.17641), ('00', 0.14313), ('heard', 0.13857)]\n",
      "Topic 20: [('time', 0.34123), ('bike', 0.28176), ('right', 0.25465), ('file', 0.20011), ('need', 0.19803)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ana\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "get_topics(svd_model.components_,terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb95fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [well, sure, story, seem, biased., disagree, s...\n",
       "1    [yeah,, expect, people, read, faq,, etc., actu...\n",
       "2    [although, realize, principle, strongest, poin...\n",
       "3    [notwithstanding, legitimate, fuss, proposal,,...\n",
       "4    [well,, change, scoring, playoff, pool., unfor...\n",
       "Name: clean_doc, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77d619a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 2), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[1]) # 수행된 결과에서 두번째 뉴스 출력. 첫번째 문서의 인덱스는 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f134231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye-bye,\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[66])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "045f2b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181856"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc466176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.006*\"symbol\" + 0.004*\"ideas?\" + 0.003*\"powerpc\" + 0.003*\"outline\"')\n",
      "(1, '0.004*\"stats\" + 0.004*\"candida\" + 0.003*\"rear\" + 0.003*\"window.\"')\n",
      "(2, '0.008*\"file\" + 0.007*\"available\" + 0.006*\"program\" + 0.006*\"also\"')\n",
      "(3, '0.012*\"drive\" + 0.012*\"anyone\" + 0.011*\"know\" + 0.011*\"please\"')\n",
      "(4, '0.016*\"israel\" + 0.015*\"israeli\" + 0.012*\"jews\" + 0.011*\"health\"')\n",
      "(5, '0.004*\"financial\" + 0.003*\"device.\" + 0.003*\"fixes\" + 0.002*\"segment\"')\n",
      "(6, '0.013*\"would\" + 0.010*\"people\" + 0.006*\"think\" + 0.006*\"know\"')\n",
      "(7, '0.010*\"----\" + 0.010*\"myers:\" + 0.006*\"simms\" + 0.005*\"calgary\"')\n",
      "(8, '0.003*\"eaten\" + 0.003*\"ciphertext\" + 0.002*\"countersteering\" + 0.002*\"hours.\"')\n",
      "(9, '0.010*\"water\" + 0.004*\"quebec\" + 0.003*\"april\" + 0.003*\"exhaust\"')\n",
      "(10, '0.203*\"max>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'\" + 0.006*\"wire\" + 0.006*\"ground\" + 0.004*\"allocation\"')\n",
      "(11, '0.013*\"period\" + 0.009*\"power\" + 0.008*\"hockey\" + 0.007*\"kings\"')\n",
      "(12, '0.008*\"scsi-2\" + 0.007*\"scsi-1\" + 0.007*\"pens\" + 0.003*\"caps\"')\n",
      "(13, '0.007*\"gordon\" + 0.007*\"----------------------------------------------------------------------------\" + 0.007*\"banks\" + 0.007*\"surrender\"')\n",
      "(14, '0.012*\"would\" + 0.009*\"like\" + 0.007*\"think\" + 0.007*\"good\"')\n",
      "(15, '0.016*\"55.0\" + 0.003*\"suck\" + 0.002*\"gifs\" + 0.002*\"employer\"')\n",
      "(16, '0.019*\"file:\" + 0.006*\"------\" + 0.004*\"injuries\" + 0.003*\"john\\'s\"')\n",
      "(17, '0.009*\"government\" + 0.007*\"people\" + 0.005*\"public\" + 0.004*\"would\"')\n",
      "(18, '0.003*\"judges\" + 0.003*\"sabbath\" + 0.003*\"cleveland\" + 0.002*\"baud\"')\n",
      "(19, '0.015*\"armenian\" + 0.011*\"armenians\" + 0.011*\"turkish\" + 0.009*\"went\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20 # 20개의 토픽, k=20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5567638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.006*\"symbol\" + 0.004*\"ideas?\" + 0.003*\"powerpc\" + 0.003*\"outline\" + 0.003*\"driver,\" + 0.002*\"truetype\" + 0.002*\"accelerators\" + 0.002*\"ncsa\" + 0.002*\"rs/6000\" + 0.002*\"investigating\"'), (1, '0.004*\"stats\" + 0.004*\"candida\" + 0.003*\"rear\" + 0.003*\"window.\" + 0.003*\"toyota\" + 0.003*\"reserve\" + 0.002*\"diet\" + 0.002*\"folks,\" + 0.002*\"hung\" + 0.002*\"terminal\"'), (2, '0.008*\"file\" + 0.007*\"available\" + 0.006*\"program\" + 0.006*\"also\" + 0.005*\"information\" + 0.005*\"data\" + 0.005*\"space\" + 0.005*\"using\" + 0.004*\"version\" + 0.004*\"number\"'), (3, '0.012*\"drive\" + 0.012*\"anyone\" + 0.011*\"know\" + 0.011*\"please\" + 0.009*\"thanks\" + 0.009*\"disk\" + 0.009*\"windows\" + 0.009*\"card\" + 0.008*\"would\" + 0.007*\"system\"'), (4, '0.016*\"israel\" + 0.015*\"israeli\" + 0.012*\"jews\" + 0.011*\"health\" + 0.009*\"medical\" + 0.008*\"arab\" + 0.006*\"april\" + 0.006*\"university\" + 0.006*\"jewish\" + 0.006*\"among\"'), (5, '0.004*\"financial\" + 0.003*\"device.\" + 0.003*\"fixes\" + 0.002*\"segment\" + 0.002*\"nick\" + 0.002*\"speedstar\" + 0.002*\"walls\" + 0.002*\"deskjet\" + 0.002*\"drops\" + 0.002*\"deciding\"'), (6, '0.013*\"would\" + 0.010*\"people\" + 0.006*\"think\" + 0.006*\"know\" + 0.006*\"like\" + 0.005*\"even\" + 0.005*\"many\" + 0.005*\"believe\" + 0.004*\"could\" + 0.004*\"also\"'), (7, '0.010*\"----\" + 0.010*\"myers:\" + 0.006*\"simms\" + 0.005*\"calgary\" + 0.005*\"cubs\" + 0.005*\"lost\" + 0.004*\"braves\" + 0.004*\"montreal\" + 0.003*\"vram\" + 0.003*\"fallacy\"'), (8, '0.003*\"eaten\" + 0.003*\"ciphertext\" + 0.002*\"countersteering\" + 0.002*\"hours.\" + 0.002*\"entity\" + 0.002*\"sockets\" + 0.002*\"casualties\" + 0.002*\"brains\" + 0.002*\"corn\" + 0.002*\"foreground\"'), (9, '0.010*\"water\" + 0.004*\"quebec\" + 0.003*\"april\" + 0.003*\"exhaust\" + 0.003*\"condition.\" + 0.003*\"vitamin\" + 0.003*\"broadcast\" + 0.002*\"league.\" + 0.002*\"captain\" + 0.002*\"cooper\"'), (10, '0.203*\"max>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'ax>\\'\" + 0.006*\"wire\" + 0.006*\"ground\" + 0.004*\"allocation\" + 0.003*\"neutral\" + 0.003*\"*******\" + 0.003*\"circuits\" + 0.003*\"francis\" + 0.003*\"yankees\" + 0.003*\"reds\"'), (11, '0.013*\"period\" + 0.009*\"power\" + 0.008*\"hockey\" + 0.007*\"kings\" + 0.007*\"---------------\" + 0.007*\"scorer\" + 0.007*\"puck\" + 0.006*\"play:\" + 0.005*\"second\" + 0.005*\"first\"'), (12, '0.008*\"scsi-2\" + 0.007*\"scsi-1\" + 0.007*\"pens\" + 0.003*\"caps\" + 0.003*\"asynchronous\" + 0.002*\"habs\" + 0.002*\"16-bit\" + 0.002*\"prize\" + 0.002*\"nords\" + 0.002*\"burst\"'), (13, '0.007*\"gordon\" + 0.007*\"----------------------------------------------------------------------------\" + 0.007*\"banks\" + 0.007*\"surrender\" + 0.006*\"norton\" + 0.005*\"intellect,\" + 0.005*\"shameful\" + 0.005*\"chastity\" + 0.005*\"n3jxp\" + 0.005*\"\"skepticism\"'), (14, '0.012*\"would\" + 0.009*\"like\" + 0.007*\"think\" + 0.007*\"good\" + 0.005*\"going\" + 0.005*\"much\" + 0.005*\"last\" + 0.005*\"time\" + 0.005*\"know\" + 0.005*\"back\"'), (15, '0.016*\"55.0\" + 0.003*\"suck\" + 0.002*\"gifs\" + 0.002*\"employer\" + 0.002*\"cocaine\" + 0.002*\"telecom\" + 0.002*\"secure.\" + 0.002*\"information?\" + 0.001*\"receives\" + 0.001*\"argv,\"'), (16, '0.019*\"file:\" + 0.006*\"------\" + 0.004*\"injuries\" + 0.003*\"john\\'s\" + 0.003*\"hong\" + 0.003*\"player.\" + 0.002*\"moncton\" + 0.002*\"kong\" + 0.002*\"summaries\" + 0.002*\"rochester\"'), (17, '0.009*\"government\" + 0.007*\"people\" + 0.005*\"public\" + 0.004*\"would\" + 0.004*\"encryption\" + 0.004*\"state\" + 0.004*\"president\" + 0.003*\"security\" + 0.003*\"u.s.\" + 0.003*\"rights\"'), (18, '0.003*\"judges\" + 0.003*\"sabbath\" + 0.003*\"cleveland\" + 0.002*\"baud\" + 0.002*\"64-bit\" + 0.002*\"cooling\" + 0.002*\"bury\" + 0.002*\">the\" + 0.002*\"quality.\" + 0.002*\"latin\"'), (19, '0.015*\"armenian\" + 0.011*\"armenians\" + 0.011*\"turkish\" + 0.009*\"went\" + 0.006*\"said,\" + 0.006*\"greek\" + 0.006*\"came\" + 0.005*\"killed\" + 0.005*\"said\" + 0.005*\"people\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8db94490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\ana\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\ana\\lib\\site-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: jinja2 in c:\\ana\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\ana\\lib\\site-packages (from pyLDAvis) (1.3.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\ana\\lib\\site-packages (from pyLDAvis) (2.1.2)\n",
      "Requirement already satisfied: numexpr in c:\\ana\\lib\\site-packages (from pyLDAvis) (2.8.3)\n",
      "Requirement already satisfied: gensim in c:\\ana\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: scipy in c:\\ana\\lib\\site-packages (from pyLDAvis) (1.9.1)\n",
      "Requirement already satisfied: setuptools in c:\\ana\\lib\\site-packages (from pyLDAvis) (63.4.1)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\ana\\lib\\site-packages (from pyLDAvis) (1.24.4)\n",
      "Requirement already satisfied: funcy in c:\\ana\\lib\\site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ana\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ana\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\ana\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\ana\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\ana\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\ana\\lib\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: six>=1.5 in c:\\ana\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\ana\\lib\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a85da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el80922224370416656218738041\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el80922224370416656218738041_data = {\"mdsDat\": {\"x\": [-0.3885421624299881, -0.37261835740539645, -0.33227118111373904, -0.267637843855413, -0.1870599778768747, -0.06071539529628262, 0.06742269486171687, 0.1146288774549652, 0.09642383995807219, 0.10526330203818918, 0.11193540409914482, 0.11534588367295191, 0.11789229001399923, 0.1225992570604033, 0.12558258424780297, 0.12695181337213993, 0.12630170523102813, 0.12581133222495403, 0.12681834714946433, 0.12586758659286212], \"y\": [0.047786054148068954, 0.02653282990847195, -0.13121718235339538, 0.16538038118100293, -0.24929105186303088, 0.17781202291259218, 0.046474759660042796, -0.014244589317904436, -0.0022319399950062623, -0.008758925466698153, -0.005401747548129082, -0.009489885398703603, -0.007439609740578145, -0.006937358380336798, -0.004190841062884311, -0.005010513054933713, -0.004925645948318106, -0.005724227152173814, -0.004434551785202439, -0.004687978742884124], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [25.156415530326186, 21.680904252049217, 20.948372555552915, 11.579381774559176, 5.44969386860141, 3.3212902262867265, 1.7732620394629095, 1.6063111918024613, 1.335221322924138, 1.2493218734604854, 1.0807995495702514, 0.9738915141875001, 0.9109861014878938, 0.715444850220097, 0.7151387894320066, 0.37375381612298986, 0.3606208916445438, 0.2703899723709176, 0.2518810001220143, 0.24691887981616012]}, \"tinfo\": {\"Term\": [\"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\", \"know\", \"would\", \"people\", \"anyone\", \"please\", \"file\", \"like\", \"government\", \"think\", \"drive\", \"power\", \"program\", \"first\", \"available\", \"windows\", \"system\", \"thanks\", \"said\", \"armenian\", \"need\", \"team\", \"space\", \"went\", \"i've\", \"problem\", \"using\", \"disk\", \"second\", \"hard\", \"jesus\", \"christian\", \"bible\", \"christians\", \"church\", \"words\", \"god.\", \"faith\", \"moral\", \"char\", \"religion\", \"christ\", \"god's\", \"holy\", \"god,\", \"pain\", \"christianity\", \"belief\", \"atheists\", \"beliefs\", \"arguments\", \"matthew\", \"islamic\", \"eternal\", \"lord\", \"morality\", \"catholic\", \"biblical\", \"exist.\", \"judas\", \"explain\", \"koresh\", \"evidence\", \"claim\", \"truth\", \"argument\", \"religious\", \"life\", \"believe\", \"true\", \"word\", \"people\", \"accept\", \"mean\", \"human\", \"nothing\", \"would\", \"things\", \"many\", \"even\", \"question\", \"think\", \"know\", \"must\", \"something\", \"whether\", \"seems\", \"read\", \"point\", \"find\", \"like\", \"could\", \"never\", \"someone\", \"really\", \"make\", \"also\", \"want\", \"much\", \"without\", \"time\", \"take\", \"since\", \"good\", \"might\", \"bike\", \"average\", \"cars\", \"playing\", \"baseball\", \"watching\", \"insurance\", \"ride\", \"ball\", \"game,\", \"fans\", \"riding\", \"scored\", \"paying\", \"score\", \"car.\", \"career\", \"canadian\", \"sports\", \"pitching\", \"chain\", \"games.\", \"he'll\", \"defensive\", \"period.\", \"biggest\", \"violent\", \"motorcycle\", \"honda\", \"owner\", \"guns\", \"players\", \"player\", \"jobs\", \"guys\", \"game\", \"money\", \"driving\", \"he's\", \"league\", \"team\", \"games\", \"last\", \"front\", \"year\", \"going\", \"play\", \"year.\", \"mike\", \"back\", \"we're\", \"home\", \"good\", \"better\", \"getting\", \"think\", \"around\", \"like\", \"well,\", \"much\", \"would\", \"that's\", \"time\", \"little\", \"next\", \"take\", \"really\", \"still\", \"make\", \"could\", \"years\", \"first\", \"know\", \"even\", \"right\", \"probably\", \"i've\", \"also\", \"since\", \"well\", \"want\", \"can't\", \"file\", \"program\", \"space\", \"files\", \"----------------------------------------------------------------------\", \"entry\", \"server\", \"programs\", \"anonymous\", \"application\", \"user\", \"widget\", \"motif\", \"directory\", \"program,\", \"entries\", \"jpeg\", \"applications\", \"satellite\", \"export\", \"site\", \"programming\", \"mailing\", \"resource\", \"functions\", \"inc.\", \"sites\", \"lunar\", \"font\", \"versions\", \"available\", \"window\", \"subject:\", \"image\", \"display\", \"data\", \"code\", \"users\", \"version\", \"output\", \"information\", \"software\", \"nasa\", \"mail\", \"source\", \"send\", \"list\", \"using\", \"include\", \"computer\", \"number\", \"also\", \"system\", \"email\", \"current\", \"line\", \"used\", \"following\", \"please\", \"government\", \"encryption\", \"federal\", \"political\", \"clipper\", \"court\", \"protect\", \"secret\", \"turkey\", \"weapons\", \"enforcement\", \"citizens\", \"congress\", \"escrow\", \"secure\", \"arms\", \"henrik]\", \"nazi\", \"countries\", \"encrypted\", \"amendment\", \"agencies\", \"constitution\", \"government.\", \"privacy\", \"europe\", \"proposal\", \"wiretap\", \"war.\", \"cryptography\", \"administration\", \"policy\", \"rights\", \"firearms\", \"military\", \"clinton\", \"crypto\", \"legal\", \"security\", \"private\", \"president\", \"united\", \"u.s.\", \"states\", \"public\", \"police\", \"state\", \"crime\", \"american\", \"chip\", \"laws\", \"people\", \"national\", \"keys\", \"would\", \"right\", \"could\", \"system\", \"number\", \"even\", \"first\", \"card\", \"scsi\", \"apple\", \"monitor\", \"controller\", \"drives\", \"printer\", \"drive.\", \"card.\", \"bios\", \"advance.\", \"price:\", \"motherboard\", \"drive,\", \"offer.\", \"card,\", \"boot\", \"vesa\", \"voltage\", \"cache\", \"stereo\", \"adapter\", \"nubus\", \"diamond\", \"adaptec\", \"svga\", \"macs\", \"connector\", \"jumper\", \"cursor\", \"battery\", \"modem\", \"floppy\", \"cable\", \"drive\", \"disk\", \"thanks.\", \"video\", \"upgrade\", \"tape\", \"cards\", \"driver\", \"thanks\", \"memory\", \"drivers\", \"port\", \"windows\", \"mouse\", \"anyone\", \"please\", \"hard\", \"sound\", \"know\", \"system\", \"problem\", \"need\", \"anybody\", \"i've\", \"would\", \"like\", \"using\", \"work\", \"looking\", \"could\", \"used\", \"armenian\", \"armenians\", \"turkish\", \"turks\", \"armenia\", \"genocide\", \"azerbaijan\", \"azerbaijani\", \"apartment\", \"ottoman\", \"daughter\", \"serdar\", \"azeri\", \"argic\", \"sumgait\", \"x-soviet\", \"crowd\", \"massacre\", \"greece\", \"azerbaijanis\", \"mamma\", \"greeks\", \"cyprus\", \"baku\", \"bullets\", \"wounded\", \"floor,\", \"apartment.\", \"building.\", \"slaughter\", \"greek\", \"source:\", \"says,\", \"father,\", \"soldiers\", \"killed\", \"went\", \"said,\", \"muslim\", \"burned\", \"came\", \"started\", \"took\", \"women\", \"told\", \"said\", \"city\", \"there,\", \"people\", \"three\", \"left\", \"dead\", \"russian\", \"lived\", \"children\", \"say,\", \"israel\", \"israeli\", \"arab\", \"palestinian\", \"smokeless\", \"cancer\", \"arabs\", \"guidelines\", \"hicnet\", \"jews.\", \"lebanese\", \"israelis\", \"clinical\", \"lebanon\", \"offense\", \"gaza\", \"palestinians\", \"illness\", \"stat\", \"scores\", \"israel's\", \"import\", \"syria\", \"island.\", \"palestine\", \"==================================================================\", \"innings\", \"nonsense.\", \"rolling\", \"documentary\", \"newsletter\", \"aged\", \"israel.\", \"jews\", \"health\", \"york,\", \"medical\", \"francisco\", \"washington,\", \"jewish\", \"page\", \"center\", \"april\", \"west\", \"among\", \"university\", \"1993\", \"california\", \"national\", \"research\", \"disease\", \"reported\", \"picture\", \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\", \"allocation\", \"*******\", \"circuits\", \"francis\", \"yankees\", \"reds\", \"patents\", \"(205)\", \"grounded\", \"cincinnati\", \"uucp:\", \"formatted\", \"chipset\", \"nearest\", \"resistor\", \"huntsville,\", \"harris\", \"sensor\", \"intergraph\", \"inputs\", \"runs,\", \"royals\", \"pairs\", \"office)\", \"awards\", \"cup.\", \"tape,\", \"bytes.\", \"software?\", \"player,\", \"2400\", \"outlet\", \"runner\", \"wire\", \"------------\", \"neutral\", \"ground\", \"--------\", \"cross\", \"bytes\", \"part\", \"unit\", \"connected\", \"internet:\", \"scorer\", \"puck\", \"play:\", \"flyers\", \"tampa\", \"wins\", \"jets\", \"-----------------------------------------\", \"period:\", \"detroit,\", \"blues\", \"buffalo\", \"winnipeg\", \"hartford,\", \"lemieux\", \"lindros\", \"hartford\", \"[kk]\", \"scoring.\", \"defenseman\", \"tommy\", \"gretzky\", \"--------------------------------------------------------------------------------\", \"edmonton\", \"intentional\", \"norris\", \"gilmour\", \"sabres\", \"carson\", \"(unassisted)\", \"leafs\", \"kings\", \"islanders\", \"ottawa\", \"---------------\", \"detroit\", \"jersey\", \"period\", \"vancouver\", \"philadelphia\", \"minnesota\", \"hockey\", \"pittsburgh\", \"shots\", \"rangers\", \"power\", \"division\", \"louis\", \"third\", \"boston\", \"goal\", \"chicago\", \"team\", \"second\", \"season.\", \"first\", \"play\", \"candida\", \"toyota\", \"diet\", \"folks,\", \"prompt\", \"laugh\", \"sequences\", \"window.\", \"sizes\", \"(david\", \"reserve\", \"igor\", \"mainstream\", \"tigers\", \"dealt\", \"'cause\", \"(formerly\", \"(sorry,\", \"tubes\", \"crashes\", \"helicopter\", \"keller\", \"throttle\", \"fractal\", \"excited\", \"then?\", \"robinson\", \"refering\", \"keyboard,\", \"adjective\", \"keyboard.\", \"nothing,\", \"stats\", \"layout\", \"rear\", \"hung\", \"shit\", \"for?\", \"------------------------------------------------------------------------\", \"road.\", \"atlanta\", \"batting\", \"brake\", \"terminal\", \"let's\", \"utility\", \"shift\", \"pick\", \"quebec\", \"exhaust\", \"vitamin\", \"league.\", \"cooper\", \"blew\", \"kidney\", \"set.\", \"penguins\", \"sea.\", \"reactions\", \"sampling\", \"girlfriend\", \"locations\", \"blessed\", \"deaf\", \"conductor\", \"spin\", \"liability\", \"meanwhile,\", \"bronx\", \"white,\", \"yassin\", \"stadium\", \"5.00\", \"manhattan\", \"sides.\", \"multi\", \"hard,\", \"proceeds\", \"broadcast\", \"water\", \"steering\", \"captain\", \"pitched\", \"condition.\", \"temperature\", \"switzerland\", \"april\", \"relay\", \"engine\", \"myers:\", \"calgary\", \"cubs\", \"simms\", \"vram\", \"fallacy\", \"slots\", \"simm\", \"players,\", \"president's\", \"angels\", \"giants\", \"mild\", \"0.333\", \"256k\", \"lost.\", \"braves\", \"clark\", \".500\", \"concentrate\", \"nhl.\", \"spots\", \"championships\", \"finnish\", \"nerve\", \"breaker\", \"anywhere.\", \"finland\", \"titled\", \"murdering\", \"----\", \"coach\", \"sweden\", \"montreal\", \"lost\", \"toronto\", \"standings\", \"risc\", \"canada\", \"diego\", \"york\", \"league\", \"judges\", \"cleveland\", \"64-bit\", \"quality.\", \"latin\", \"sheets\", \"creed\", \"rejecting\", \"approval\", \"*very*\", \"christians.\", \"entries,\", \"implementations\", \"enhancement\", \"methanol\", \"ghetto\", \"definition,\", \"conscious\", \"baud\", \"printers\", \"steam\", \"wipe\", \"diff\", \"warsaw\", \"given,\", \"claims.\", \"abused\", \"phigs\", \"terminated\", \"hitter\", \"cooling\", \"sabbath\", \">the\", \"promises\", \"bury\", \"son.\", \"reality,\", \"nuclear\", \"gordon\", \"surrender\", \"intellect,\", \"shameful\", \"\\\"skepticism\", \"chastity\", \"n3jxp\", \"geb@cadre.dsl.pitt.edu\", \"soon.\\\"\", \"norton\", \"kent\", \"#define\", \"----------------------------------------------------------------------------\", \"laptop\", \"temp\", \"seagate\", \"retail\", \"x-windows\", \"twin\", \"allocated\", \"click\", \"configure\", \"burnt\", \"solaris\", \"miles.\", \"compilers\", \"suter\", \"calgary,\", \"cd's\", \"(version\", \"banks\", \"cheers,\", \"column\", \"terminal\", \"injuries\", \"hong\", \"player.\", \"moncton\", \"kong\", \"summaries\", \"file:\", \"providence\", \"(first\", \"utica\", \"adirondack\", \"binghamton\", \"winmarks\", \"breton\", \"evolutionary\", \"fredericton\", \"bowl\", \"lease\", \"embrace\", \"generated,\", \"hood\", \"infantile\", \"cereals\", \"caught.\", \"1-0)\", \"drafting\", \"palestinean\", \"arose\", \"coated\", \"out\\\"\", \"john's\", \"halifax\", \"cape\", \"rochester\", \"------\", \"springfield\", \"baltimore\", \"----------\", \"financial\", \"device.\", \"fixes\", \"segment\", \"speedstar\", \"walls\", \"deskjet\", \"drops\", \"deciding\", \"printer,\", \"challenges\", \"inspection\", \"micro\", \"c650\", \"eggs\", \"protects\", \"etc?\", \"firms\", \"love.\", \"brigham\", \"widget,\", \"method,\", \"(compared\", \"1069\", \"biker)\", \"allah,\", \"completely.\", \"configuration.\", \"m'lud.\", \"wibbled:\", \"---------------------------------------------------------------------\", \"translations\", \"nick\", \"selective\", \"concise\", \"55.0\", \"gifs\", \"employer\", \"cocaine\", \"telecom\", \"information?\", \"receives\", \"argv,\", \"location:\", \"flags\", \"enjoy!\", \"anyways.\", \"ditto\", \"restart\", \"pulse\", \"dennis,\", \"losses\", \"workers,\", \"yep.\", \"omnipotent\", \"^^^^^^^^^^^\", \"governed\", \"chevrolet\", \"(403)\", \"462-0666\", \"idacom\", \"andrew@idacom.hp.com\", \"clearance\", \"automatics\", \"overlap\", \"secure.\", \"suck\", \"wireless\", \"respected\", \"yamaha\", \"andrew\", \"ext.\", \"scsi-2\", \"scsi-1\", \"pens\", \"asynchronous\", \"habs\", \"prize\", \"nords\", \"--clh]\", \"isles\", \"guitar\", \"suspect.\", \"obfuscation\", \"(mydisplay,\", \"\\\"normal\\\"\", \"kidding,\", \"init\", \"equal.\", \"weighs\", \"bookstore\", \"info?\", \"amish\", \"writing.\", \"meters.\", \"10mb/s\", \"it....\", \"sing\", \"+====================================================================+\", \"thanx.\", \"bike?\", \"none,\", \"16-bit\", \"caps\", \"corel\", \"synchronous\", \"burst\", \"creative\", \"8-bit\", \"norway\", \"symbol\", \"ideas?\", \"powerpc\", \"outline\", \"driver,\", \"truetype\", \"accelerators\", \"ncsa\", \"investigating\", \"_______________________________________________________________________________\", \"packard\", \"affair\", \"executing\", \"bold\", \"wireframe\", \"50mhz\", \"joysticks\", \"parish\", \"hewlett\", \"_/_/_/\", \"xterm.\", \"workstation.\", \"rectangular\", \"shape,\", \"object,\", \"antibiotic\", \"keypad\", \"motherboards\", \"ample\", \"vaginal\", \"rs/6000\", \"fonts.\", \"eaten\", \"ciphertext\", \"countersteering\", \"hours.\", \"entity\", \"sockets\", \"casualties\", \"brains\", \"corn\", \"foreground\", \"invalid\", \"osf/motif\", \"verdict\", \"insurance.\", \"token\", \"supply.\", \"similarity\", \"-------------------------------\", \"tonight,\", \"initiation\", \"gangs\", \"gxxor\", \"mydisplay,\", \"nerves\", \"compatible.\", \"goaltending\", \"fund.\", \"zeos\", \"spectacular\", \"mahan\", \"well).\", \"steer\", \"washer\"], \"Freq\": [3417.0, 3430.0, 7197.0, 4020.0, 1703.0, 1486.0, 1656.0, 4332.0, 1098.0, 3327.0, 810.0, 959.0, 1391.0, 2202.0, 1457.0, 916.0, 1540.0, 785.0, 1464.0, 517.0, 1873.0, 637.0, 1113.0, 605.0, 1482.0, 1238.0, 1754.0, 591.0, 920.0, 789.0, 756.77688798549, 485.5713244576343, 443.2088410645212, 375.89119079655075, 350.4081560089697, 306.16962851730267, 268.28786008152684, 266.06048799983785, 263.34944445715706, 255.55276623322447, 250.63406689799658, 230.79012131500775, 227.58988943853544, 210.08540526927078, 206.9020006232041, 198.8085638181184, 195.93399647749595, 191.59301668552683, 163.09475735193286, 149.9492481224044, 160.33464591273597, 142.9518402917376, 140.8342985440293, 139.55436868717763, 139.2537529052649, 135.1333865559468, 118.13275884049386, 117.87446469560123, 117.04100198484463, 115.01771577840829, 270.2491314128017, 158.10745823905143, 475.92583305047094, 378.7600568563691, 273.1491009560364, 317.35793875898776, 297.8787368414575, 501.97795093976936, 1197.0955023963447, 562.7130345504057, 471.42578598733434, 2520.1028232090243, 275.72316008608203, 561.6678099812115, 454.71356470716654, 543.0845850879446, 3310.608549900854, 785.6629880870993, 1379.8128542565976, 1392.0131648920094, 593.2319445927059, 1600.9262884770233, 1582.350501373269, 906.1128258197778, 922.4940962013017, 524.6185207468352, 656.5146247847499, 716.399157209551, 664.7175845771422, 838.6908620906263, 1553.2471071730888, 1166.6444544996803, 704.8691696702969, 640.2153544958693, 758.3457083486385, 910.0827613394698, 1003.1968785332431, 795.0296853262092, 813.3343926634293, 677.068433613516, 786.3063261452731, 667.3929759056304, 673.4398987793866, 722.5564175393001, 635.5659369491322, 274.5599999465525, 235.0695599015177, 201.74966583879697, 183.63011047380374, 170.12963068519073, 125.0255783375318, 157.56771745016533, 121.32207730817707, 120.02893586998125, 119.21531550873618, 115.85999239442204, 114.09244215723223, 111.84948980279259, 115.70760412973122, 110.64754160260551, 105.23540735287631, 99.85182106982023, 98.78336159897599, 98.233447368294, 98.08012538444268, 97.8376563981897, 97.41405913904329, 96.29321868550721, 92.06986785801423, 90.96352322889187, 89.55220340673671, 88.64099946003694, 102.29834406761378, 87.10561418772612, 84.69455927378812, 229.0863669865003, 331.1697106286962, 218.38234297297342, 203.84310392936607, 164.1890180127408, 596.7527623910466, 483.3959717340969, 191.07454076439362, 470.696490542758, 306.7034343555313, 564.6792840757665, 364.91628123715645, 1156.1330246779385, 269.02199902956374, 718.3920260846817, 1224.3767966344396, 390.5808436772052, 277.37675914678823, 190.56314079355178, 1043.407454661973, 349.67258088650027, 355.18462308640284, 1486.2654991396325, 789.9546994861159, 528.5513720134616, 1697.8756631290887, 703.4059527568628, 1985.253600780051, 564.0048342242877, 1156.8244801379574, 2658.4873128518175, 699.0418156219073, 1110.3051876720936, 677.4451165917025, 527.6432407312333, 798.2846928681613, 805.4412462839624, 791.3318888930002, 925.5937641892148, 1030.3199171386818, 602.5027241795904, 874.3027297531683, 1099.9306009691802, 914.6860172235347, 708.3589289538861, 610.1243094700503, 649.1655312670595, 817.3846930844087, 675.4129198826674, 615.7163998771309, 638.1513005843523, 605.3565937498646, 1656.132107930088, 1390.5532534163392, 1112.4126890250732, 763.6630793713738, 564.6122295463415, 559.8872047831563, 532.0966329594123, 512.4301103100652, 469.4505000596401, 439.56407475542704, 409.90589247647745, 359.5041609739335, 333.0115645960557, 311.83305347356566, 242.0908607863366, 221.7909496654465, 221.24068895192735, 220.98186166840088, 216.5720979037799, 213.8299824104238, 213.91852319825728, 207.6256648978875, 200.85011278091443, 199.09588162621534, 198.69687862511006, 198.18514895829802, 188.07712838292744, 184.4404809208009, 182.5435146963671, 179.37370586423805, 1433.4566973466046, 791.263440142891, 479.15315764379795, 656.6881481386706, 466.0866411470505, 1124.2092549820616, 589.0303942212952, 335.7003431904828, 832.6020961650373, 432.8666596597737, 1147.6098212398283, 778.5539020848489, 282.08073822232194, 494.0865679771474, 565.6660683900561, 720.77115252581, 616.3346379483745, 1076.7921375896456, 451.5534623038412, 559.5595565201577, 825.5512857236969, 1286.8578248491672, 762.7177058720263, 508.2163929205864, 538.7237170578215, 541.3748475820353, 693.6347511131147, 539.262818995941, 519.216590860744, 1097.7789472720106, 481.80818411785015, 327.14639561947905, 310.6770794978072, 270.57283745645736, 262.7463635173601, 270.4561244975157, 238.03139709617383, 211.2744065983186, 199.4866665386901, 191.01705468123555, 184.36806595409396, 177.32656800927518, 165.90008638837816, 165.82748385440377, 157.70822307915415, 156.98174503459984, 156.08625247847263, 152.02604206280947, 143.14001251487636, 141.61448218584397, 141.17056267813112, 110.76437529141666, 108.61238638688664, 241.4995120608569, 104.5980618478692, 100.06177573592659, 95.4384924917401, 94.5454190769437, 93.09645244897706, 306.21408912408, 233.45885215832, 384.00091370548034, 137.35782617650028, 378.189881582464, 223.5476301260685, 130.2601503941109, 257.9565768585962, 396.3921800125526, 343.55940658035234, 461.1606006541674, 361.0326239132266, 394.21384934686506, 383.8005069447085, 573.6172289680865, 297.2625022607849, 474.1112403426402, 212.65528359338992, 380.50577792242416, 319.9467197844873, 228.7231637244037, 854.8504724769983, 344.6368723232513, 238.41215013580492, 541.7908358558936, 352.8591800309774, 303.78402628973686, 276.4001386585989, 264.3312264706109, 267.1860678874003, 261.41227073504274, 490.6679819595692, 363.86079199051875, 288.5432435233748, 257.88218401767386, 233.2912028019751, 232.429135567116, 152.41376143778447, 130.5891773887117, 130.3164073735915, 122.80464554097108, 118.67161520300287, 112.37408208834395, 109.5457244217983, 102.15467437335408, 98.97918210716179, 95.53994158357452, 88.730571861262, 81.2418671113003, 78.82970876239683, 77.46035241842759, 76.31241863896817, 71.92562722927869, 70.62394405543448, 69.60857352048403, 67.99131525372208, 67.34786751326041, 63.98845123570116, 62.637091800315936, 62.241366213304836, 60.63789692089639, 75.84662295727036, 206.91186285455245, 185.63094124481347, 197.9620794473942, 695.922970710854, 507.1507799304615, 161.66816732423828, 358.1899081700183, 112.87645084397887, 237.35444268645543, 161.79848012290879, 253.01661358491074, 542.769771362036, 326.9823232317571, 203.61425394006588, 169.54282353549843, 500.7959470025306, 178.5292133072127, 689.593332123316, 607.9002306470302, 379.7458236082209, 207.26253291792756, 622.9879119930388, 416.5064968410231, 366.34456511882644, 413.71434605160647, 218.1751178999104, 304.9356508057963, 477.7360945643438, 394.0890201853689, 273.93324261001567, 253.68583492253435, 231.28263328426982, 257.7936043388719, 245.6937160915039, 516.6529086637811, 393.78591623490826, 390.14620098334393, 156.50038692122277, 140.35231148911168, 133.91321106268185, 81.84102079393615, 79.550081330496, 79.34259172132755, 79.00148000495219, 78.71855659763686, 75.38683360787692, 75.0894077586801, 74.96417710357476, 73.00698046046722, 67.9664607946443, 63.651667829454425, 57.03641183308634, 56.91958886113108, 55.61852018246429, 54.78923939206751, 50.72405560703934, 48.86033357254456, 46.75861973088939, 42.16492054290089, 42.14449376829781, 38.94655925399242, 37.92018484102493, 37.72728694450499, 37.46678673076468, 221.0980124335923, 67.75349320658944, 141.08246520823738, 53.89805744025434, 115.49283752639295, 190.69133416239313, 303.33768401102174, 222.5543594959969, 111.9944460145736, 66.94183933492046, 196.07809455593394, 165.11420438793397, 154.64936568222018, 104.04769218126528, 144.59150428790704, 187.54049809322441, 103.81820138578415, 97.31132010059984, 174.72632872690355, 122.3988971041485, 112.02718403950361, 91.90597515646665, 95.41288796877596, 82.29214655739906, 86.49563916490361, 82.21737011671857, 298.17833447771613, 273.5217396541647, 158.05843960800803, 84.08636734505662, 75.05700576458725, 74.9088105521885, 67.53659918991552, 59.298774747794546, 52.56939402455632, 50.318037419519165, 48.57805438817071, 44.751509457157944, 43.429455816392185, 41.60416153023644, 40.6710109152835, 39.563931757529026, 37.339829344819464, 34.52406614749369, 31.966455179847625, 45.634094662816295, 30.562123342244256, 30.115650709696858, 27.618525417376222, 25.255121151529014, 24.084685745727796, 23.121003069370037, 22.9593800760455, 22.261384611952128, 21.339363153277954, 20.742816978860574, 73.67601980747054, 36.953326767742645, 50.80281107481373, 229.90690333466543, 205.9997858013028, 51.798724325039345, 161.72436678776623, 59.61721550403165, 76.77174942068798, 109.33464245145406, 82.35844288560763, 103.21841172854725, 117.14169900190066, 68.88487145035921, 108.51881918464841, 111.05767068875198, 93.2796353782077, 58.02776313971861, 74.72871623582859, 66.79208311597714, 54.070900706568395, 53.341701575376916, 51.31196618324461, 3416.7769440167804, 66.59970349396231, 53.6199392312192, 50.88488287980174, 50.80926779346783, 43.844056630157766, 42.47333743108078, 39.58572033267589, 38.14086577150833, 36.56920630018299, 33.762597235354306, 29.98367981771958, 26.683663180196927, 25.93986036054362, 25.665273388454818, 24.48344668028686, 23.694137433903453, 23.686002875563094, 23.441691375492805, 22.982972935060403, 21.98222208429855, 21.74356061883909, 21.45289292997323, 20.32587489377863, 20.244001398144984, 19.951157297892046, 18.83897575411074, 18.567658305350058, 18.435833322759315, 17.913139377541054, 25.35518677201891, 32.3986094078352, 26.710101966677342, 21.888650132146957, 96.25538692940421, 39.24544263167832, 58.21807437994351, 96.24837688298884, 36.10345818834524, 41.792789879081624, 37.06457637187343, 40.8841999436929, 28.599729450408404, 25.03224774965513, 24.797874344502958, 91.61541663252282, 91.48145452911746, 87.37752908014703, 61.81649614480699, 46.36416327262788, 43.42249120574993, 46.39004869221917, 37.56973062672667, 35.78911130740507, 33.90395195600079, 33.53226095184937, 33.42977635389103, 33.153101870379516, 32.655677024507774, 29.422505247672284, 29.140431171342073, 28.413460010095466, 27.86460689739521, 27.852678854286342, 27.410218926974522, 27.20428074068493, 26.94264681481343, 26.598240883014153, 26.125887439568587, 25.403022252679886, 25.37202924241931, 31.274183861006765, 25.209041472843793, 25.085516407158675, 24.699138836799772, 62.4846557893467, 102.02634707680788, 36.33494978338963, 34.12220969666103, 98.06074255662398, 69.67945824705905, 34.07337192934795, 179.58832993883254, 44.02143818439481, 57.631730145466896, 54.14661108389509, 106.7481686494933, 58.760868200000566, 47.50178407116676, 43.330039083874674, 124.61845223626246, 63.622792077713584, 41.703567536097005, 66.44199942190707, 46.67127123155501, 52.238731028932236, 49.01651177964501, 71.05965942339618, 73.5277203169001, 44.50771148449355, 72.30112858412194, 46.329596090806646, 48.55017722419951, 37.507985105554674, 32.308755028163944, 32.14713899561898, 28.476294966473322, 27.030139492605183, 24.392964035632584, 39.43358234572083, 21.230012934874008, 20.689276009392916, 34.43582129669832, 20.551191713217424, 20.44353978129793, 20.181419713403375, 19.47705655256233, 18.640859498375985, 18.347446204883255, 17.23256055466519, 17.075824262742472, 16.922809211869815, 16.39385723394718, 16.003691673152872, 16.035139060090692, 15.680920565731979, 15.604509963514142, 15.472523435179092, 15.185134644731725, 15.11331682935541, 15.07267471063516, 14.484646886280387, 23.59908655870382, 22.66267394929851, 49.87623338273419, 27.448511999504955, 43.379499047991075, 29.351589473283664, 22.99405977554079, 24.653014373066156, 27.396710736684216, 21.326493511893837, 26.650701118890378, 20.48400484343007, 24.39051271769723, 29.269328371908777, 28.497938608019613, 22.441228053472052, 21.650600175475027, 21.29485075216914, 40.37651656102246, 33.69257506177672, 30.563692058941832, 27.451214438424376, 25.21978401952458, 22.47477428651151, 22.21094658311296, 21.39276907425912, 20.589705538844218, 19.699875964577387, 19.18878439517484, 19.022580864787606, 18.71940876574109, 17.013268811612438, 16.889197165771442, 16.87565585897288, 16.58279126269278, 16.427509248495785, 15.834652218383296, 15.806717908746677, 15.668586015729565, 15.408075305278647, 15.406353426773983, 15.162743270756488, 15.108317913143985, 15.008794920125222, 14.672723585692445, 14.467603488365464, 14.396708045945703, 14.154113322880727, 30.399133820438657, 115.72821488278525, 24.236237510356325, 26.387951820876886, 19.69573500522875, 32.417941294110015, 21.676580603799984, 18.808714047203807, 34.924449726883616, 15.779435905844188, 15.83963959193553, 98.50244919927225, 53.24601450062215, 52.29394823538479, 64.35595769531558, 33.910281122148724, 33.84347133311518, 29.889681106403735, 29.178655993116376, 27.11458451621443, 25.80402989233209, 25.58576951012093, 24.55744608764119, 22.457469852166202, 21.14754822575075, 20.065572318727813, 19.673964628333085, 43.97731815572669, 18.199590973926668, 17.387197027572302, 16.62872447070007, 16.303650525330767, 15.900158664448645, 15.830625320524671, 15.705414376101402, 15.374507811215757, 15.197217357157616, 14.651523567214666, 20.291159765602703, 14.5901287621507, 14.193674833630705, 102.9202575051801, 30.410074035188906, 29.359117383733278, 37.947600837902606, 50.04927734586188, 33.07093124043274, 19.732953567084923, 16.588925349891827, 20.96509979421335, 17.68883697837321, 20.351116048227816, 18.270759164691817, 31.94510611650523, 24.35951178016883, 22.512568378361433, 16.665605647403098, 16.34614839801013, 16.335211039060816, 16.212947905048335, 16.126878113426468, 15.793202408698457, 15.709556710675006, 15.639052093053966, 15.332916228545933, 15.2431713418543, 15.022804761497255, 14.68977347834568, 13.697826141744681, 13.613916664941236, 13.560181477185798, 23.121171690251526, 13.24506600425169, 13.18693227751511, 13.135743612327701, 12.810626805566535, 12.436349202551067, 12.380330158016958, 12.345455709526302, 12.333454331531959, 12.28251386325568, 12.279258365654508, 12.16158520501202, 21.524343995427415, 30.348287325606183, 17.37249271012028, 13.93716253444853, 18.250035739567558, 14.028433331297842, 13.476724987569936, 14.718997273393207, 55.35176167648484, 50.22995363765892, 40.13037352972476, 39.73558225094355, 39.217677209522805, 39.217677209522805, 39.217677209522805, 38.69579331254476, 38.69579331254476, 45.27340446242839, 31.562859096482672, 25.680192830350087, 51.08185178625634, 21.00849719689188, 20.628818926147975, 16.49323387091797, 15.874203663166899, 15.02688049918876, 14.784734972031956, 14.198551300777453, 13.894255385507511, 13.878011305613631, 13.201512333291804, 13.180660053376371, 12.776551854255688, 12.49143084108605, 12.364715829567754, 11.816830391231372, 11.077565671764697, 10.779283492486462, 50.45478345115356, 22.159912613278614, 17.191398900511086, 14.641043393590557, 26.700111111254177, 23.55682835174152, 20.835731962840683, 18.741764171990365, 18.149734477269718, 17.321647794944518, 141.4001765747836, 14.911045468428963, 14.408460661455715, 14.393988436155606, 13.451852160898492, 12.365183228926835, 12.133242315542809, 12.09675420439918, 10.424009075847113, 10.296878212860069, 9.462216820598663, 8.784016050506825, 8.775285010454665, 8.6071996021454, 8.12461676654352, 8.011300221005158, 7.947535582353434, 7.630636310859539, 7.60584463053531, 7.603146596743548, 7.299278356657433, 7.2044111898583285, 7.024395631805021, 6.739907277578703, 25.215388707427895, 10.88980783465504, 15.354555742124251, 15.826197910906043, 43.84238159739567, 11.447283824584051, 14.66113484617345, 10.459707348082793, 17.56654715805454, 11.501013446365004, 10.527383910597655, 9.394380109243558, 9.176706850367017, 9.175936057235608, 9.12927841471129, 8.312824009624963, 8.030159373493031, 6.87571583333213, 6.791314898704912, 6.408525239391232, 6.176359882403607, 5.932467328022124, 5.890509788401589, 5.886459928044681, 5.833180679360082, 5.703752274885756, 5.647590771316412, 5.522642830233897, 5.497298896359827, 4.875121804130586, 4.787637240346733, 4.638719824706226, 4.638719824706226, 4.586844259721834, 4.453469193497056, 4.3066212295577, 4.300678633697422, 4.29931011058437, 7.990984086567799, 6.249597102293459, 9.277937377204653, 5.436285231763027, 5.964607301099246, 60.57113567771395, 7.701468792425372, 6.937035872332229, 6.232012883119016, 5.883477676685999, 5.748806854303289, 5.464679585735375, 5.290739337877645, 4.475842143976769, 4.4254994718904666, 4.326066272979838, 4.31850846164136, 4.2539912584613475, 4.135859591951035, 3.9271465387955327, 3.817828794159199, 3.6318070187499907, 3.569513012259611, 3.3476004447115795, 3.330204569464828, 3.317522302974326, 3.0650769089915184, 3.0385679540126307, 2.836108357498884, 2.836108357498884, 2.836108357498884, 2.836108357498884, 2.8134893358479327, 2.6701413935278526, 2.5777531639131466, 5.753882404415172, 9.817065582029773, 4.04975632087331, 3.410805803233768, 3.4501985927740066, 3.921066893309952, 2.888666956606691, 22.547518556522824, 19.487009720513196, 18.670203030127027, 7.766439635900416, 7.005943230848645, 6.58301518968598, 5.967827188868101, 4.6124535063039875, 4.170743918001253, 3.7705500255815494, 3.401139516393411, 3.3737976879883362, 3.2459226848735017, 3.1184817576889805, 3.0600565909954733, 2.970473427596296, 2.9075287838840516, 2.8415000207765195, 2.832764325265703, 2.816951606425275, 2.5514271286095433, 2.5391563900771996, 2.5383647135421947, 2.2939274396059726, 2.2499118429598894, 2.2043690522302146, 2.147882857129536, 2.0982888562237565, 2.0788408340536964, 2.0748013511953443, 6.754382024311805, 8.034695918058407, 2.8642668738703967, 3.44499572062216, 4.785370989648908, 4.303521270283404, 4.606158083926524, 3.230215677066331, 14.6259697187124, 9.825357880347376, 8.817534684661455, 7.3275954436170005, 7.272704969827053, 6.513869173050404, 6.162629841147463, 5.833853228557318, 5.257483866534923, 4.699782558622073, 4.448444996858433, 4.433433743220077, 4.035227774549207, 3.9584051144778805, 3.7004940515053657, 3.7004334279513116, 3.5769570963631874, 3.489940447197474, 3.411057201755864, 3.397968668755729, 3.385316194517496, 3.3715623410916513, 3.3241217943072585, 3.229338867813312, 3.1747678216838118, 2.995936338302585, 2.852923527886436, 2.784570932291168, 2.7596608062504946, 2.6046528409436216, 5.607724910065522, 4.170429993973246, 7.363890387392419, 6.869067934282521, 6.355126758164648, 5.938193432340715, 5.652380348888102, 5.638638615890448, 5.478919326898923, 5.343663773763382, 5.3247308803024405, 4.334459704375429, 4.093000151738435, 3.9410805753095715, 3.768301330554645, 3.683936526228645, 3.653462290542901, 3.6203813127858377, 3.310568464002145, 3.229205591206257, 3.1681629983758803, 3.1095953172401116, 2.986212039792194, 2.918514878815628, 2.897084146638043, 2.84510768266652, 2.7213141321926804, 2.6290214049834186, 2.5953319561283514, 2.5869768666239823, 2.429317842066675, 2.3924474197396686, 2.9811370227958047, 3.5899764615088894, 3.134200838627112], \"Total\": [3417.0, 3430.0, 7197.0, 4020.0, 1703.0, 1486.0, 1656.0, 4332.0, 1098.0, 3327.0, 810.0, 959.0, 1391.0, 2202.0, 1457.0, 916.0, 1540.0, 785.0, 1464.0, 517.0, 1873.0, 637.0, 1113.0, 605.0, 1482.0, 1238.0, 1754.0, 591.0, 920.0, 789.0, 757.4646084125843, 486.25904489810335, 443.8965614916156, 376.57891122364515, 351.09587653968, 306.8761006019782, 268.97558050862125, 266.74820842693225, 264.03763446111293, 256.2404866853125, 251.33083223402244, 231.47784174210202, 228.2776098656297, 210.77312569636504, 207.58972105029835, 199.49628424691986, 196.62171690459022, 192.2807371126211, 163.78247777902712, 150.63696854949868, 161.09898194723058, 143.63956076728638, 141.52201913279646, 140.2420891142719, 139.94147351196006, 135.82110870953204, 118.82048026920866, 118.56218512269558, 117.72872440134168, 115.70543620550264, 272.56210396479725, 159.5114917458444, 488.59851510316224, 392.74611402236144, 282.93225372124886, 331.7556057834713, 312.0545392252496, 554.5309176081958, 1449.1387425215044, 638.128174232149, 560.7726173583816, 4020.4761344176272, 304.30667189137864, 715.2194972689584, 560.332750456439, 710.5213867437944, 7197.559605459545, 1166.6086510037637, 2499.650002398585, 2648.4668713936735, 836.9318887877406, 3327.517742207288, 3430.7974210972766, 1572.4672701617958, 1647.1426109352208, 721.9456050926667, 1033.3224200574873, 1190.3061768435, 1075.2544410204866, 1576.5179180281857, 4332.157745518806, 2937.7438319319, 1324.8369999678105, 1113.240213159634, 1604.4794007311368, 2367.9589294536963, 3457.1483251384698, 1974.2580348306108, 2252.054548032225, 1352.514816425218, 2247.3085368257002, 1576.821645577683, 1750.5879765962368, 2516.306859874982, 1424.6637923843557, 275.2473993428364, 235.7566615616304, 202.43677733880293, 184.3172089695409, 170.81672917003164, 125.71269309794019, 158.43843715183033, 122.00917834382874, 120.71603449915828, 119.9024139967633, 116.54709094034206, 114.78040111217666, 112.53659321519717, 116.41901022064911, 111.33464008977042, 105.92254894511024, 100.53891956613357, 99.47046580042037, 98.92054586106029, 98.76722401963377, 98.52475496644277, 98.101162244691, 96.98031720488684, 92.75696663799252, 91.65062204627746, 90.23931567966325, 89.32809800163437, 103.09131651705937, 87.7927159302914, 85.38597641866953, 231.20570775440382, 337.20178675494026, 223.56259542400417, 208.82712513219371, 167.478068859766, 639.1745956858831, 523.1308443988715, 199.29029008034192, 516.7612910213046, 330.3711939410947, 637.748750159691, 402.83470953208973, 1467.5886901641518, 296.7366470115132, 878.1408879360342, 1602.7356205001738, 450.7971767690008, 312.3630141072593, 204.50256108851482, 1424.1895969047841, 416.2860300470272, 433.83447548918093, 2516.306859874982, 1170.937771975473, 731.7701503985155, 3327.517742207288, 1088.8138941948953, 4332.157745518806, 827.6032964375473, 2252.054548032225, 7197.559605459545, 1139.1604804507595, 2247.3085368257002, 1113.4760418200437, 794.8467832645046, 1576.821645577683, 1604.4794007311368, 1587.739568863287, 2367.9589294536963, 2937.7438319319, 1109.8870846969726, 2202.390997316059, 3430.7974210972766, 2648.4668713936735, 1559.420494440238, 1172.735295120786, 1482.7114732789332, 3457.1483251384698, 1750.5879765962368, 1398.2703311933865, 1974.2580348306108, 1286.8207231250467, 1656.8160274621953, 1391.2372816018476, 1113.0966935592476, 764.3469988928216, 565.2961490634718, 560.5711243000818, 532.7805524750637, 513.1144082467212, 470.1344195735844, 440.24799453950027, 410.5898145424858, 360.1880804878778, 333.69548411, 312.51697298751, 242.77478030778434, 222.47487001709445, 221.9246094938621, 221.66578118234506, 217.25601741772408, 214.51390192436799, 214.6213743754348, 208.30958441933524, 201.5340322948586, 199.77980114015952, 199.38079813905424, 198.86906847874425, 188.76104789687162, 185.12440044344032, 183.2274342103113, 180.06940757596297, 1457.4462739454223, 813.5668498972427, 489.7560951891459, 679.5393203100439, 480.2866403864921, 1234.959864469203, 627.1244406910588, 348.57139037182543, 934.1438038806314, 461.323612443429, 1398.4492229108744, 915.7543219507173, 293.1895760810956, 560.9362013437446, 664.5334975466724, 914.1449241250673, 820.2571816927394, 1754.2996632841148, 545.4458394564284, 762.9919835261085, 1428.0548381572632, 3457.1483251384698, 1540.3118225266735, 672.8844960121679, 786.0464234342809, 820.5372185295233, 2022.7610212376987, 864.9086365294867, 1486.5546509296782, 1098.4679058054362, 482.49714260552935, 327.8353592086808, 311.3660391691578, 271.26179599412393, 263.43532537366946, 271.2251659924057, 238.72193230277432, 211.96336508371192, 200.17697579714348, 191.7060131626662, 185.05704454777407, 178.01552929044337, 166.58904486980882, 166.51644233583443, 158.39718850104381, 157.67070351999317, 156.77521101993193, 152.7150096723463, 143.82897099630702, 142.30344075134454, 141.85952125953648, 111.45333379224815, 109.30134511406018, 243.07838964745366, 105.28702043884995, 100.75073501094755, 96.12745097317085, 95.23438244683643, 93.78541116159928, 309.1924114718023, 235.62562627238515, 390.8215891664376, 138.79583140410708, 390.29194347593995, 229.77124046298695, 131.7466803564917, 269.6270945738644, 434.5637157669906, 372.8431798969321, 528.3027550772396, 406.8026232617164, 454.05001906158424, 464.4177129248159, 817.7853899212646, 363.21278284335375, 771.434371269727, 239.7717484117723, 564.9095408438188, 481.6735036331639, 275.2316313784002, 4020.4761344176272, 655.9244212497011, 314.6652105037742, 7197.559605459545, 1559.420494440238, 2937.7438319319, 1540.3118225266735, 1428.0548381572632, 2648.4668713936735, 2202.390997316059, 491.36259036858036, 364.555398935652, 289.23788411897624, 258.5769407037125, 233.98580974064132, 233.12374257045138, 153.109488355234, 131.28378432737793, 131.0110143057908, 123.49925247317047, 119.37155856313443, 113.06971754616345, 110.24033135399769, 102.84928168216805, 99.67381289449911, 96.2345485574958, 89.4251787934614, 81.93647404900973, 79.52431594262714, 78.15495943185643, 77.00702557116756, 72.620234167945, 71.31855099410079, 70.30318045268342, 68.68592218592147, 68.042474507944, 64.68305816790055, 63.331698732515314, 62.935973145504214, 61.332503861700985, 76.76429481022136, 212.79512276133173, 192.68513395552893, 206.83576042598688, 810.6597838091709, 591.8637046811303, 175.6756130543573, 417.8198547884758, 118.94149074359203, 275.22763348543566, 181.069632367283, 303.5757737023456, 785.9829392425798, 447.75600641065796, 260.6207423780445, 208.50467311980285, 916.5196180053402, 227.4827001267882, 1703.96838363659, 1486.5546509296782, 789.7866857880945, 351.73490567789435, 3430.7974210972766, 1540.3118225266735, 1238.9330074634954, 1873.8556530326784, 445.0941285527937, 1482.7114732789332, 7197.559605459545, 4332.157745518806, 1754.2996632841148, 1368.2110482462253, 777.5029711196854, 2937.7438319319, 2022.7610212376987, 517.3534672487037, 394.4866459656802, 390.8471542688916, 157.2009169012469, 141.11819613941228, 135.00938218245386, 82.54155776458028, 80.25060302815527, 80.04311380581954, 79.7020017164269, 79.41907888936066, 76.08736043106978, 75.78993388840885, 75.6647037471667, 73.70750215812649, 68.6669833903081, 64.3521895475511, 57.7369376961051, 57.62011055879034, 56.31904188012354, 55.48976108972676, 51.424577304698595, 49.56085527020382, 47.45914142854865, 42.86544239576612, 42.84501546595706, 39.64708105897315, 38.62070653868418, 38.427830862936446, 38.16730857504125, 264.66502053811877, 73.64957526443116, 168.9782769684331, 57.5196861751935, 138.68972873140146, 314.5843019766515, 605.4298243755987, 403.55197716989426, 158.247450228355, 82.82886206520573, 629.4800799621426, 466.5199330519007, 535.7203423739307, 266.61425793927384, 650.1556672914268, 1464.7598443183813, 300.184599369462, 257.90312569328796, 4020.4761344176272, 839.0438133091133, 614.4731448731147, 240.3609859333434, 322.56131136183143, 151.95925399182028, 423.1844180592766, 335.2725370053496, 298.88586755275526, 274.22890302163717, 158.76560195737682, 84.79352954435385, 75.76416780255748, 75.66520536208613, 68.24376123435268, 60.00593681201361, 53.276556062526545, 51.025199574920755, 49.285217561338904, 45.45867176900887, 44.13662585440743, 42.31132360197278, 41.37817297041035, 40.27109395143191, 38.04699138278969, 35.23132699677616, 32.67361741113857, 46.65893771521835, 31.269285699116676, 30.82281278780356, 28.325687545389425, 25.962283218302783, 24.791847791201608, 23.82816510734027, 23.666542133788354, 22.968546673781113, 22.046525304628968, 21.449979028297044, 83.47848159025813, 40.23646083506822, 57.73586548558449, 376.1746466694612, 339.8964624631347, 64.89150142962718, 292.9474335918313, 86.7959146836514, 131.55517517522404, 306.9462533772457, 209.31626290091518, 385.5970147902923, 526.8189636605197, 160.61953612115843, 500.4142879238016, 558.066441602408, 581.5397985704565, 155.41286029513282, 655.9244212497011, 472.8833607731398, 127.74047313329389, 219.32141550386322, 195.55411154114634, 3417.471667469538, 67.29442695296898, 54.31466268397743, 51.579611636522635, 51.503991305644625, 44.538780101800675, 43.16806088934905, 40.280443832000486, 38.83558922426656, 37.263929782645434, 34.45732070750701, 30.678403276726232, 27.37838665520511, 26.634583826306002, 26.359996869387587, 25.178170139547166, 24.388860899158523, 24.380726365402598, 24.136414837296975, 23.677696394067056, 22.676945549807275, 22.43828407806424, 22.1476163915223, 21.020598359287355, 20.938724857151637, 20.645880806744394, 19.533699242043948, 19.262382185889326, 19.130556810995955, 18.607862904933512, 26.88716888226388, 35.154205114790024, 28.866647567591574, 23.39665117217671, 158.1349311427818, 57.393397359638605, 105.88739944848874, 279.40965462345656, 85.60558510177943, 142.78695565915544, 113.50023974591645, 1164.2325130599652, 242.51835984249848, 141.34473671924096, 129.3354684552339, 92.32334729116232, 92.1893852130198, 88.08545974049373, 62.524426803446474, 47.072094507598464, 44.130422167229284, 47.20540597006661, 38.277661288780564, 36.497041966044556, 34.61188261464027, 34.24019161347001, 34.13770701253051, 33.86103253889887, 33.36360768314726, 30.132599681024843, 29.848361829981556, 29.12139129386829, 28.572537556034693, 28.560609512925826, 28.118149585614006, 27.91221140164833, 27.650577622183523, 27.306173169362708, 26.83405090576371, 26.11095304743939, 26.080393041443795, 32.148354138488706, 25.916972133807196, 25.79344706579816, 25.407069495439256, 64.64691545111238, 109.19084193315169, 38.18864552907573, 35.831778987633086, 114.56169594063024, 80.8005402869007, 36.93763244858385, 317.50730530309454, 55.657741704754145, 88.236966135969, 81.04004163574795, 307.5869110828583, 115.19301293382071, 80.87299614666377, 68.22755547139546, 959.474930981197, 193.22420305507606, 67.92438593019754, 370.6281164382195, 109.38152114094922, 170.79446857845775, 141.91094767564434, 637.748750159691, 920.9468406891382, 112.68869788865123, 2202.390997316059, 450.7971767690008, 49.26220928745708, 38.22001750075213, 33.020787098925105, 32.85917107607693, 29.18832705839118, 27.74217157942731, 25.10500421243491, 40.71269790683353, 21.942045026958, 21.401308078898914, 35.62644250673137, 21.263223837523654, 21.155571858526006, 20.893451803674058, 20.189088627075282, 19.352891562923986, 19.059478337616575, 17.944592644288967, 17.787856326000053, 17.634841295360314, 17.105889311647225, 16.715723736410453, 16.748992746862005, 16.39295271431351, 16.31654204515692, 16.18455551240717, 15.897167089537337, 15.825348949229783, 15.784706789894273, 15.196678971874595, 25.21730402130951, 24.586578165006724, 60.74085001722593, 31.359212890112293, 54.04493856594952, 35.991526077097085, 26.717611981599475, 29.5720609960662, 35.31977633865508, 25.03764685589349, 37.73478399155417, 25.470421757160032, 39.77241442289592, 69.67676366397728, 334.9376099379191, 84.25751486434768, 58.57234497401259, 264.64176121222323, 41.09035288952105, 34.406411369356675, 31.277528366521793, 28.165050762212683, 25.933620327104542, 23.18861059805413, 22.92478289069292, 22.10660544041591, 21.303541863226005, 20.413712276388733, 19.902620716725295, 19.73641717886964, 19.433245099179523, 17.72710514702126, 17.60303353824695, 17.58949218030484, 17.296627574105745, 17.14258929191911, 16.548488624104113, 16.52055427047911, 16.382422323309523, 16.12191163695904, 16.120189734353943, 15.876579584803366, 15.822154220723947, 15.722631227705184, 15.386559917164078, 15.181439824443792, 15.110544373998236, 14.867949664971334, 34.999612157676715, 159.72901258711929, 29.65602508336066, 41.33084076821413, 27.118390371101185, 98.50596710256472, 42.70825530144803, 33.26591751177546, 526.8189636605197, 21.65726654950376, 195.27522342717666, 99.21686997437679, 53.96043529175197, 53.00836900402239, 65.34636513431266, 34.6247018972884, 34.5578965456334, 30.604101881543418, 29.89307676825606, 27.829005302967854, 26.518450667436614, 26.300197642395744, 25.271866862745714, 23.17189065963285, 21.86196899438836, 20.779993093867496, 20.388385435746237, 45.70018413391369, 18.9140117711599, 18.10161779939604, 17.343145273379303, 17.01807130362142, 16.614579449036395, 16.54504616020369, 16.41983514473901, 16.08892861676931, 15.911638166594253, 15.3659443835178, 21.283880257493987, 15.30454955893254, 14.908095684526195, 137.52706992389855, 39.537744737669506, 44.879307082586145, 82.22721469993293, 281.0732882697728, 116.30915924225495, 35.884570748193894, 21.18684091938642, 156.78425720887165, 41.518652977832744, 208.76575786615246, 330.3711939410947, 32.662957121971154, 25.077105958051444, 23.230162520430113, 17.383199782564052, 17.06374255024172, 17.052805183874813, 16.93054203496238, 16.844472247571897, 16.510796558540374, 16.427150847055966, 16.35664622296801, 16.050510387603893, 15.960766135710056, 15.74039890432987, 15.407367600756142, 14.415420272617915, 14.331510802838455, 14.277775632093514, 24.354077462104993, 13.962660179576174, 13.904526399925572, 13.853337774064297, 13.528220940473833, 13.153943332605866, 13.097924309875905, 13.063049839440344, 13.051048481728373, 13.000108004411397, 12.99685250210588, 12.879179346946774, 22.86643098520996, 37.08027690872386, 20.894033297430383, 15.850414361428552, 24.775293327079115, 17.629148967961374, 21.13032777190103, 162.11700944280597, 56.072903662311006, 50.951095600508445, 40.85151549257428, 40.45672421379307, 39.93881917237233, 39.93881917237233, 39.93881917237233, 39.41693527539428, 39.41693527539428, 46.2678426913036, 32.28400314388462, 26.401334989534178, 52.552367294325585, 21.729639172491893, 21.349960897419724, 17.214375840269565, 16.595345645233827, 15.748022488540773, 15.505876966773826, 14.919693297661345, 14.615397361107526, 14.599153281213646, 13.922654345026887, 13.901802028976386, 13.497693823572126, 13.212572845819174, 13.085857801975656, 12.53797236351544, 11.798707641116293, 11.500425565326296, 62.078650841353465, 56.91432972643605, 38.8468061457888, 69.67676366397728, 27.412082861785134, 24.2688000642943, 21.54770370919874, 19.45373587829473, 18.861706190040998, 18.033619633438505, 147.7742314515849, 15.623017181200245, 15.12043242590552, 15.105960142459972, 14.163823867202858, 13.077154935231201, 12.845214031600287, 12.808725910703545, 11.135980808295995, 11.008849919164435, 10.174188552048722, 9.495987772712652, 9.487256807777293, 9.319171369004524, 8.83658848729035, 8.723271959873989, 8.659507288657801, 8.34260803804213, 8.317816340025804, 8.315118381521108, 8.011250089626456, 7.916382974561436, 7.736367338109387, 7.451878999212584, 29.430015124825463, 12.851346422426918, 20.985034642703706, 23.424013532736097, 118.59037877784203, 19.160429297518554, 54.31894263501086, 70.7340083258315, 18.297141171261554, 12.231607406021068, 11.257977941482755, 10.124974061043677, 9.907301648565651, 9.906530023591568, 9.859872346510992, 9.043417973705827, 8.760753359768657, 7.606309819261047, 7.521908868770369, 7.13911924838612, 6.906953826953799, 6.663061259821824, 6.621103787427444, 6.617053917753874, 6.563774623910275, 6.4343462194007905, 6.378184714371484, 6.253236804974099, 6.2278928469047825, 5.60571576451533, 5.5182312084826455, 5.369313756505926, 5.369313756505926, 5.3174382566043885, 5.184063159277442, 5.037215187186426, 5.031272565497122, 5.029904042384071, 10.159486379571183, 9.32394935192387, 19.930034665884875, 9.336545736574193, 16.20350573273126, 61.301239394913544, 8.431572555091213, 7.667139708222245, 6.962116645657119, 6.613581492833438, 6.478910584253377, 6.19478339547552, 6.020843102742659, 5.205945881176783, 5.155603228768177, 5.056170095331995, 5.048612214427541, 4.984094975660944, 4.865963358287686, 4.657250262497203, 4.547932517825711, 4.361911479125168, 4.299616945739993, 4.07770418164682, 4.060308296341814, 4.0476262835358465, 3.7951808434371284, 3.7686716712122266, 3.56621207469848, 3.56621207469848, 3.56621207469848, 3.566212269614839, 3.5435931276128696, 3.4002451276790975, 3.3078570017982694, 7.657599735210327, 13.764419627363203, 7.124248383442497, 10.350841208185576, 12.72918571034504, 95.60131243992113, 6.559111366344976, 23.281921241454523, 20.22141239897798, 19.404615392761368, 8.500842359668766, 7.740345922152597, 7.317417872113421, 6.7022298769859265, 5.346856198197951, 4.9051466095320295, 4.504952704046332, 4.13554224553479, 4.10820045549451, 3.9803253633382845, 3.8528844543556464, 3.7944592874618746, 3.7048761060610786, 3.641931587748111, 3.5759027439224242, 3.5671670351800686, 3.5513542848900577, 3.2858298198248184, 3.2735591977287988, 3.2727674305365584, 3.0283301180707554, 2.9843145278915877, 2.9387717563374673, 2.8822855355943187, 2.8326915409369575, 2.8132435245455683, 2.8092040496605444, 17.404961615186384, 26.27844606068919, 5.216873431817291, 10.016252902111706, 54.179335195222286, 36.74802508031497, 55.401144600737354, 27.78855583456199, 15.361194806158112, 10.560582974295162, 9.552759785474612, 8.062820559264805, 8.007930096744246, 7.24909426699819, 6.897854938675777, 6.569078322251449, 5.9927090782201615, 5.435007639819366, 5.183670124459989, 5.168659094251363, 4.7704528694985, 4.693630211819481, 4.435719165199914, 4.43565851565068, 4.312182196777889, 4.225165552845069, 4.146282314589896, 4.133193749953023, 4.120541281963208, 4.106787435039437, 4.059346908255462, 3.964564359664871, 3.9099929091295236, 3.7311614194998786, 3.5881486647285916, 3.51979602559838, 3.4948859570581785, 3.3398779601095523, 7.792655791328187, 8.60681732435532, 8.099337923910523, 7.6045153517038155, 7.090574154926216, 6.67364116547728, 6.387827778034422, 6.374086037444377, 6.214369183447299, 6.079111198615092, 6.060178277064008, 5.069907113633834, 4.828447580986251, 4.676528089161328, 4.503748814575904, 4.419383933290135, 4.388909733607811, 4.355828733084587, 4.046015937038159, 3.9646530004646614, 3.903610494465723, 3.8450427903386135, 3.7216595327406448, 3.653962288074032, 3.632531543399611, 3.580555135423629, 3.456761558288064, 3.3644688483515583, 3.3307793852071406, 3.3244266421956246, 3.1647652938029136, 3.1278948165012364, 4.372434364926807, 7.352101528282598, 9.949137964494936], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.8547, -6.2984, -6.3897, -6.5544, -6.6246, -6.7596, -6.8917, -6.9, -6.9103, -6.9403, -6.9597, -7.0422, -7.0562, -7.1362, -7.1515, -7.1914, -7.206, -7.2284, -7.3894, -7.4734, -7.4065, -7.5212, -7.5362, -7.5453, -7.5474, -7.5775, -7.7119, -7.7141, -7.7212, -7.7387, -6.8844, -7.4205, -6.3185, -6.5468, -6.8737, -6.7237, -6.7871, -6.2652, -5.3961, -6.151, -6.328, -4.6517, -6.8643, -6.1528, -6.3641, -6.1865, -4.3789, -5.8172, -5.254, -5.2452, -6.0982, -5.1054, -5.1171, -5.6746, -5.6567, -6.2211, -5.9968, -5.9095, -5.9844, -5.7519, -5.1356, -5.4219, -5.9257, -6.0219, -5.8526, -5.6702, -5.5728, -5.8054, -5.7826, -5.966, -5.8164, -5.9804, -5.9713, -5.9009, -6.0292, -6.7199, -6.8752, -7.028, -7.1221, -7.1985, -7.5065, -7.2752, -7.5366, -7.5473, -7.5541, -7.5827, -7.598, -7.6179, -7.584, -7.6287, -7.6789, -7.7314, -7.7421, -7.7477, -7.7493, -7.7517, -7.7561, -7.7677, -7.8125, -7.8246, -7.8402, -7.8505, -7.7072, -7.8679, -7.896, -6.901, -6.5324, -6.9488, -7.0177, -7.234, -5.9436, -6.1542, -7.0824, -6.1808, -6.6092, -5.9988, -6.4354, -5.2822, -6.7403, -5.758, -5.2249, -6.3674, -6.7097, -7.0851, -5.3848, -6.4781, -6.4624, -5.031, -5.6631, -6.0649, -4.8979, -5.7791, -4.7416, -6.0, -5.2816, -4.4495, -5.7853, -5.3227, -5.8167, -6.0666, -5.6526, -5.6437, -5.6613, -5.5046, -5.3974, -5.934, -5.5616, -5.3321, -5.5165, -5.7721, -5.9214, -5.8594, -5.6289, -5.8197, -5.9123, -5.8765, -5.9292, -4.8884, -5.0632, -5.2864, -5.6626, -5.9645, -5.973, -6.0239, -6.0615, -6.1491, -6.2149, -6.2848, -6.416, -6.4925, -6.5582, -6.8114, -6.899, -6.9014, -6.9026, -6.9228, -6.9355, -6.9351, -6.9649, -6.9981, -7.0069, -7.0089, -7.0115, -7.0638, -7.0834, -7.0937, -7.1112, -5.0328, -5.6271, -6.1287, -5.8135, -6.1563, -5.2759, -5.9222, -6.4845, -5.5761, -6.2303, -5.2552, -5.6432, -6.6585, -6.098, -5.9627, -5.7204, -5.8769, -5.3189, -6.188, -5.9735, -5.5846, -5.1407, -5.6638, -6.0698, -6.0115, -6.0066, -5.7587, -6.0105, -6.0484, -4.7068, -5.5303, -5.9174, -5.9691, -6.1073, -6.1367, -6.1077, -6.2354, -6.3547, -6.4121, -6.4555, -6.4909, -6.5299, -6.5965, -6.5969, -6.6471, -6.6517, -6.6574, -6.6838, -6.744, -6.7547, -6.7579, -7.0004, -7.0201, -6.221, -7.0577, -7.1021, -7.1494, -7.1588, -7.1742, -5.9836, -6.2548, -5.7572, -6.7853, -5.7725, -6.2982, -6.8383, -6.1551, -5.7254, -5.8685, -5.5741, -5.8189, -5.731, -5.7577, -5.3559, -6.0132, -5.5464, -6.3482, -5.7663, -5.9397, -6.2753, -4.9569, -5.8654, -6.2338, -5.413, -5.8418, -5.9915, -6.086, -6.1306, -6.1199, -6.1418, -4.7584, -5.0574, -5.2893, -5.4017, -5.5019, -5.5056, -5.9276, -6.0821, -6.0842, -6.1436, -6.1778, -6.2324, -6.2578, -6.3277, -6.3593, -6.3946, -6.4686, -6.5568, -6.5869, -6.6044, -6.6193, -6.6786, -6.6968, -6.7113, -6.7348, -6.7443, -6.7955, -6.8168, -6.8232, -6.8493, -6.6255, -5.6219, -5.7304, -5.6661, -4.4089, -4.7254, -5.8686, -5.0731, -6.2279, -5.4846, -5.8678, -5.4207, -4.6575, -5.1643, -5.638, -5.8211, -4.738, -5.7694, -4.4181, -4.5442, -5.0147, -5.6202, -4.5197, -4.9223, -5.0506, -4.929, -5.5689, -5.2341, -4.7851, -4.9776, -5.3413, -5.4181, -5.5105, -5.402, -5.4501, -4.2116, -4.4832, -4.4925, -5.4059, -5.5148, -5.5618, -6.0542, -6.0826, -6.0852, -6.0895, -6.0931, -6.1363, -6.1403, -6.142, -6.1684, -6.24, -6.3056, -6.4153, -6.4173, -6.4405, -6.4555, -6.5326, -6.57, -6.614, -6.7174, -6.7179, -6.7968, -6.8235, -6.8286, -6.8355, -5.0604, -6.2431, -5.5096, -6.4719, -5.7098, -5.2083, -4.7441, -5.0538, -5.7405, -6.2552, -5.1805, -5.3523, -5.4178, -5.8141, -5.4851, -5.225, -5.8163, -5.8811, -5.2958, -5.6517, -5.7402, -5.9382, -5.9008, -6.0487, -5.9989, -6.0496, -4.1338, -4.2201, -4.7685, -5.3996, -5.5132, -5.5152, -5.6188, -5.7489, -5.8693, -5.9131, -5.9483, -6.0303, -6.0603, -6.1032, -6.1259, -6.1535, -6.2114, -6.2898, -6.3668, -6.0108, -6.4117, -6.4264, -6.513, -6.6024, -6.6499, -6.6907, -6.6977, -6.7286, -6.7709, -6.7992, -5.5318, -6.2218, -5.9035, -4.3938, -4.5036, -5.8841, -4.7456, -5.7435, -5.4906, -5.137, -5.4204, -5.1946, -5.0681, -5.599, -5.1445, -5.1214, -5.2958, -5.7705, -5.5176, -5.6299, -5.8411, -5.8547, -5.8935, -1.5961, -5.5339, -5.7506, -5.803, -5.8045, -5.9519, -5.9837, -6.0541, -6.0913, -6.1334, -6.2132, -6.3319, -6.4485, -6.4768, -6.4874, -6.5346, -6.5673, -6.5677, -6.578, -6.5978, -6.6423, -6.6532, -6.6667, -6.7207, -6.7247, -6.7393, -6.7966, -6.8111, -6.8183, -6.847, -6.4996, -6.2544, -6.4475, -6.6466, -5.1656, -6.0627, -5.6684, -5.1656, -6.1462, -5.9998, -6.1199, -6.0218, -6.3792, -6.5124, -6.5218, -5.0301, -5.0316, -5.0775, -5.4236, -5.7112, -5.7767, -5.7106, -5.9215, -5.9701, -6.0242, -6.0352, -6.0383, -6.0466, -6.0617, -6.166, -6.1756, -6.2009, -6.2204, -6.2208, -6.2368, -6.2443, -6.254, -6.2669, -6.2848, -6.3129, -6.3141, -6.1049, -6.3205, -6.3254, -6.341, -5.4128, -4.9225, -5.9549, -6.0178, -4.9621, -5.3038, -6.0192, -4.3571, -5.763, -5.4936, -5.556, -4.8772, -5.4742, -5.687, -5.7789, -4.7225, -5.3947, -5.8171, -5.3514, -5.7046, -5.5919, -5.6556, -5.2842, -5.2501, -5.7521, -5.2669, -5.7119, -5.5986, -5.8567, -6.0059, -6.0109, -6.1322, -6.1843, -6.2869, -5.8066, -6.4258, -6.4516, -5.9421, -6.4583, -6.4636, -6.4765, -6.512, -6.5559, -6.5717, -6.6344, -6.6436, -6.6526, -6.6843, -6.7084, -6.7064, -6.7288, -6.7337, -6.7422, -6.7609, -6.7656, -6.7683, -6.8081, -6.32, -6.3605, -5.5717, -6.1689, -5.7112, -6.1019, -6.346, -6.2763, -6.1708, -6.4213, -6.1984, -6.4616, -6.287, -6.1047, -6.1314, -6.3703, -6.4062, -6.4228, -5.6381, -5.819, -5.9165, -6.0239, -6.1087, -6.2239, -6.2357, -6.2733, -6.3115, -6.3557, -6.382, -6.3907, -6.4068, -6.5023, -6.5097, -6.5105, -6.528, -6.5374, -6.5741, -6.5759, -6.5847, -6.6014, -6.6015, -6.6175, -6.6211, -6.6277, -6.6503, -6.6644, -6.6693, -6.6863, -5.9219, -4.5851, -6.1485, -6.0634, -6.3559, -5.8576, -6.2601, -6.402, -5.7831, -6.5776, -6.5738, -4.6421, -5.2572, -5.2753, -5.0677, -5.7085, -5.7104, -5.8347, -5.8587, -5.9321, -5.9816, -5.9901, -6.0312, -6.1205, -6.1806, -6.2332, -6.2529, -5.4485, -6.3308, -6.3764, -6.421, -6.4408, -6.4658, -6.4702, -6.4782, -6.4995, -6.5111, -6.5476, -6.222, -6.5518, -6.5794, -4.5982, -5.8174, -5.8526, -5.596, -5.3192, -5.7335, -6.2499, -6.4234, -6.1893, -6.3592, -6.219, -6.3269, -5.7014, -5.9725, -6.0513, -6.3521, -6.3714, -6.3721, -6.3796, -6.3849, -6.4058, -6.4111, -6.4156, -6.4354, -6.4413, -6.4558, -6.4782, -6.5482, -6.5543, -6.5583, -6.0246, -6.5818, -6.5862, -6.5901, -6.6151, -6.6448, -6.6493, -6.6521, -6.6531, -6.6572, -6.6575, -6.6671, -6.0962, -5.7527, -6.3105, -6.5308, -6.2612, -6.5243, -6.5644, -6.4763, -4.9101, -5.0072, -5.2316, -5.2415, -5.2546, -5.2546, -5.2546, -5.268, -5.268, -5.1111, -5.4718, -5.6781, -4.9903, -5.8788, -5.8971, -6.1208, -6.1591, -6.2139, -6.2302, -6.2706, -6.2923, -6.2935, -6.3434, -6.345, -6.3762, -6.3987, -6.4089, -6.4542, -6.5189, -6.5461, -5.0027, -5.8255, -6.0794, -6.2399, -5.6387, -5.7639, -5.8867, -5.9926, -6.0247, -6.0714, -3.9718, -6.2212, -6.2555, -6.2565, -6.3242, -6.4085, -6.4274, -6.4304, -6.5792, -6.5915, -6.676, -6.7504, -6.7514, -6.7707, -6.8284, -6.8425, -6.8505, -6.8912, -6.8944, -6.8948, -6.9356, -6.9487, -6.974, -7.0153, -5.6959, -6.5355, -6.1919, -6.1617, -5.1427, -6.4856, -6.2381, -6.5758, -5.4085, -5.832, -5.9205, -6.0344, -6.0578, -6.0579, -6.063, -6.1567, -6.1913, -6.3465, -6.3588, -6.4168, -6.4537, -6.494, -6.5011, -6.5018, -6.5109, -6.5333, -6.5432, -6.5656, -6.5702, -6.6903, -6.7084, -6.74, -6.74, -6.7513, -6.7808, -6.8143, -6.8157, -6.816, -6.1962, -6.4419, -6.0468, -6.5814, -6.4886, -4.1349, -6.1973, -6.3018, -6.409, -6.4665, -6.4897, -6.5404, -6.5727, -6.74, -6.7513, -6.774, -6.7758, -6.7908, -6.819, -6.8708, -6.899, -6.949, -6.9663, -7.0305, -7.0357, -7.0395, -7.1186, -7.1273, -7.1963, -7.1963, -7.1963, -7.1963, -7.2043, -7.2566, -7.2918, -6.4888, -5.9546, -6.84, -7.0117, -7.0003, -6.8723, -7.1779, -4.8351, -4.981, -5.0238, -5.9009, -6.004, -6.0662, -6.1644, -6.422, -6.5226, -6.6235, -6.7266, -6.7347, -6.7733, -6.8134, -6.8323, -6.862, -6.8834, -6.9064, -6.9095, -6.9151, -7.0141, -7.0189, -7.0192, -7.1205, -7.1398, -7.1603, -7.1863, -7.2096, -7.2189, -7.2209, -6.0405, -5.867, -6.8984, -6.7138, -6.3852, -6.4913, -6.4233, -6.7782, -5.197, -5.5949, -5.7031, -5.8882, -5.8957, -6.0059, -6.0613, -6.1161, -6.2202, -6.3323, -6.3873, -6.3907, -6.4848, -6.504, -6.5714, -6.5714, -6.6053, -6.6299, -6.6528, -6.6566, -6.6604, -6.6644, -6.6786, -6.7075, -6.7246, -6.7826, -6.8315, -6.8557, -6.8647, -6.9225, -6.1557, -6.4518, -5.8633, -5.9329, -6.0107, -6.0785, -6.1279, -6.1303, -6.159, -6.184, -6.1876, -6.3933, -6.4507, -6.4885, -6.5333, -6.5559, -6.5643, -6.5733, -6.6628, -6.6877, -6.7068, -6.7254, -6.7659, -6.7889, -6.7962, -6.8143, -6.8588, -6.8933, -6.9062, -6.9094, -6.9723, -6.9876, -6.7676, -6.5818, -6.7176], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3791, 1.3786, 1.3785, 1.3782, 1.3781, 1.3778, 1.3775, 1.3775, 1.3774, 1.3774, 1.3773, 1.3771, 1.377, 1.3768, 1.3767, 1.3766, 1.3766, 1.3765, 1.3758, 1.3755, 1.3753, 1.3753, 1.3752, 1.3751, 1.3751, 1.375, 1.3743, 1.3742, 1.3742, 1.3741, 1.3715, 1.3712, 1.3538, 1.3438, 1.3449, 1.3357, 1.3336, 1.2805, 1.189, 1.2543, 1.2065, 0.913, 1.2814, 1.1384, 1.1712, 1.1113, 0.6034, 0.9847, 0.7859, 0.7368, 1.0359, 0.6484, 0.6062, 0.8288, 0.8003, 1.0608, 0.9265, 0.8723, 0.8991, 0.7489, 0.3543, 0.4565, 0.749, 0.8268, 0.6306, 0.4238, 0.1428, 0.4705, 0.3616, 0.6881, 0.3299, 0.5203, 0.4247, 0.1323, 0.5729, 1.5262, 1.5258, 1.5253, 1.525, 1.5247, 1.5233, 1.5232, 1.5231, 1.523, 1.523, 1.5228, 1.5227, 1.5226, 1.5226, 1.5225, 1.5222, 1.5219, 1.5218, 1.5218, 1.5218, 1.5217, 1.5217, 1.5216, 1.5213, 1.5212, 1.5211, 1.521, 1.521, 1.5209, 1.5206, 1.5195, 1.5107, 1.5053, 1.5046, 1.5089, 1.4601, 1.4497, 1.4866, 1.4354, 1.4544, 1.4071, 1.4299, 1.2902, 1.4307, 1.3279, 1.2595, 1.3854, 1.4099, 1.4581, 1.2176, 1.3544, 1.3287, 1.0022, 1.1352, 1.2034, 0.8559, 1.0918, 0.7484, 1.1453, 0.8626, 0.5328, 1.0404, 0.8236, 1.0318, 1.119, 0.848, 0.8396, 0.8324, 0.5894, 0.481, 0.9178, 0.6049, 0.3912, 0.4656, 0.7396, 0.8753, 0.7028, 0.0866, 0.5764, 0.7085, 0.3994, 0.7746, 1.5627, 1.5626, 1.5625, 1.5622, 1.5619, 1.5619, 1.5618, 1.5618, 1.5617, 1.5616, 1.5614, 1.5612, 1.5611, 1.5609, 1.5603, 1.56, 1.56, 1.56, 1.56, 1.5599, 1.5598, 1.5598, 1.5597, 1.5597, 1.5597, 1.5597, 1.5595, 1.5594, 1.5594, 1.5592, 1.5465, 1.5353, 1.5412, 1.5289, 1.5331, 1.4692, 1.5004, 1.5255, 1.448, 1.4994, 1.3654, 1.4008, 1.5245, 1.4362, 1.402, 1.3254, 1.2773, 1.075, 1.3742, 1.253, 1.0151, 0.5749, 0.8603, 1.2824, 1.1853, 1.1473, 0.4928, 1.0907, 0.5112, 2.1553, 2.1545, 2.1538, 2.1537, 2.1534, 2.1533, 2.1531, 2.153, 2.1527, 2.1525, 2.1523, 2.1522, 2.1521, 2.1518, 2.1518, 2.1516, 2.1516, 2.1515, 2.1514, 2.1511, 2.1511, 2.1511, 2.1497, 2.1496, 2.1494, 2.1494, 2.1491, 2.1488, 2.1487, 2.1486, 2.1463, 2.1467, 2.1383, 2.1455, 2.1244, 2.1285, 2.1446, 2.1117, 2.064, 2.0741, 2.02, 2.0366, 2.0146, 1.9653, 1.8013, 1.9556, 1.6691, 2.0359, 1.7608, 1.7468, 1.9708, 0.6077, 1.5124, 1.8784, -0.4307, 0.6699, -0.1131, 0.4381, 0.4691, -0.1378, 0.0247, 2.9082, 2.9077, 2.9072, 2.9069, 2.9066, 2.9066, 2.9051, 2.9043, 2.9043, 2.904, 2.9037, 2.9034, 2.9033, 2.9028, 2.9026, 2.9024, 2.9018, 2.9011, 2.9008, 2.9007, 2.9006, 2.9, 2.8998, 2.8997, 2.8994, 2.8994, 2.8988, 2.8986, 2.8985, 2.8982, 2.8976, 2.8816, 2.8723, 2.8658, 2.757, 2.7551, 2.8265, 2.7556, 2.8573, 2.7616, 2.7971, 2.7274, 2.5394, 2.5953, 2.6628, 2.7028, 2.3052, 2.6673, 2.005, 2.0154, 2.1774, 2.3807, 1.2036, 1.6018, 1.6912, 1.399, 2.1966, 1.3281, 0.1972, 0.5124, 1.0527, 1.2244, 1.6972, 0.4764, 0.8015, 3.4035, 3.403, 3.403, 3.4004, 3.3994, 3.3967, 3.3963, 3.396, 3.396, 3.396, 3.396, 3.3956, 3.3955, 3.3955, 3.3953, 3.3946, 3.3939, 3.3926, 3.3926, 3.3923, 3.3921, 3.3911, 3.3906, 3.3899, 3.3883, 3.3883, 3.387, 3.3865, 3.3864, 3.3863, 3.225, 3.3214, 3.2244, 3.3398, 3.2218, 2.9042, 2.7137, 2.8097, 3.0591, 3.1919, 2.2384, 2.3662, 2.1624, 2.4639, 1.9015, 1.3494, 2.3431, 2.4301, 0.2689, 1.4798, 1.7028, 2.4434, 2.1867, 2.7915, 1.8171, 1.9992, 4.03, 4.0298, 4.0279, 4.024, 4.023, 4.0223, 4.0219, 4.0205, 4.019, 4.0184, 4.0179, 4.0167, 4.0162, 4.0155, 4.0151, 4.0146, 4.0136, 4.0121, 4.0105, 4.0101, 4.0095, 4.0091, 4.0071, 4.0047, 4.0034, 4.0022, 4.002, 4.0011, 3.9997, 3.9988, 3.9074, 3.9472, 3.9044, 3.54, 3.5316, 3.807, 3.4382, 3.6567, 3.4938, 3.0001, 3.0996, 2.7144, 2.5289, 3.1857, 2.5038, 2.4179, 2.2023, 3.0472, 1.8602, 2.0751, 3.1726, 2.6185, 2.6944, 4.131, 4.1209, 4.1184, 4.1177, 4.1176, 4.1155, 4.115, 4.1138, 4.1132, 4.1124, 4.1109, 4.1083, 4.1055, 4.1048, 4.1045, 4.1033, 4.1023, 4.1023, 4.102, 4.1015, 4.1001, 4.0998, 4.0994, 4.0976, 4.0975, 4.097, 4.095, 4.0945, 4.0942, 4.0932, 4.0726, 4.0496, 4.0536, 4.0646, 3.6348, 3.7511, 3.533, 3.0655, 3.2679, 2.9026, 3.0121, 0.7822, 1.9935, 2.4002, 2.4796, 4.3084, 4.3084, 4.308, 4.3047, 4.3009, 4.2999, 4.2987, 4.2974, 4.2965, 4.2954, 4.2952, 4.2951, 4.2949, 4.2946, 4.2922, 4.2921, 4.2915, 4.291, 4.291, 4.2906, 4.2904, 4.2901, 4.2898, 4.2893, 4.2886, 4.2885, 4.2885, 4.2884, 4.2882, 4.2878, 4.2821, 4.2482, 4.2663, 4.2672, 4.1605, 4.168, 4.2354, 3.7462, 4.0815, 3.8901, 3.9128, 3.2578, 3.6429, 3.784, 3.8621, 2.2749, 3.2052, 3.8283, 2.5972, 3.4644, 3.1314, 3.253, 2.1216, 1.7883, 3.3871, 0.8996, 2.0408, 4.368, 4.3638, 4.3608, 4.3607, 4.3579, 4.3566, 4.3538, 4.3506, 4.3496, 4.3487, 4.3486, 4.3485, 4.3483, 4.3479, 4.3467, 4.3451, 4.3445, 4.3421, 4.3417, 4.3414, 4.3401, 4.339, 4.339, 4.3382, 4.338, 4.3376, 4.3367, 4.3365, 4.3364, 4.3346, 4.3162, 4.3011, 4.1855, 4.2494, 4.1627, 4.1786, 4.2325, 4.2006, 4.1285, 4.2221, 4.0348, 4.1647, 3.8936, 3.5152, 1.9185, 3.0596, 3.3873, 1.8627, 4.5099, 4.5065, 4.5044, 4.5018, 4.4996, 4.4962, 4.4958, 4.4946, 4.4934, 4.4919, 4.4909, 4.4906, 4.49, 4.4864, 4.4861, 4.486, 4.4853, 4.4849, 4.4834, 4.4833, 4.4829, 4.4822, 4.4822, 4.4815, 4.4813, 4.481, 4.48, 4.4793, 4.4791, 4.4783, 4.3865, 4.2052, 4.3257, 4.0788, 4.2077, 3.4161, 3.8493, 3.9573, 1.8138, 4.2108, 2.0156, 4.6244, 4.6183, 4.6181, 4.6164, 4.6108, 4.6107, 4.608, 4.6074, 4.6056, 4.6043, 4.6041, 4.6029, 4.6003, 4.5984, 4.5966, 4.596, 4.5932, 4.5931, 4.5914, 4.5896, 4.5887, 4.5877, 4.5875, 4.5871, 4.5862, 4.5857, 4.584, 4.5839, 4.5838, 4.5825, 4.3418, 4.3691, 4.2073, 3.8583, 2.906, 3.374, 4.0336, 4.387, 2.6196, 3.7784, 2.3035, 1.7367, 4.6762, 4.6694, 4.667, 4.6562, 4.6554, 4.6554, 4.6551, 4.6549, 4.654, 4.6537, 4.6535, 4.6527, 4.6524, 4.6517, 4.6507, 4.6473, 4.647, 4.6468, 4.6464, 4.6456, 4.6454, 4.6452, 4.6439, 4.6423, 4.6421, 4.6419, 4.6418, 4.6416, 4.6416, 4.6411, 4.6379, 4.4981, 4.5138, 4.5698, 4.3927, 4.4699, 4.2487, 2.2992, 4.9271, 4.9258, 4.9222, 4.922, 4.9218, 4.9218, 4.9218, 4.9216, 4.9216, 4.9183, 4.9174, 4.9123, 4.9116, 4.9063, 4.9057, 4.8972, 4.8956, 4.8931, 4.8924, 4.8905, 4.8894, 4.8894, 4.8868, 4.8868, 4.8851, 4.8839, 4.8833, 4.8808, 4.877, 4.8753, 4.7327, 3.9968, 4.1248, 3.38, 4.9141, 4.9107, 4.9068, 4.9032, 4.902, 4.9002, 4.8964, 4.8938, 4.8922, 4.8922, 4.8889, 4.8845, 4.8834, 4.8833, 4.8744, 4.8736, 4.8679, 4.8625, 4.8624, 4.861, 4.8564, 4.8553, 4.8547, 4.8512, 4.851, 4.8509, 4.8474, 4.8462, 4.8439, 4.84, 4.7859, 4.7748, 4.6281, 4.5484, 3.9454, 4.4254, 3.6308, 3.0291, 5.5486, 5.5277, 5.5222, 5.5144, 5.5127, 5.5127, 5.5123, 5.5051, 5.5023, 5.4883, 5.4872, 5.4814, 5.4775, 5.4732, 5.4724, 5.4723, 5.4713, 5.4688, 5.4677, 5.4651, 5.4645, 5.4497, 5.4473, 5.4431, 5.4431, 5.4415, 5.4374, 5.4326, 5.4324, 5.4324, 5.3492, 5.1893, 4.8247, 5.0485, 4.5899, 5.6131, 5.5345, 5.525, 5.5143, 5.5081, 5.5055, 5.4997, 5.4958, 5.474, 5.4724, 5.4691, 5.4689, 5.4667, 5.4625, 5.4546, 5.4501, 5.4419, 5.439, 5.4278, 5.4269, 5.4262, 5.4114, 5.4098, 5.396, 5.396, 5.396, 5.396, 5.3944, 5.3834, 5.3757, 5.3393, 5.2871, 5.0603, 4.515, 4.3196, 2.4313, 4.805, 5.881, 5.8761, 5.8745, 5.8227, 5.8134, 5.8073, 5.797, 5.7653, 5.7509, 5.7351, 5.7176, 5.7161, 5.7091, 5.7016, 5.698, 5.6921, 5.6878, 5.6832, 5.6825, 5.6814, 5.6601, 5.659, 5.6589, 5.6353, 5.6306, 5.6255, 5.619, 5.613, 5.6105, 5.61, 4.9665, 4.7281, 5.3135, 4.8458, 3.4863, 3.7684, 3.4259, 3.761, 5.9349, 5.9118, 5.9039, 5.8884, 5.8877, 5.877, 5.8713, 5.8653, 5.8531, 5.8386, 5.831, 5.8305, 5.8166, 5.8136, 5.8027, 5.8027, 5.797, 5.7928, 5.7888, 5.7881, 5.7874, 5.7867, 5.7842, 5.7789, 5.7757, 5.7645, 5.7547, 5.7497, 5.7478, 5.7353, 5.6549, 5.2594, 5.9087, 5.9022, 5.8944, 5.8871, 5.8815, 5.8813, 5.8779, 5.8749, 5.8745, 5.8471, 5.8386, 5.8328, 5.8256, 5.8218, 5.8205, 5.8189, 5.8033, 5.7987, 5.7951, 5.7916, 5.7837, 5.7791, 5.7776, 5.7739, 5.7646, 5.7572, 5.7544, 5.7531, 5.7394, 5.7358, 5.6209, 5.287, 4.8488]}, \"token.table\": {\"Topic\": [18, 14, 14, 10, 8, 17, 16, 10, 15, 10, 18, 10, 9, 14, 8, 13, 18, 3, 12, 3, 15, 3, 8, 2, 3, 6, 15, 3, 8, 3, 9, 20, 9, 10, 16, 3, 4, 10, 14, 18, 9, 18, 12, 12, 15, 16, 18, 12, 14, 18, 2, 3, 4, 7, 11, 8, 10, 12, 17, 11, 19, 17, 13, 3, 18, 7, 12, 13, 9, 17, 19, 19, 13, 19, 1, 2, 3, 5, 5, 5, 15, 10, 3, 4, 5, 19, 7, 9, 4, 16, 14, 8, 1, 2, 3, 4, 5, 4, 2, 4, 7, 18, 1, 2, 3, 4, 6, 7, 19, 1, 2, 3, 17, 17, 12, 3, 19, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 17, 12, 6, 6, 5, 3, 3, 13, 2, 3, 4, 6, 7, 11, 17, 7, 7, 6, 1, 2, 1, 17, 6, 6, 6, 4, 15, 1, 2, 3, 4, 5, 6, 18, 1, 8, 10, 17, 3, 4, 2, 8, 6, 6, 6, 6, 1, 2, 3, 4, 5, 6, 6, 2, 2, 15, 4, 14, 2, 5, 6, 10, 8, 13, 1, 1, 1, 2, 4, 1, 2, 3, 4, 1, 1, 2, 2, 18, 16, 15, 5, 11, 11, 9, 19, 18, 5, 2, 9, 12, 15, 20, 2, 10, 12, 16, 12, 15, 16, 7, 11, 11, 9, 6, 6, 1, 6, 14, 2, 18, 7, 13, 1, 8, 10, 8, 16, 2, 5, 5, 12, 14, 2, 3, 4, 7, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 12, 2, 7, 10, 6, 15, 4, 15, 18, 1, 11, 2, 5, 5, 5, 1, 2, 5, 2, 2, 9, 20, 1, 15, 14, 2, 3, 7, 15, 2, 16, 12, 1, 14, 2, 3, 5, 14, 17, 2, 9, 12, 1, 4, 6, 7, 4, 5, 8, 1, 1, 1, 1, 13, 1, 8, 20, 8, 4, 2, 6, 7, 1, 2, 13, 12, 17, 13, 14, 7, 4, 8, 4, 10, 12, 15, 17, 1, 3, 4, 4, 14, 20, 14, 16, 3, 4, 5, 12, 10, 16, 3, 6, 8, 11, 11, 16, 14, 4, 1, 3, 5, 8, 5, 13, 4, 5, 11, 13, 11, 7, 18, 20, 1, 2, 3, 4, 5, 6, 20, 4, 4, 10, 4, 18, 13, 2, 4, 1, 2, 3, 8, 6, 3, 4, 4, 12, 8, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, 1, 2, 4, 5, 6, 11, 10, 16, 9, 2, 13, 17, 16, 2, 9, 12, 9, 16, 5, 3, 12, 10, 13, 3, 1, 7, 3, 5, 1, 2, 3, 17, 2, 3, 6, 7, 9, 7, 15, 2, 5, 5, 5, 2, 5, 6, 9, 19, 2, 5, 5, 1, 2, 16, 20, 9, 16, 1, 3, 5, 15, 17, 4, 4, 4, 1, 2, 5, 11, 13, 17, 20, 3, 13, 3, 18, 4, 16, 1, 4, 1, 2, 3, 4, 5, 6, 1, 4, 15, 10, 19, 11, 1, 1, 2, 3, 3, 17, 1, 12, 2, 4, 6, 4, 3, 1, 15, 3, 16, 1, 2, 3, 4, 5, 12, 12, 2, 4, 16, 1, 2, 3, 4, 6, 9, 16, 17, 6, 3, 5, 9, 10, 1, 2, 3, 4, 5, 3, 13, 19, 10, 13, 20, 8, 10, 8, 3, 4, 7, 15, 2, 6, 3, 20, 2, 9, 12, 2, 2, 5, 9, 2, 20, 7, 14, 15, 6, 1, 2, 3, 5, 13, 12, 17, 9, 11, 13, 2, 4, 9, 20, 1, 1, 1, 1, 2, 4, 5, 6, 1, 2, 3, 5, 14, 17, 4, 4, 6, 1, 6, 6, 9, 1, 2, 3, 6, 8, 8, 7, 18, 2, 6, 2, 4, 20, 18, 2, 15, 1, 2, 4, 5, 11, 8, 9, 9, 2, 1, 2, 6, 2, 4, 7, 10, 4, 19, 7, 13, 2, 9, 1, 1, 2, 3, 4, 6, 2, 15, 15, 20, 1, 3, 4, 6, 7, 4, 10, 8, 1, 2, 3, 5, 17, 19, 10, 7, 1, 3, 13, 7, 3, 1, 2, 3, 15, 18, 2, 3, 4, 17, 18, 20, 15, 7, 8, 16, 2, 20, 14, 9, 8, 1, 3, 7, 8, 20, 19, 1, 7, 9, 15, 18, 7, 7, 1, 7, 7, 7, 18, 9, 11, 1, 9, 1, 4, 7, 1, 4, 7, 7, 2, 4, 2, 15, 19, 3, 1, 13, 5, 10, 14, 10, 10, 19, 19, 3, 4, 18, 11, 1, 2, 4, 6, 2, 9, 1, 2, 3, 4, 5, 6, 15, 1, 2, 14, 1, 2, 3, 4, 6, 12, 13, 10, 1, 4, 10, 12, 13, 9, 15, 1, 2, 12, 11, 15, 7, 7, 1, 2, 4, 5, 6, 1, 3, 4, 9, 1, 2, 4, 10, 11, 1, 2, 4, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 1, 2, 4, 6, 17, 11, 1, 2, 3, 5, 6, 1, 17, 1, 2, 3, 6, 12, 12, 7, 9, 12, 16, 3, 16, 5, 20, 1, 3, 5, 3, 10, 1, 2, 3, 4, 5, 6, 11, 1, 2, 3, 4, 6, 1, 8, 1, 2, 4, 11, 1, 3, 7, 14, 2, 3, 5, 18, 13, 16, 16, 1, 2, 3, 4, 5, 2, 3, 12, 12, 14, 4, 6, 2, 9, 12, 3, 5, 15, 1, 2, 4, 5, 2, 12, 1, 1, 5, 19, 3, 2, 3, 5, 1, 2, 3, 4, 5, 11, 12, 1, 6, 1, 2, 3, 4, 5, 20, 12, 14, 1, 3, 2, 3, 4, 7, 4, 19, 8, 1, 2, 3, 4, 5, 12, 20, 1, 4, 8, 9, 1, 2, 4, 5, 6, 3, 7, 1, 2, 3, 6, 12, 3, 16, 18, 7, 18, 9, 14, 2, 3, 18, 1, 2, 4, 5, 10, 11, 5, 2, 3, 4, 13, 1, 2, 3, 4, 7, 18, 19, 7, 5, 8, 17, 20, 9, 10, 6, 15, 8, 11, 19, 3, 5, 17, 2, 19, 1, 3, 4, 7, 1, 8, 7, 15, 7, 7, 19, 1, 2, 3, 4, 8, 15, 8, 2, 11, 18, 1, 2, 3, 4, 6, 1, 2, 3, 4, 9, 2, 9, 13, 2, 9, 12, 2, 3, 10, 1, 3, 5, 7, 7, 11, 2, 2, 3, 9, 12, 2, 4, 9, 9, 2, 12, 8, 13, 15, 2, 12, 12, 2, 1, 2, 3, 5, 1, 2, 3, 4, 2, 4, 6, 4, 10, 4, 3, 5, 1, 2, 3, 4, 5, 9, 19, 2, 4, 12, 5, 5, 16, 13, 3, 4, 3, 4, 18, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 11, 3, 3, 3, 3, 13, 14, 10, 4, 4, 16, 15, 3, 4, 7, 9, 17, 13, 11, 1, 2, 3, 4, 5, 2, 9, 12, 15, 11, 1, 2, 3, 4, 5, 7, 13, 1, 2, 3, 4, 5, 10, 13, 17, 19, 8, 10, 13, 4, 11, 1, 1, 4, 2, 3, 4, 7, 1, 3, 4, 7, 10, 8, 3, 6, 10, 17, 17, 14, 2, 2, 1, 2, 3, 4, 5, 6, 3, 4, 12, 13, 14, 6, 10, 10, 6, 15, 7, 8, 19, 20, 8, 13, 8, 2, 4, 6, 4, 13, 9, 1, 2, 4, 6, 1, 2, 4, 6, 11, 3, 1, 2, 4, 6, 1, 4, 6, 2, 2, 9, 7, 9, 5, 18, 18, 11, 14, 2, 9, 1, 2, 3, 4, 5, 6, 9, 4, 4, 16, 17, 3, 4, 1, 2, 3, 4, 5, 16, 13, 16, 1, 2, 3, 5, 8, 10, 6, 3, 11, 14, 19, 13, 1, 3, 4, 10, 12, 10, 13, 2, 6, 9, 11, 20, 12, 12, 1, 2, 3, 4, 5, 18, 3, 3, 10, 6, 12, 7, 20, 3, 5, 8, 14, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 10, 13, 14, 1, 2, 5, 1, 3, 4, 6, 3, 20, 16, 11, 2, 12, 2, 15, 11, 2, 12, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 10, 12, 13, 13, 20, 11, 13, 5, 1, 2, 3, 4, 5, 6, 1, 3, 1, 17, 6, 15, 20, 14, 18, 14, 5, 2, 12, 3, 11, 19, 3, 18, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 9, 3, 5, 8, 2, 9, 12, 17, 17, 14, 2, 11, 1, 10, 14, 13, 1, 2, 3, 5, 3, 5, 18, 1, 2, 4, 6, 10, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 6, 9, 1, 2, 3, 4, 6, 10, 10, 1, 2, 3, 4, 5, 6, 12, 20, 1, 2, 4, 5, 6, 9, 20, 1, 2, 6, 2, 12, 10, 13, 16, 1, 3, 4, 5, 19, 1, 4, 10, 4, 6, 6, 14, 2, 3, 4, 7, 3, 4, 5, 8, 3, 4, 7, 1, 2, 3, 4, 7, 8, 3, 5, 1, 2, 3, 4, 5, 3, 3, 4, 1, 2, 3, 4, 5, 15, 2, 10, 11, 8, 19, 9, 12, 20, 1, 3, 5, 3, 5, 3, 5, 6, 2, 11, 5, 12, 16, 1, 2, 3, 4, 5, 6, 4, 13, 6, 20, 3, 4, 7, 2, 1, 2, 6, 11, 13, 1, 2, 4, 6, 4, 18, 1, 2, 3, 4, 5, 6, 14, 20, 1, 2, 4, 6, 1, 2, 6, 1, 2, 3, 7, 1, 2, 3, 4, 5, 11, 16, 3, 16, 3, 6, 10, 16, 3, 5, 15, 9, 9, 13, 3, 5, 8, 19, 8, 17, 4, 1, 2, 3, 4, 5, 1, 4, 6, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 17, 19, 1, 2, 3, 4, 5, 6, 18, 6, 14, 19, 6, 7, 17, 8, 11, 1, 2, 3, 2, 3, 1, 2, 3, 4, 5, 6, 17, 2, 3, 4, 7, 12, 3, 7, 20], \"Freq\": [0.7786374171196675, 0.9764935671152302, 0.9847986857598954, 0.9817654348045823, 0.978483930823317, 0.8412287147150797, 0.9060874419893791, 0.9812484322257576, 0.9258994455749886, 0.9444119970731022, 0.7537072289698225, 0.9473605969768507, 0.9839781012323232, 0.9564863437023517, 0.9942066714874351, 0.9739972651963247, 0.6938937781497786, 0.24722405573545708, 0.7489434629632965, 0.6239966577611311, 0.37102503974986173, 0.5723925599216712, 0.4205333093302074, 0.18378712457685653, 0.6079112582157562, 0.05654988448518662, 0.14137471121296655, 0.3136249260033932, 0.679520673007352, 0.13966273690895553, 0.8554342635673526, 0.7566866506724288, 0.9927461271291946, 0.09843017280979992, 0.7874413824783993, 0.9994761169628301, 0.1981892504890802, 0.7644442518864522, 0.9704605639241449, 0.01902863850831657, 0.9887874010223362, 0.9351289458065373, 0.9391425776632631, 0.9605722158598975, 0.9617908923407633, 0.9312176987127203, 0.6604299802275622, 0.5170939298221269, 0.05745488109134743, 0.40218416763943204, 0.1513224034130114, 0.6190461957805011, 0.06534376511016401, 0.15992026724329614, 0.0034391455321138953, 0.9102751689452084, 0.05689219805907553, 0.9624642274737962, 0.8412287147150797, 0.9480377823869847, 0.9017826746325237, 0.9950859167304448, 0.9900920830739909, 0.9025084293896436, 0.09025084293896435, 0.9652442769466478, 0.14358166072076423, 0.8136294107509974, 0.9799619633043839, 0.7411751455915833, 0.7258309630498443, 0.9199619083085919, 0.9194663568065161, 0.8698356305463066, 0.906979785505713, 0.04600622100391298, 0.0032861586431366416, 0.04272006236077634, 0.9900136423288488, 0.991459210025258, 0.9178312383636908, 0.9212539151422913, 0.00646846405602162, 0.9896750005713079, 0.9968873778008192, 0.7738951103292616, 0.9195639783445498, 0.07455924148739593, 0.9939410393331022, 0.9403024085498083, 0.9383570909057825, 0.9956247944101709, 0.2901235080678312, 0.2363219402706063, 0.3722721384678951, 0.06537179743103674, 0.03528920038312603, 0.9978676499335335, 0.2885417721154488, 0.6744442648833497, 0.03717409334002715, 0.9130113744478534, 0.42165063047146467, 0.025978474863170807, 0.1478774722980492, 0.12589568587536623, 0.061948670827561156, 0.217819520006586, 0.8583971084782552, 0.12552128933942383, 0.16736171911923178, 0.6694468764769271, 0.041840429779807946, 0.8412286687365383, 0.9885857267508961, 0.9975870314396182, 0.8040391885275543, 0.15502338847818736, 0.289826334980959, 0.05167446282606245, 0.013480294650277162, 0.4897840389600702, 0.2946064051544415, 0.18486258490766747, 0.11209128164242693, 0.00293432674456615, 0.40493709075012874, 0.7922969382693136, 0.9761847124794798, 0.9869681006120016, 0.9839281412922248, 0.9991775485438195, 0.9994366935396045, 0.996996463870996, 0.9690628761168909, 0.13477115460435884, 0.26194956810424674, 0.24866227117142264, 0.0626401141118851, 0.22208767730577444, 0.06643648466412055, 0.0018981852761177302, 0.995177784432283, 0.9964280803117579, 0.9912151410862877, 0.9555226632911761, 0.04219973907279642, 0.993178219167204, 0.830448479503205, 0.992076173236316, 0.9993167780423248, 0.998766381649019, 0.997492452329473, 0.8842422129517802, 0.1533779104862409, 0.6456567130049541, 0.14143831266395865, 0.0018368612034280346, 0.022042334441136416, 0.03490036286513266, 0.9410832081718216, 0.995222457312663, 0.26500747963041765, 0.7155201950021276, 0.8822893313129184, 0.983226638002069, 0.015781027686006692, 0.9967904976401585, 0.9687162387117239, 0.9934389684512028, 0.9968772442984964, 0.9943350975181249, 0.9895773244825371, 0.16149535181261188, 0.7323463127850182, 0.04423568332258499, 0.006319383331797856, 0.04002276110138642, 0.014745227774194998, 0.9903255428832419, 0.9940684391917854, 0.7179815752684192, 0.2761467597186228, 0.17719457254493667, 0.8054298752042576, 0.9952186816010353, 0.9900436158228136, 0.15704490636773824, 0.7852245318386911, 0.04106088606952994, 0.9444003795991887, 0.9985399623652542, 0.9957714991503605, 0.826007865828787, 0.16906593745033655, 0.004140390304906201, 0.23656252845330722, 0.6746729150834394, 0.08710966751710231, 0.0008540163482068853, 0.9979802468201084, 0.9952583100411502, 0.9973479887578848, 0.9991011746398801, 0.7109231684175177, 0.9312176987127203, 0.9176307889165376, 0.9959574453838987, 0.9657426353851618, 0.9487416206750278, 0.9929850972745281, 0.8522188198651048, 0.8410035107449242, 0.9952454241724984, 0.5302540995499697, 0.42968866687669954, 0.0365692482448255, 0.8845914299659522, 0.8224886560948369, 0.3771458237487564, 0.6034333179980101, 0.962796995982955, 0.02188174990870352, 0.9427062030289128, 0.9368613306005917, 0.9595030841031539, 0.11428698072366071, 0.8571523554274554, 0.9766565459147395, 0.9666730102255284, 0.9888666403143487, 0.9798102539622547, 0.1810962945282465, 0.8088967822261677, 0.9337299970133601, 0.9044038621633176, 0.09228610838401201, 0.24217674926343125, 0.7265302477902937, 0.6431704475992213, 0.32599050083796144, 0.026431662230104982, 0.9409030891172949, 0.9004869932953978, 0.03867803122401884, 0.9572812727944662, 0.9852221862789982, 0.9822011203846094, 0.9570925546876384, 0.20590316618091462, 0.29598580138506475, 0.12225500491991806, 0.37319948870290776, 0.31931113691808694, 0.2938933349743586, 0.0730761805882189, 0.31136807381067183, 0.3574701523945691, 0.47015096130155276, 0.08237355685613983, 0.009325308323336584, 0.07771090269447153, 0.0015542180538894307, 0.5804154168282831, 0.19772393320523932, 0.08291648811832616, 0.13394201926806534, 0.995270296598748, 0.9912085699245397, 0.9946772730811355, 0.23826503435096552, 0.7147951030528966, 0.6088640082845286, 0.07610800103556607, 0.3044320041422643, 0.3387301041978036, 0.6290701935102067, 0.9912903441779115, 0.9992620716845612, 0.9975627406060343, 0.9922829823801607, 0.0441818978445416, 0.0607501095362447, 0.8946834313519674, 0.9946396920868135, 0.9978424012447504, 0.9692384246365325, 0.8045868940838092, 0.9930947908361445, 0.9589327418380627, 0.9323054977366381, 0.19450358048230457, 0.5342365010580632, 0.2671182505290316, 0.9238400908188366, 0.9946738769700925, 0.9306148375531054, 0.9670568365342669, 0.9990614805317326, 0.9764935671152302, 0.22841347798499417, 0.10542160522384346, 0.2635540130596086, 0.3865458858207594, 0.7960364451263072, 0.5707804882336202, 0.345286962017869, 0.07751339963666447, 0.6994586458486722, 0.03780857545127958, 0.20322109305062774, 0.05671286317691937, 0.6643504315398419, 0.3342513108684829, 0.9761744418293014, 0.9979356912156007, 0.9994672697591515, 0.9968380049041485, 0.9984627093913356, 0.9781956387570939, 0.9968786972080655, 0.9867279086673917, 0.9205057359022397, 0.9887627762572717, 0.9942880069745132, 0.6262812962253699, 0.3464534830182897, 0.026650267924483825, 0.964999999919595, 0.033100263849484786, 0.9186216195676792, 0.9516754149136364, 0.846598323216904, 0.9570482351570708, 0.9578939014860358, 0.9742475589738828, 0.9748826682949617, 0.026112928615043617, 0.999034895447903, 0.2023382985822663, 0.7587686196834985, 0.9048174283966536, 0.861806876468053, 0.0031891597109436577, 0.9392075348729072, 0.05581029494151401, 0.5405849819722313, 0.43761641397752055, 0.8678643144497731, 0.9082258345918701, 0.7715955375353727, 0.7339526654159632, 0.040629522549812246, 0.2254283186634744, 0.9802143574322698, 0.617150397262482, 0.3702902383574892, 0.5989484874410604, 0.04060667711464817, 0.020303338557324083, 0.32485341691718533, 0.9828505543733961, 0.7940895616639776, 0.9589597239187396, 0.9942952769654918, 0.05659920691557648, 0.49524306051129424, 0.2688462328489883, 0.1768725216111765, 0.994762516415101, 0.98054489443936, 0.9959325237135287, 0.9957868823680631, 0.04373222916365048, 0.9621090416003106, 0.9639996145802764, 0.38337138635608087, 0.5750570795341212, 0.8250582361452186, 0.3972436218962513, 0.35060919498983617, 0.05582515337702246, 0.10348077211350505, 0.08782249738580362, 0.00510595915033742, 0.8461938157478357, 0.9953180131155388, 0.9983475056997312, 0.9640007366821419, 0.8707950952483058, 0.10884938690603822, 0.9450376702033069, 0.1084364616441336, 0.8883448588538637, 0.21710666676023002, 0.4202064517939936, 0.06303096776909904, 0.2941445162557955, 0.9945271551748699, 0.00759032407719202, 0.9867421300349627, 0.9916254441722715, 0.9809771735488433, 0.9726780250155984, 0.08014793798660068, 0.19210061326947145, 0.6857101361075836, 0.041982253231076544, 0.9945786680672495, 0.9886835029955384, 0.9101510359473143, 0.03077023075266721, 0.058301489847158924, 0.9947231962996639, 0.37443680658290646, 0.212180857063647, 0.012481226886096883, 0.012481226886096883, 0.38275762450697104, 0.96648611715096, 0.9411024118502995, 0.9131634770975054, 0.9602338844450106, 0.991839247601242, 0.9768683980775567, 0.8795205259361086, 0.9127907222028827, 0.09900923894313306, 0.8663308407524143, 0.024752309735783264, 0.9823216026284148, 0.9810648430469524, 0.9956875286333956, 0.5539678758913481, 0.4335400767845333, 0.9690865303765478, 0.9609541459443867, 0.998345776286747, 0.5714711884918915, 0.42273211203509786, 0.14192456698329803, 0.8566161364349059, 0.012492539861553784, 0.016656719815405046, 0.9702539292473439, 0.8025529247603388, 0.37779946220915345, 0.18113672845644344, 0.020701340395022107, 0.09315603177759949, 0.3312214463203537, 0.9790219362124585, 0.962102959084575, 0.14062619396799333, 0.8585599210677487, 0.9917424636489678, 0.9978383901040644, 0.10870432642743198, 0.8333998359436453, 0.039528845973611636, 0.016470352489004848, 0.8741335045926492, 0.2148716157011362, 0.782746600054139, 0.9951796305341496, 0.04014244746582926, 0.9584009332466736, 0.884621281827334, 0.8642681742337106, 0.9689181887336823, 0.9061933164970418, 0.0014861391604747522, 0.7549586935211742, 0.24224068315738462, 0.9486409172166755, 0.9129871459748146, 0.9942364115479329, 0.998969646529211, 0.9963172090900083, 0.015362932108582531, 0.8910500622977868, 0.010241954739055021, 0.08193563791244017, 0.9529618716253626, 0.7911126256794482, 0.9392864379706618, 0.9978655116550559, 0.9345497207107369, 0.9989811742429743, 0.8237387023118048, 0.9964640839962245, 0.9141081685138034, 0.9982737770393977, 0.9972739238165007, 0.5255870915491208, 0.3454828942294867, 0.0098170002731876, 0.10081304126696497, 0.013592769609028985, 0.004530923203009661, 0.9742149951059467, 0.024560041893427226, 0.8979900533368627, 0.9805999307769458, 0.8384948157805625, 0.9881879175077632, 0.993810139326258, 0.9905999259342078, 0.00733777722914228, 0.9976043420973753, 0.4573790308536461, 0.4573790308536461, 0.997195076093127, 0.9838561775628705, 0.995305837872675, 0.052156056464957024, 0.9388090163692264, 0.9974518941132611, 0.9995074724962402, 0.0406024781253271, 0.9541582359451868, 0.9995460191597216, 0.9837602405490394, 0.5321855149286036, 0.10275810896118448, 0.2549923444592355, 0.03234977504333585, 0.07738573637817596, 0.9396782803717411, 0.9744312204697422, 0.007204827334392185, 0.9870613448117295, 0.932495671729452, 0.21976115984392688, 0.39684143327188454, 0.2043233924168742, 0.11850756760178703, 0.027243118988916556, 0.03269174278669987, 0.9770848776908531, 0.7758548946668489, 0.9836789735413145, 0.031138883819572607, 0.9653053984067508, 0.9916124492417168, 0.9738529290928324, 0.21852019047743265, 0.04046670194026531, 0.6231872098800857, 0.05780957420037901, 0.05896576568438659, 0.9987587327667852, 0.46474786779555743, 0.46474786779555743, 0.8453925481665145, 0.1352628077066423, 0.7889690896393993, 0.9861793662289019, 0.976029168072302, 0.9902145194407606, 0.05760639793040609, 0.2534681508937868, 0.6912767751648731, 0.9083600987776018, 0.9065277332919482, 0.09098977248655242, 0.9980900962248699, 0.9006900947339178, 0.9340170964701334, 0.06101619223171726, 0.004693553248593635, 0.9924737628986547, 0.9060788242998316, 0.012412038689038788, 0.081919455347656, 0.9887752375252762, 0.8060920064310096, 0.993268274466076, 0.9894224329598108, 0.9657510999243898, 0.99252361453599, 0.15578662225825501, 0.7229045892510255, 0.03006408499720711, 0.0915588043096762, 0.9711822295318712, 0.9892423118473102, 0.9488147018517183, 0.9642795356321563, 0.9777059828675853, 0.9161757020501283, 0.4801092253308643, 0.21077965990135508, 0.30445950874640176, 0.8916712073199512, 0.9987838935855641, 0.9971591991775187, 0.9963729774027201, 0.15473543910043341, 0.7636942639473003, 0.04367532555254169, 0.003743599333075002, 0.03306846077549585, 0.2873258470693518, 0.5905480065630109, 0.07511007620485131, 0.04689412165170611, 0.9808659157590202, 0.790476165368455, 0.9995740378003187, 0.9972429880552182, 0.989237949167806, 0.1624695243541141, 0.8350177879595168, 0.9917436889722416, 0.976471463595698, 0.04294769275661456, 0.4080030811878383, 0.15031692464815094, 0.0536846159457682, 0.34358154205291647, 0.9929172853162591, 0.9832360452072434, 0.8879116525257224, 0.9904599770661942, 0.004325152738280324, 0.9792326906833497, 0.0179127931222564, 0.8210265359857534, 0.9043523468332657, 0.07781285844531413, 0.8559414428984555, 0.20132018285588174, 0.31274267399624395, 0.005064658688198283, 0.48114257537883687, 0.926505336504671, 0.984384125407237, 0.9614925233979323, 0.9891016677033124, 0.9898915859099969, 0.05224849552225239, 0.9114459774437362, 0.03483233034816826, 0.3295121084472821, 0.0617835203338654, 0.6060669137512511, 0.9353503760313568, 0.9957461753831262, 0.7235397332795287, 0.9948090476756423, 0.93173638449602, 0.6502227266300147, 0.3478691587470578, 0.9963319531661793, 0.016135186103195174, 0.8182844380906125, 0.011525132930853697, 0.009220106344682958, 0.14291164834258585, 0.9909705956594301, 0.9889240480129969, 0.9053267572102499, 0.8990594266647085, 0.8120175014388566, 0.014277230794529349, 0.08209407706854376, 0.026769807739742527, 0.06424753857538207, 0.1667059070278782, 0.8057452173014112, 0.9840557990483295, 0.2981025020481846, 0.4377115923739181, 0.058001844289918274, 0.20570421521424503, 0.8412287147150797, 0.9469174215420075, 0.98762069949811, 0.993434053823822, 0.032374874186768716, 0.9668314700321385, 0.9398045101631762, 0.9733050713616526, 0.9956299464497309, 0.09166812978136966, 0.07883459161197791, 0.8286798932235817, 0.9170870788849695, 0.8447481606563716, 0.0028603112179318127, 0.8209093195464302, 0.1759091399028065, 0.9260816185027554, 0.8097436767432196, 0.7802253872279546, 0.984967108706664, 0.971836099670989, 0.9701482923120999, 0.8404398065428547, 0.9972327601829967, 0.9051035303515907, 0.9791558407978999, 0.9574526044522018, 0.9713782801000495, 0.03865915560301712, 0.7035966319749116, 0.0618546489648274, 0.19329577801508563, 0.8284236150251354, 0.8343471933539953, 0.9963113928419391, 0.9629353393069683, 0.9426885793210613, 0.02618579387002948, 0.8154700192297852, 0.997036100903637, 0.991388172352006, 0.1039215390561363, 0.8833330819771585, 0.9991652848437383, 0.98991013702865, 0.6701706476672873, 0.9204704726900689, 0.05414532192294522, 0.9993866269031922, 0.9744646625678642, 0.5701323866133658, 0.07493168509775666, 0.35511102937632505, 0.2259588750931643, 0.1595003824187042, 0.6114181326050329, 0.979907975207124, 0.9768845875307721, 0.019154599755505337, 0.13591566239549197, 0.8494728899718248, 0.9276045903136572, 0.9958336774998914, 0.9939031714616268, 0.979703089359132, 0.9851281691737681, 0.9571826055696618, 0.9912029762040704, 0.9502868947558367, 0.9517274320728003, 0.03965530966970001, 0.8360857590684361, 0.2415265414258067, 0.7563594323597631, 0.7906264826487859, 0.9596601243683591, 0.009536394477251, 0.047681972386254996, 0.33695260486286865, 0.6071504483849803, 0.06410794052019039, 0.9341442761513458, 0.4611172872731223, 0.3206251681418676, 0.023318194046681277, 0.00874432276750548, 0.18159043613853046, 0.0046636388093362555, 0.9543145152745525, 0.990524245436481, 0.006269140793901779, 0.9664219379484422, 0.08789928735793895, 0.7876866370990497, 0.05314840630945145, 0.03679505052192793, 0.03270671157504705, 0.0013627796489602936, 0.9376606540382519, 0.9732475312070494, 0.16713195271061426, 0.8320264602332753, 0.8609909979122348, 0.06377711095646184, 0.03188855547823092, 0.9590558121351661, 0.015468642131212356, 0.0151344914196469, 0.9292577731663197, 0.05448416911072884, 0.9586348779539301, 0.9477687014153592, 0.9942129186914123, 0.9926420736703622, 0.18877960895093854, 0.5842403414947149, 0.006509641687963398, 0.037430439705789534, 0.18226996726297515, 0.0333794347123169, 0.007417652158292644, 0.956877128419751, 0.9624128122692956, 0.32543374278034415, 0.4926290601720806, 0.09554018136670654, 0.08359765869586822, 0.9668556666072091, 0.9052696325125166, 0.07213303844721249, 0.021639911534163742, 0.3584818677497205, 0.4582012282570478, 0.08356113079549184, 0.007617451149865278, 0.09094775009233089, 0.0011541592651311027, 0.9715776083520467, 0.08896610458550873, 0.2486176073348463, 0.6593241449419208, 0.001218713761445325, 0.08777734789400542, 0.12069385335425745, 0.7509839764264907, 0.00975303865488949, 0.029259115964668472, 0.3376812664827573, 0.6080058973639008, 0.026044565765957345, 0.023350300341892793, 0.003592353898752737, 0.3224548601866497, 0.09212996005332849, 0.03948426859428364, 0.5396183374552097, 0.7683522055930048, 0.958983424479578, 0.07845629182889634, 0.42572184582565065, 0.1942114764944811, 0.2971049739750009, 0.002572337437012995, 0.9932723767419843, 0.9170291554844314, 0.1850051291607997, 0.569246551263999, 0.03202011850859995, 0.03202011850859995, 0.17788954726999973, 0.9809506526659392, 0.20611154312660393, 0.6183346293798118, 0.1766670369656605, 0.9407065283764284, 0.9939262439702872, 0.7950274901484639, 0.9894399215614155, 0.6394076902615083, 0.010696403593896711, 0.8806705625641627, 0.10696403593896713, 0.9973501632018295, 0.9453774227303483, 0.38429720578386173, 0.3910540797317098, 0.12542447265693069, 0.05616651469148748, 0.04307507141753175, 0.9911738475691971, 0.9540387854145036, 0.552077290290959, 0.19762766768386503, 0.17362430723643205, 0.07641069742432839, 0.9872362871064633, 0.9955474608536116, 0.9998619835025913, 0.7857727622722508, 0.1817623827320153, 0.032157960021818095, 0.9684905081296638, 0.41987054978395205, 0.020481490233363514, 0.5530002363008149, 0.006827163411121172, 0.008933436833299368, 0.25906966816568167, 0.7303084611222234, 0.9166554188997661, 0.9735602076024882, 0.8919467575667029, 0.868689750984799, 0.4464211159150562, 0.37903679653165145, 0.08493231922283302, 0.05966319945405625, 0.030182559723816692, 0.9339736333049125, 0.029339485862981542, 0.03422940017347847, 0.9494261958660813, 0.9631274919940055, 0.9685057719447963, 0.028184030400509943, 0.2961498972060405, 0.6663372687135911, 0.024679158100503376, 0.023496779132517694, 0.9727666560862325, 0.9766761571590483, 0.005734702956479832, 0.923287175993253, 0.068816435477758, 0.997768785174183, 0.5351026440645799, 0.46213410169213714, 0.996070126657396, 0.9939544838255733, 0.9978199325868683, 0.8523221170152857, 0.9979158120408643, 0.9894140791491515, 0.21100505653065948, 0.786873023312251, 0.3610036891470387, 0.5137530975930181, 0.07637470422298974, 0.009768857516894035, 0.03907543006757614, 0.9221786709227972, 0.9390870769987913, 0.2906839884852543, 0.7077523197901844, 0.5761646154369744, 0.03879254033295302, 0.24801788081724063, 0.1068384717366575, 0.02988933435489823, 0.8258703232601147, 0.9978141824627929, 0.9764935671152302, 0.03410762460816145, 0.9618350139501529, 0.0960476511607376, 0.26374989921916836, 0.5259752325468964, 0.11434244185802096, 0.9950552704417449, 0.9133701419994021, 0.9863430609961241, 0.19318457076143156, 0.2481514513924466, 0.2524207236744672, 0.08538544564041174, 0.22093484059456536, 0.932318139839695, 0.8378589035873228, 0.35887178453642105, 0.018887988659811634, 0.5477516711345374, 0.07555195463924654, 0.5321409350864517, 0.41439060051413046, 0.007548098370020591, 0.037740491850102954, 0.00830290820702265, 0.10781221493911664, 0.8864559894994034, 0.10568074472793955, 0.6642789668613344, 0.2113614894558791, 0.018871561558560634, 0.940177045597125, 0.5017552737686625, 0.45157974639179627, 0.7119454353063722, 0.9578316082624975, 0.8952244417343489, 0.9585745107549964, 0.9725977565074176, 0.3598603705617011, 0.5038045187863815, 0.10795811116851034, 0.7642275238026006, 0.19000131807246978, 0.03237059493086522, 0.012666754538164652, 0.9354697447380111, 0.040672597597304835, 0.9955334062503999, 0.24673536809912466, 0.08018899463221552, 0.5736597308304648, 0.09252576303717175, 0.078428360737549, 0.14985418926638827, 0.5784091604394239, 0.18486685030993694, 0.008403038650451678, 0.7302467424605954, 0.7672648185614961, 0.9908605686703282, 0.9932398202202587, 0.9551680026574773, 0.7388601507680803, 0.8553353949205821, 0.9488783688840763, 0.02790818732011989, 0.9911921695652692, 0.9393603949741626, 0.9353354918259629, 0.03464205525281344, 0.8681825359435115, 0.938603592620349, 0.060694920538960216, 0.906931586936525, 0.9954796275119349, 0.7716540412410409, 0.019109838598128877, 0.544630400046673, 0.04299713684578997, 0.39175169126164194, 0.9975123133305801, 0.9514477018283148, 0.9680601543753173, 0.8737712493914158, 0.9906416262111277, 0.9724816248345121, 0.7100313496544324, 0.35645800589201115, 0.1580440315280242, 0.2722823804042591, 0.17608166556111393, 0.03521633311222279, 0.0017178699079133067, 0.9930377174300724, 0.9964008436435341, 0.9857515775933026, 0.9791484971708172, 0.6267914335885061, 0.11665285014008309, 0.0002487267593605183, 0.21266137925324316, 0.0435271828880907, 0.06614021047469526, 0.08818694729959368, 0.12913088711726217, 0.1511776239421606, 0.5669160897831023, 0.9929010624068766, 0.9863813082028131, 0.923069254188348, 0.3173273201262759, 0.6573208774044287, 0.02266623715187685, 0.8237550982181532, 0.09068863466621871, 0.07935255533294136, 0.3426161662978004, 0.3375024921739526, 0.05113674123847767, 0.2607973803162361, 0.2581274147989099, 0.7375068994254569, 0.9922319977376173, 0.3732865293201753, 0.07812973869492042, 0.5121838425555894, 0.03472432830885352, 0.8673523707544373, 0.028837802608203796, 0.10204145538287497, 0.98767719730712, 0.9751183984357746, 0.017892080705243573, 0.929811543546009, 0.03719246174184036, 0.9745818061826734, 0.981608084540052, 0.014827916684895045, 0.9702107461642029, 0.9982790051384007, 0.22198982041704346, 0.019508196339679578, 0.3491294448377138, 0.4089994267077649, 0.6184582686948696, 0.2492433323462031, 0.10416139262229383, 0.027900373023828706, 0.09911545435757987, 0.817702498450034, 0.08259621196464989, 0.9888567881434513, 0.008488041099943788, 0.9988244088207741, 0.18225011186279705, 0.8153294478072499, 0.06253420288807507, 0.39083876805046924, 0.039604995162447545, 0.15529327050538644, 0.22095418353786525, 0.1302795893501564, 0.9421361158567907, 0.12682122013579955, 0.8726057086955761, 0.980449435981822, 0.9905393099993665, 0.9927536277003302, 0.9202885717689646, 0.9310546724481412, 0.004113899229998767, 0.991449714429703, 0.07778069055203501, 0.9226399155137948, 0.9566216009990223, 0.33511398662178316, 0.5201514805070934, 0.120231735658197, 0.009379780796029554, 0.015348732211684724, 0.3858158569676206, 0.12107192164255877, 0.179186444030987, 0.017757215174241954, 0.2954154888078434, 0.9416227735142115, 0.9998294456272949, 0.9968086458288539, 0.9985138253710303, 0.9978281485984207, 0.8832576663780177, 0.06308983331271555, 0.9592875927416485, 0.9925485902324586, 0.9954828454508531, 0.9067479386712736, 0.9601218398485829, 0.2946983438077846, 0.7018956404384579, 0.0036684441137898494, 0.9870984581329887, 0.8588758976965976, 0.9779557396016115, 0.9734645041269744, 0.7085403339797873, 0.14696536438366584, 0.015532924690956552, 0.06930074092888308, 0.05974201804214059, 0.2638230239327061, 0.6302438905059091, 0.05862733865171248, 0.01465683466292812, 0.9546481476197367, 0.6015259047875535, 0.04788683878895328, 0.3192455919263552, 0.007561079808782097, 0.022683239426346292, 0.3312773978503331, 0.6152294531506186, 0.47242738027960407, 0.5017203708774159, 0.00062325511910238, 0.00124651023820476, 0.02306043940678806, 0.7956341729860291, 0.18503120302000678, 0.8071307228678644, 0.7390351373761439, 0.9729415483279851, 0.9478463980871681, 0.9498665060465978, 0.2308693938162093, 0.7387820602118698, 0.9986836782774252, 0.9549612729231776, 0.044863952419209686, 0.26901157766310674, 0.10030940184048047, 0.3875590525654927, 0.2416544680702484, 0.11842243700104588, 0.7295667993814433, 0.008458745500074706, 0.14168398712625133, 0.9543473220368812, 0.9532066813029981, 0.9960966967846142, 0.4830525267884447, 0.09661050535768893, 0.2898315160730668, 0.82203660518471, 0.9641257459795777, 0.9917286686335612, 0.993200920151743, 0.2751021943917646, 0.45401481032487023, 0.010260221702256956, 0.22636614130604407, 0.025009290399251326, 0.008977693989474836, 0.01535227368784073, 0.9825455160218067, 0.8023848418309797, 0.09439821668599761, 0.09439821668599761, 0.11981956680141626, 0.8387369676099138, 0.9435643417167198, 0.2988386251663145, 0.6830597146658616, 0.9525310546597002, 0.9481833001242705, 0.7699557327653189, 0.1283259554608865, 0.9403055094552332, 0.042741159520692414, 0.9804671303501007, 0.058903530370035144, 0.6417384624524881, 0.2945176518501757, 0.16181108934999303, 0.8090554467499652, 0.9646188555872598, 0.4103061688448132, 0.38641146683222005, 0.07441492912493283, 0.12834868509621444, 0.43612721522091435, 0.0049559910820558455, 0.007433986623083768, 0.5525930056492268, 0.9626873929449531, 0.9988215865283407, 0.5100328274047436, 0.2415944971917207, 0.002982648113478033, 0.24457714530519872, 0.11835840889616958, 0.04142544311365935, 0.8344267827179955, 0.9969942859697521, 0.995231833487521, 0.9964976649932051, 0.9858775671396516, 0.9803712342808333, 0.998476503331802, 0.9395980668966669, 0.9878909803649474, 0.9797336089199588, 0.929455714715559, 0.6034322986604339, 0.3993301976429342, 0.13790155347616673, 0.4299922454847404, 0.1172706124049292, 0.19979437668987937, 0.02714597509373361, 0.008686712029994756, 0.08035208627745148, 0.996975844256075, 0.9968985505059443, 0.13058922306971868, 0.783535338418312, 0.08744402402057719, 0.9112587766354885, 0.6358131665849743, 0.22161524375640657, 0.02612930821582086, 0.027097060371962377, 0.08903319836501923, 0.8888911661144824, 0.32131797825913866, 0.5355299637652311, 0.06016551484179686, 0.053602004131782656, 0.7887152036533733, 0.09735874219854401, 0.9529169992744356, 0.9559847031657703, 0.9857090530554695, 0.9985349456329861, 0.9499423173133229, 0.9887107959759787, 0.7567035688767563, 0.9382620529277875, 0.18780193971882952, 0.273166457772843, 0.1365832288864215, 0.37560387943765905, 0.017072903610802687, 0.8608553794343667, 0.11228548427404784, 0.3338568037102929, 0.07419040082450953, 0.5935232065960763, 0.9748767808239669, 0.7414701391898414, 0.9701242941574876, 0.97939648010191, 0.3844422611130635, 0.38558473440017516, 0.10739248898849323, 0.08225807667203737, 0.039986565048907054, 0.6805564248693339, 0.9971047880145066, 0.9959681941515423, 0.9570666715066621, 0.9694160102291157, 0.9802607544609, 0.9899138626514197, 0.9413114232774991, 0.8506648358924405, 0.1496034435394921, 0.9673330081998643, 0.9351305660160673, 0.8291890181912387, 0.16583780363824774, 0.574898384404864, 0.2524163219027606, 0.014372459610121598, 0.0008982787256325999, 0.15540221953443978, 0.0008982787256325999, 0.5597572389172201, 0.3630529597315592, 0.032784046530943474, 0.004856895782361996, 0.03885516625889597, 0.17017270688744532, 0.7941392988080781, 0.9894224329598108, 0.21038571607609063, 0.1961704649898683, 0.5885113949696049, 0.14747187367047232, 0.8517253111988504, 0.06788905410585218, 0.9232911358395897, 0.9990147364864226, 0.6319583963829168, 0.9084209120959784, 0.9333479165567061, 0.9906940883408261, 0.9630096295292001, 0.36533628194367035, 0.5740998716257677, 0.9447878820421494, 0.41800695082175293, 0.5573426010956706, 0.07502358960534752, 0.5015862847900378, 0.06216240281585938, 0.008574124526325432, 0.35368263671092404, 0.9793834455896845, 0.21777614046867494, 0.1011103509318848, 0.040184883062672164, 0.6144398248937615, 0.02592573100817559, 0.055984083458524576, 0.04737114754182849, 0.01722587183339218, 0.8268418480028246, 0.04952438152100251, 0.8231692507730818, 0.16463385015461635, 0.9349473420446442, 0.40804659571952073, 0.5440621276260277, 0.8092790565336374, 0.16859980344450778, 0.986922938995522, 0.37411677056411924, 0.49819253453908807, 0.04282818248882173, 0.01448600290063088, 0.041568530062679916, 0.027712353375119944, 0.020418326792110586, 0.978037853342097, 0.21795325057048542, 0.7265108352349514, 0.990401219178359, 0.942683739900894, 0.9183097511658577, 0.9813331668475652, 0.7254187774865913, 0.9170205103549485, 0.9846790623726906, 0.33422975921614057, 0.6461775344845385, 0.42085116080277307, 0.5711551468037634, 0.976486542178782, 0.5990264082424509, 0.29951320412122545, 0.9885020427176732, 0.03116252131419889, 0.023371890985649166, 0.4953542450569532, 0.17918449755664362, 0.27072440391710284, 0.4230028182772938, 0.5060813328115149, 0.03868541516478999, 0.028538421023205727, 0.0025367485353960644, 0.9772244146173397, 0.1344341755638354, 0.8611053948278106, 0.9863785183287697, 0.8859288236292507, 0.11132910881004744, 0.0015680156170429218, 0.0015680156170429218, 0.9072240217349219, 0.983608358858305, 0.46829353854035566, 0.5151228923943912, 0.3587996727368803, 0.4162076203747811, 0.21527980364212818, 0.9233004681753249, 0.10432796426729071, 0.02671813719040372, 0.1768486223555294, 0.6908546902090105, 0.0740000263780355, 0.9221541748647502, 0.7060422820828802, 0.35025793718029785, 0.6136097696466872, 0.02984654101285746, 0.005267036649327787, 0.9268095122229905, 0.2365229185804612, 0.26754231773855447, 0.011632274684284977, 0.10469047215856479, 0.37611021479188095, 0.6737477896496965, 0.2828712093949107, 0.029144306422505956, 0.000857185483014881, 0.012857782245223215, 0.48113943306519735, 0.5102902919079981, 0.008414680903076531, 0.12950987221715865, 0.28869909015074946, 0.10252864883858392, 0.15109485092001843, 0.14839672858216094, 0.17807607429859312, 0.15851377233265088, 0.4374026650081419, 0.2526685694324961, 0.004767331498726342, 0.14540361071115343, 0.955281325976911, 0.9572377119841468, 0.34975170837477293, 0.49392416831551905, 0.11791883297622752, 0.035598138256974346, 0.00044497672821217934, 0.0022248836410608966, 0.9801007172566677, 0.9113880764897583, 0.373756643562529, 0.33991859352806136, 0.029223770484312968, 0.033838050034467645, 0.2230235115908095, 0.9673185550036906, 0.7685192988012505, 0.1717313917786313, 0.5394605676524397, 0.28933006223573754, 0.7136153381276117, 0.2837265802194119, 0.9942433961274927, 0.21450137967419644, 0.6435041390225893, 0.8822678934015885, 0.0767870813084864, 0.0062683331680397055, 0.03447583242421838, 0.9656378772542382, 0.9648952935177396, 0.031809734951134275, 0.9557081915009363, 0.9954550396794679, 0.9978325177511495, 0.9987219101185452, 0.967375146348844, 0.013214403145275942, 0.11452482725905816, 0.8677458065397868, 0.002202400524212657, 0.2267869535144444, 0.23915715097886864, 0.41233991548080795, 0.11957857548943432, 0.0368729185660874, 0.88740824015717, 0.0737458371321748, 0.007167605327628323, 0.066300349280562, 0.6182059595079429, 0.09676267192298237, 0.19890104784168597, 0.010751407991442485, 0.042037475474212306, 0.9500469457171982, 0.20912010640840425, 0.20368199489423772, 0.3430953991665072, 0.12260469595575474, 0.12161594840772445, 0.9985634944618804, 0.9639345318661541, 0.034426233280934075, 0.08721429023909077, 0.05814286015939385, 0.6139201999183056, 0.08436415003519891, 0.15618768317327367, 0.9267865046623995, 0.7002342769661365, 0.261104306665339, 0.023736755151394458, 0.9778866171551733, 0.8982364133752947, 0.7905459088405958, 0.19763647721014896, 0.8881489986862556, 0.029973971762893535, 0.8917256599460827, 0.07814642638182957, 0.9940611368118605, 0.9885707304362452, 0.11488204653247111, 0.8568285970546803, 0.026327135663691294, 0.9963270459242469, 0.9911269086460538, 0.9934068474979979, 0.9819579126156368, 0.9084916694914624, 0.4026829249137184, 0.3231593787357891, 0.1433449908812356, 0.045586746216647364, 0.08205614318996525, 0.0025325970120359644, 0.9975388883634828, 0.9122739620030532, 0.603067323160252, 0.301533661580126, 0.10641922661995466, 0.3116563065298672, 0.5853057464097506, 0.9943307785365401, 0.043824223831484994, 0.16903629192144212, 0.01878181021349357, 0.7262299949217513, 0.043824223831484994, 0.07446802862084509, 0.8407680650740574, 0.062457056262644264, 0.021619750244761475, 0.9941203238161804, 0.8389489912998266, 0.35114812139434054, 0.44054428264544554, 0.1351669958116708, 0.05292252746065417, 0.007866862190097242, 0.012873047220159122, 0.22870554856613373, 0.6861166456984013, 0.2912023200455997, 0.6814859274096192, 0.015708008965115337, 0.01087477543738754, 0.049551572770535485, 0.44926759311952175, 0.5004708849824084, 0.10584017617369142, 0.31129463580497474, 0.14942142518638787, 0.42958659741086513, 0.7272016011962739, 0.1731432383800652, 0.05679098218866138, 0.031858355861931996, 0.011081167256324173, 0.9304107563530438, 0.79524379914494, 0.999477827007426, 0.8028397602384831, 0.9722618369958252, 0.027041416452475542, 0.9579320950246812, 0.02456236141088926, 0.45279990940421083, 0.5466331436421918, 0.9342000818732182, 0.9745715805355394, 0.9743845149963527, 0.9384020091055685, 0.09485570260536764, 0.29089082132312744, 0.6070764966743529, 0.9017703445659242, 0.28073136875017024, 0.5614627375003405, 0.9882712902323237, 0.5005490452144205, 0.16192059217423646, 0.17005358995467754, 0.11608005922993207, 0.051016076986403265, 0.5476076228198348, 0.06001179428162572, 0.3900766628305672, 0.8399126230855006, 0.0017832539768269653, 0.10164547667913701, 0.014266031814615722, 0.0410148414670202, 0.9971450999271054, 0.20464679068255176, 0.33985984881209486, 0.24923055579553624, 0.019733797672960348, 0.18564387440488622, 0.9303154328580712, 0.7304979981198348, 0.4600170309792942, 0.3692918358027677, 0.02889868391534074, 0.07530330135632059, 0.06641139861313881, 0.980277391505939, 0.9164337098536068, 0.9902866944581369, 0.9525005448090337, 0.7280596879666905, 0.3142384824151941, 0.3927981030189926, 0.23567886181139558, 0.9879031239614285, 0.9305101395942821, 0.004555077727221567, 0.8176364520362713, 0.17650926192983574, 0.8867887281459119, 0.10884771392404695, 0.22434714614954127, 0.5432985105549132, 0.005405955328904609, 0.1937133992857485, 0.008108932993356913, 0.02432679898007074, 0.7357081010198295, 0.5843870242275018, 0.02874034545381156, 0.1820221878741399, 0.11017132423961098, 0.0958011515127052, 0.18492406148151197, 0.8013375997532186, 0.902411249483503], \"Term\": [\"\\\"normal\\\"\", \"\\\"skepticism\", \"#define\", \"'cause\", \"(205)\", \"(403)\", \"(compared\", \"(david\", \"(first\", \"(formerly\", \"(mydisplay,\", \"(sorry,\", \"(unassisted)\", \"(version\", \"*******\", \"*very*\", \"+====================================================================+\", \"----\", \"----\", \"------\", \"------\", \"--------\", \"--------\", \"----------\", \"----------\", \"----------\", \"----------\", \"------------\", \"------------\", \"---------------\", \"---------------\", \"-------------------------------\", \"-----------------------------------------\", \"---------------------------------------------------------------------\", \"---------------------------------------------------------------------\", \"----------------------------------------------------------------------\", \"------------------------------------------------------------------------\", \"------------------------------------------------------------------------\", \"----------------------------------------------------------------------------\", \"----------------------------------------------------------------------------\", \"--------------------------------------------------------------------------------\", \"--clh]\", \".500\", \"0.333\", \"1-0)\", \"1069\", \"10mb/s\", \"16-bit\", \"16-bit\", \"16-bit\", \"1993\", \"1993\", \"1993\", \"1993\", \"1993\", \"2400\", \"2400\", \"256k\", \"462-0666\", \"5.00\", \"50mhz\", \"55.0\", \"64-bit\", \"8-bit\", \"8-bit\", \"==================================================================\", \">the\", \">the\", \"[kk]\", \"^^^^^^^^^^^\", \"_/_/_/\", \"_______________________________________________________________________________\", \"abused\", \"accelerators\", \"accept\", \"accept\", \"accept\", \"accept\", \"adaptec\", \"adapter\", \"adirondack\", \"adjective\", \"administration\", \"administration\", \"advance.\", \"affair\", \"aged\", \"aged\", \"agencies\", \"allah,\", \"allocated\", \"allocation\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amendment\", \"american\", \"american\", \"american\", \"amish\", \"among\", \"among\", \"among\", \"among\", \"among\", \"among\", \"ample\", \"andrew\", \"andrew\", \"andrew\", \"andrew\", \"andrew@idacom.hp.com\", \"angels\", \"anonymous\", \"antibiotic\", \"anybody\", \"anybody\", \"anybody\", \"anybody\", \"anybody\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyways.\", \"anywhere.\", \"apartment\", \"apartment.\", \"apple\", \"application\", \"applications\", \"approval\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"arab\", \"arabs\", \"argic\", \"argument\", \"argument\", \"arguments\", \"argv,\", \"armenia\", \"armenian\", \"armenians\", \"arms\", \"arose\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"asynchronous\", \"atheists\", \"atlanta\", \"atlanta\", \"automatics\", \"available\", \"available\", \"average\", \"awards\", \"azerbaijan\", \"azerbaijani\", \"azerbaijanis\", \"azeri\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"baku\", \"ball\", \"baltimore\", \"baltimore\", \"banks\", \"banks\", \"baseball\", \"battery\", \"batting\", \"batting\", \"baud\", \"baud\", \"belief\", \"beliefs\", \"believe\", \"believe\", \"believe\", \"better\", \"better\", \"better\", \"better\", \"bible\", \"biblical\", \"biggest\", \"bike\", \"bike?\", \"biker)\", \"binghamton\", \"bios\", \"blessed\", \"blew\", \"blues\", \"bold\", \"bookstore\", \"boot\", \"boston\", \"boston\", \"boston\", \"bowl\", \"brains\", \"brake\", \"brake\", \"braves\", \"braves\", \"breaker\", \"breton\", \"brigham\", \"broadcast\", \"broadcast\", \"bronx\", \"buffalo\", \"building.\", \"bullets\", \"burned\", \"burned\", \"burnt\", \"burst\", \"burst\", \"bury\", \"bury\", \"bytes\", \"bytes\", \"bytes\", \"bytes.\", \"c650\", \"cable\", \"cable\", \"cache\", \"calgary\", \"calgary,\", \"california\", \"california\", \"california\", \"california\", \"came\", \"came\", \"came\", \"came\", \"can't\", \"can't\", \"can't\", \"can't\", \"can't\", \"can't\", \"canada\", \"canada\", \"canada\", \"canada\", \"canadian\", \"cancer\", \"candida\", \"cape\", \"cape\", \"caps\", \"caps\", \"caps\", \"captain\", \"captain\", \"car.\", \"card\", \"card,\", \"card.\", \"cards\", \"cards\", \"cards\", \"career\", \"cars\", \"carson\", \"casualties\", \"catholic\", \"caught.\", \"cd's\", \"center\", \"center\", \"center\", \"cereals\", \"chain\", \"challenges\", \"championships\", \"char\", \"chastity\", \"cheers,\", \"cheers,\", \"cheers,\", \"cheers,\", \"chevrolet\", \"chicago\", \"chicago\", \"chicago\", \"children\", \"children\", \"children\", \"children\", \"chip\", \"chip\", \"chipset\", \"christ\", \"christian\", \"christianity\", \"christians\", \"christians.\", \"church\", \"cincinnati\", \"ciphertext\", \"circuits\", \"citizens\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claims.\", \"clark\", \"clearance\", \"cleveland\", \"click\", \"clinical\", \"clinton\", \"clinton\", \"clipper\", \"coach\", \"coach\", \"coated\", \"cocaine\", \"code\", \"code\", \"code\", \"column\", \"column\", \"compatible.\", \"compilers\", \"completely.\", \"computer\", \"computer\", \"computer\", \"concentrate\", \"concise\", \"concise\", \"condition.\", \"condition.\", \"condition.\", \"condition.\", \"conductor\", \"configuration.\", \"configure\", \"congress\", \"connected\", \"connected\", \"connected\", \"connected\", \"connector\", \"conscious\", \"constitution\", \"controller\", \"cooling\", \"cooling\", \"cooper\", \"corel\", \"corel\", \"corn\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"countersteering\", \"countries\", \"court\", \"crashes\", \"creative\", \"creative\", \"creed\", \"crime\", \"crime\", \"cross\", \"cross\", \"cross\", \"cross\", \"crowd\", \"crypto\", \"crypto\", \"cryptography\", \"cubs\", \"cup.\", \"current\", \"current\", \"current\", \"current\", \"cursor\", \"cyprus\", \"data\", \"data\", \"data\", \"daughter\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"deaf\", \"dealt\", \"deciding\", \"defenseman\", \"defensive\", \"definition,\", \"dennis,\", \"deskjet\", \"detroit\", \"detroit\", \"detroit\", \"detroit,\", \"device.\", \"diamond\", \"diego\", \"diego\", \"diet\", \"diff\", \"directory\", \"disease\", \"disease\", \"disk\", \"disk\", \"display\", \"display\", \"display\", \"ditto\", \"division\", \"division\", \"division\", \"division\", \"division\", \"documentary\", \"drafting\", \"drive\", \"drive\", \"drive,\", \"drive.\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver,\", \"drivers\", \"drivers\", \"drives\", \"driving\", \"driving\", \"drops\", \"eaten\", \"edmonton\", \"eggs\", \"email\", \"email\", \"email\", \"embrace\", \"employer\", \"encrypted\", \"encryption\", \"enforcement\", \"engine\", \"engine\", \"engine\", \"engine\", \"enhancement\", \"enjoy!\", \"entity\", \"entries\", \"entries,\", \"entry\", \"equal.\", \"escrow\", \"etc?\", \"eternal\", \"europe\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"evidence\", \"evidence\", \"evolutionary\", \"excited\", \"executing\", \"exhaust\", \"exist.\", \"explain\", \"explain\", \"export\", \"ext.\", \"ext.\", \"faith\", \"fallacy\", \"fans\", \"father,\", \"father,\", \"federal\", \"file\", \"file:\", \"file:\", \"files\", \"financial\", \"find\", \"find\", \"find\", \"find\", \"find\", \"finland\", \"finnish\", \"firearms\", \"firearms\", \"firms\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fixes\", \"flags\", \"floor,\", \"floppy\", \"floppy\", \"flyers\", \"folks,\", \"following\", \"following\", \"following\", \"following\", \"following\", \"font\", \"fonts.\", \"fonts.\", \"for?\", \"for?\", \"foreground\", \"formatted\", \"fractal\", \"francis\", \"francisco\", \"francisco\", \"francisco\", \"fredericton\", \"front\", \"front\", \"functions\", \"fund.\", \"game\", \"game\", \"game\", \"game,\", \"games\", \"games\", \"games\", \"games.\", \"gangs\", \"gaza\", \"geb@cadre.dsl.pitt.edu\", \"generated,\", \"genocide\", \"getting\", \"getting\", \"getting\", \"getting\", \"ghetto\", \"giants\", \"gifs\", \"gilmour\", \"girlfriend\", \"given,\", \"goal\", \"goal\", \"goal\", \"goaltending\", \"god's\", \"god,\", \"god.\", \"going\", \"going\", \"going\", \"going\", \"going\", \"good\", \"good\", \"good\", \"good\", \"gordon\", \"governed\", \"government\", \"government.\", \"greece\", \"greek\", \"greek\", \"greeks\", \"gretzky\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"grounded\", \"guidelines\", \"guitar\", \"guns\", \"guns\", \"guys\", \"guys\", \"gxxor\", \"habs\", \"halifax\", \"halifax\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard,\", \"harris\", \"hartford\", \"hartford,\", \"he'll\", \"he's\", \"he's\", \"he's\", \"health\", \"health\", \"health\", \"helicopter\", \"henrik]\", \"hewlett\", \"hicnet\", \"hitter\", \"hockey\", \"hockey\", \"holy\", \"home\", \"home\", \"home\", \"home\", \"home\", \"honda\", \"hong\", \"hood\", \"hours.\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hung\", \"hung\", \"huntsville,\", \"i've\", \"i've\", \"i've\", \"i've\", \"idacom\", \"ideas?\", \"igor\", \"illness\", \"image\", \"image\", \"implementations\", \"import\", \"inc.\", \"include\", \"include\", \"include\", \"infantile\", \"info?\", \"information\", \"information\", \"information\", \"information?\", \"init\", \"initiation\", \"injuries\", \"innings\", \"inputs\", \"inspection\", \"insurance\", \"insurance.\", \"intellect,\", \"intentional\", \"intergraph\", \"internet:\", \"internet:\", \"internet:\", \"internet:\", \"invalid\", \"investigating\", \"islamic\", \"island.\", \"islanders\", \"islanders\", \"isles\", \"israel\", \"israel's\", \"israel.\", \"israel.\", \"israeli\", \"israelis\", \"it....\", \"jersey\", \"jersey\", \"jesus\", \"jets\", \"jewish\", \"jewish\", \"jewish\", \"jews\", \"jews\", \"jews\", \"jews.\", \"jobs\", \"jobs\", \"john's\", \"john's\", \"joysticks\", \"jpeg\", \"judas\", \"judges\", \"jumper\", \"keller\", \"kent\", \"keyboard,\", \"keyboard.\", \"keyboard.\", \"keypad\", \"keys\", \"keys\", \"kidding,\", \"kidney\", \"killed\", \"killed\", \"killed\", \"killed\", \"kings\", \"kings\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"kong\", \"koresh\", \"koresh\", \"laptop\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"latin\", \"laugh\", \"laws\", \"laws\", \"layout\", \"layout\", \"layout\", \"leafs\", \"leafs\", \"league\", \"league\", \"league\", \"league.\", \"lease\", \"lebanese\", \"lebanon\", \"left\", \"left\", \"left\", \"left\", \"left\", \"legal\", \"legal\", \"legal\", \"lemieux\", \"let's\", \"let's\", \"let's\", \"let's\", \"liability\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"lindros\", \"line\", \"line\", \"line\", \"line\", \"list\", \"list\", \"list\", \"list\", \"list\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lived\", \"lived\", \"lived\", \"lived\", \"location:\", \"locations\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"lord\", \"losses\", \"lost\", \"lost\", \"lost\", \"lost\", \"lost\", \"lost.\", \"louis\", \"louis\", \"louis\", \"love.\", \"lunar\", \"m'lud.\", \"macs\", \"mahan\", \"mail\", \"mail\", \"mail\", \"mailing\", \"mainstream\", \"make\", \"make\", \"make\", \"make\", \"make\", \"mamma\", \"manhattan\", \"many\", \"many\", \"many\", \"many\", \"massacre\", \"matthew\", \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\", \"mean\", \"mean\", \"mean\", \"meanwhile,\", \"medical\", \"medical\", \"medical\", \"medical\", \"memory\", \"memory\", \"memory\", \"meters.\", \"methanol\", \"method,\", \"micro\", \"might\", \"might\", \"might\", \"might\", \"might\", \"mike\", \"mike\", \"mike\", \"mild\", \"miles.\", \"military\", \"military\", \"minnesota\", \"minnesota\", \"minnesota\", \"modem\", \"modem\", \"moncton\", \"money\", \"money\", \"money\", \"monitor\", \"montreal\", \"montreal\", \"moral\", \"morality\", \"motherboard\", \"motherboards\", \"motif\", \"motorcycle\", \"mouse\", \"mouse\", \"much\", \"much\", \"much\", \"much\", \"much\", \"multi\", \"murdering\", \"muslim\", \"muslim\", \"must\", \"must\", \"must\", \"must\", \"must\", \"mydisplay,\", \"myers:\", \"n3jxp\", \"nasa\", \"nasa\", \"national\", \"national\", \"national\", \"national\", \"nazi\", \"ncsa\", \"nearest\", \"need\", \"need\", \"need\", \"need\", \"need\", \"nerve\", \"nerves\", \"neutral\", \"neutral\", \"neutral\", \"neutral\", \"never\", \"never\", \"never\", \"never\", \"never\", \"newsletter\", \"newsletter\", \"next\", \"next\", \"next\", \"next\", \"nhl.\", \"nick\", \"nick\", \"none,\", \"nonsense.\", \"nords\", \"norris\", \"norton\", \"norway\", \"norway\", \"norway\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing,\", \"nothing,\", \"nubus\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"number\", \"number\", \"number\", \"number\", \"number\", \"obfuscation\", \"object,\", \"offense\", \"offer.\", \"office)\", \"omnipotent\", \"osf/motif\", \"ottawa\", \"ottawa\", \"ottoman\", \"out\\\"\", \"outlet\", \"outlet\", \"outline\", \"output\", \"output\", \"overlap\", \"owner\", \"packard\", \"page\", \"page\", \"page\", \"page\", \"pain\", \"pairs\", \"palestine\", \"palestinean\", \"palestinian\", \"palestinians\", \"parish\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"patents\", \"paying\", \"penguins\", \"pens\", \"people\", \"people\", \"people\", \"people\", \"people\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period.\", \"period:\", \"phigs\", \"philadelphia\", \"philadelphia\", \"philadelphia\", \"pick\", \"pick\", \"pick\", \"picture\", \"picture\", \"picture\", \"picture\", \"pitched\", \"pitched\", \"pitching\", \"pittsburgh\", \"pittsburgh\", \"pittsburgh\", \"pittsburgh\", \"play\", \"play\", \"play\", \"play:\", \"player\", \"player\", \"player,\", \"player,\", \"player.\", \"players\", \"players\", \"players,\", \"playing\", \"please\", \"please\", \"please\", \"please\", \"point\", \"point\", \"point\", \"point\", \"police\", \"police\", \"police\", \"policy\", \"policy\", \"political\", \"port\", \"port\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"powerpc\", \"president\", \"president\", \"president's\", \"price:\", \"printer\", \"printer,\", \"printers\", \"privacy\", \"privacy\", \"private\", \"private\", \"prize\", \"probably\", \"probably\", \"probably\", \"probably\", \"probably\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"proceeds\", \"program\", \"program,\", \"programming\", \"programs\", \"promises\", \"promises\", \"prompt\", \"proposal\", \"protect\", \"protects\", \"providence\", \"public\", \"public\", \"public\", \"puck\", \"pulse\", \"quality.\", \"quebec\", \"question\", \"question\", \"question\", \"question\", \"question\", \"rangers\", \"rangers\", \"rangers\", \"rangers\", \"reactions\", \"read\", \"read\", \"read\", \"read\", \"read\", \"reality,\", \"reality,\", \"really\", \"really\", \"really\", \"really\", \"really\", \"rear\", \"rear\", \"receives\", \"rectangular\", \"reds\", \"refering\", \"rejecting\", \"relay\", \"relay\", \"religion\", \"religious\", \"religious\", \"reported\", \"reported\", \"reported\", \"reported\", \"research\", \"research\", \"research\", \"research\", \"reserve\", \"resistor\", \"resource\", \"respected\", \"respected\", \"respected\", \"restart\", \"retail\", \"ride\", \"riding\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rights\", \"rights\", \"risc\", \"risc\", \"risc\", \"road.\", \"road.\", \"robinson\", \"rochester\", \"rochester\", \"rolling\", \"royals\", \"rs/6000\", \"rs/6000\", \"runner\", \"runner\", \"runs,\", \"russian\", \"russian\", \"russian\", \"sabbath\", \"sabbath\", \"sabres\", \"said\", \"said\", \"said\", \"said\", \"said,\", \"said,\", \"said,\", \"said,\", \"sampling\", \"satellite\", \"say,\", \"say,\", \"say,\", \"say,\", \"says,\", \"says,\", \"says,\", \"score\", \"scored\", \"scorer\", \"scores\", \"scoring.\", \"scsi\", \"scsi-1\", \"scsi-2\", \"sea.\", \"seagate\", \"season.\", \"season.\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"secret\", \"secure\", \"secure.\", \"secure.\", \"security\", \"security\", \"seems\", \"seems\", \"seems\", \"seems\", \"seems\", \"segment\", \"selective\", \"selective\", \"send\", \"send\", \"send\", \"send\", \"sensor\", \"sequences\", \"serdar\", \"server\", \"set.\", \"shameful\", \"shape,\", \"sheets\", \"shift\", \"shift\", \"shift\", \"shift\", \"shift\", \"shit\", \"shit\", \"shots\", \"shots\", \"shots\", \"sides.\", \"similarity\", \"simm\", \"simms\", \"since\", \"since\", \"since\", \"since\", \"since\", \"sing\", \"site\", \"sites\", \"sizes\", \"slaughter\", \"slots\", \"smokeless\", \"sockets\", \"software\", \"software\", \"software?\", \"solaris\", \"soldiers\", \"soldiers\", \"someone\", \"someone\", \"someone\", \"someone\", \"someone\", \"someone\", \"something\", \"something\", \"something\", \"something\", \"something\", \"son.\", \"son.\", \"soon.\\\"\", \"sound\", \"sound\", \"sound\", \"source\", \"source\", \"source:\", \"source:\", \"space\", \"spectacular\", \"speedstar\", \"spin\", \"sports\", \"spots\", \"springfield\", \"springfield\", \"stadium\", \"standings\", \"standings\", \"started\", \"started\", \"started\", \"started\", \"started\", \"stat\", \"state\", \"state\", \"state\", \"state\", \"state\", \"states\", \"states\", \"states\", \"states\", \"states\", \"stats\", \"stats\", \"steam\", \"steer\", \"steer\", \"steering\", \"steering\", \"stereo\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"subject:\", \"subject:\", \"suck\", \"suck\", \"sumgait\", \"summaries\", \"supply.\", \"surrender\", \"suspect.\", \"suter\", \"svga\", \"sweden\", \"sweden\", \"switzerland\", \"switzerland\", \"symbol\", \"synchronous\", \"synchronous\", \"syria\", \"system\", \"system\", \"system\", \"system\", \"system\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tampa\", \"tape\", \"tape\", \"tape,\", \"team\", \"team\", \"team\", \"team\", \"telecom\", \"temp\", \"temperature\", \"temperature\", \"terminal\", \"terminal\", \"terminal\", \"terminated\", \"thanks\", \"thanks\", \"thanks\", \"thanks\", \"thanks.\", \"thanks.\", \"thanx.\", \"that's\", \"that's\", \"that's\", \"that's\", \"then?\", \"there,\", \"there,\", \"there,\", \"there,\", \"there,\", \"things\", \"things\", \"things\", \"things\", \"things\", \"think\", \"think\", \"think\", \"third\", \"third\", \"third\", \"third\", \"third\", \"third\", \"three\", \"three\", \"three\", \"three\", \"three\", \"throttle\", \"tigers\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"titled\", \"token\", \"told\", \"told\", \"told\", \"told\", \"told\", \"tommy\", \"tonight,\", \"took\", \"took\", \"took\", \"toronto\", \"toronto\", \"toyota\", \"translations\", \"translations\", \"true\", \"true\", \"true\", \"true\", \"truetype\", \"truth\", \"truth\", \"tubes\", \"turkey\", \"turkish\", \"turks\", \"twin\", \"u.s.\", \"u.s.\", \"u.s.\", \"u.s.\", \"unit\", \"unit\", \"unit\", \"unit\", \"united\", \"united\", \"united\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"upgrade\", \"upgrade\", \"used\", \"used\", \"used\", \"used\", \"used\", \"user\", \"users\", \"users\", \"using\", \"using\", \"using\", \"using\", \"using\", \"utica\", \"utility\", \"utility\", \"utility\", \"uucp:\", \"vaginal\", \"vancouver\", \"vancouver\", \"verdict\", \"version\", \"version\", \"version\", \"versions\", \"vesa\", \"video\", \"video\", \"video\", \"violent\", \"vitamin\", \"voltage\", \"vram\", \"walls\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"war.\", \"warsaw\", \"washer\", \"washer\", \"washington,\", \"washington,\", \"washington,\", \"watching\", \"water\", \"water\", \"water\", \"water\", \"water\", \"we're\", \"we're\", \"we're\", \"we're\", \"weapons\", \"weighs\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well).\", \"well).\", \"well,\", \"well,\", \"well,\", \"well,\", \"went\", \"went\", \"went\", \"west\", \"west\", \"west\", \"west\", \"whether\", \"whether\", \"whether\", \"whether\", \"whether\", \"white,\", \"wibbled:\", \"widget\", \"widget,\", \"window\", \"window\", \"window.\", \"window.\", \"windows\", \"windows\", \"winmarks\", \"winnipeg\", \"wins\", \"wipe\", \"wire\", \"wire\", \"wire\", \"wireframe\", \"wireless\", \"wireless\", \"wiretap\", \"without\", \"without\", \"without\", \"without\", \"without\", \"women\", \"women\", \"women\", \"word\", \"word\", \"word\", \"word\", \"word\", \"words\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workers,\", \"workstation.\", \"would\", \"would\", \"would\", \"would\", \"would\", \"wounded\", \"writing.\", \"x-soviet\", \"x-windows\", \"xterm.\", \"yamaha\", \"yamaha\", \"yamaha\", \"yankees\", \"yassin\", \"year\", \"year\", \"year\", \"year.\", \"year.\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"yep.\", \"york\", \"york\", \"york\", \"york\", \"york\", \"york,\", \"york,\", \"zeos\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 15, 3, 18, 4, 20, 5, 11, 12, 2, 10, 8, 19, 14, 17, 6, 16, 13, 1, 9]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el80922224370416656218738041\", ldavis_el80922224370416656218738041_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el80922224370416656218738041\", ldavis_el80922224370416656218738041_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el80922224370416656218738041\", ldavis_el80922224370416656218738041_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb109d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 문서의 topic 비율은 [(1, 0.01465752), (4, 0.36243057), (6, 0.38144457), (14, 0.036303703), (17, 0.193759)]\n",
      "1 번째 문서의 topic 비율은 [(3, 0.17460015), (6, 0.40191194), (7, 0.048601992), (9, 0.07244057), (14, 0.15613459), (17, 0.10788236), (18, 0.022888267)]\n",
      "2 번째 문서의 topic 비율은 [(1, 0.03796233), (4, 0.12677692), (6, 0.6962279), (14, 0.076513246), (17, 0.049787838)]\n",
      "3 번째 문서의 topic 비율은 [(1, 0.029096112), (2, 0.03914954), (3, 0.055007655), (6, 0.26293182), (10, 0.01562253), (14, 0.23593898), (15, 0.0751292), (17, 0.26340106), (18, 0.015471263)]\n",
      "4 번째 문서의 topic 비율은 [(1, 0.47491115), (14, 0.49172446)]\n"
     ]
    }
   ],
   "source": [
    "for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "    if i==5:\n",
    "        break\n",
    "    print(i,'번째 문서의 topic 비율은',topic_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b74249f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topictable_per_doc(ldamodel, corpus):\n",
    "    topic_table = pd.DataFrame()\n",
    "\n",
    "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
    "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
    "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
    "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
    "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \n",
    "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
    "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
    "\n",
    "        # 모든 문서에 대해서 각각 아래를 수행\n",
    "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
    "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
    "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
    "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
    "            else:\n",
    "                break\n",
    "    return(topic_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "086f4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 제목 개수 : 1244184\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/19.%20Topic%20Modeling%20(LDA%2C%20BERT-Based)/dataset/abcnews-date-text.csv\")\n",
    "\n",
    "data = pd.read_csv(\"C://Users/kimchaeyeon/OneDrive - 서울여자대학교/바탕 화면/GDSC/abcnews-date-text.csv\",\n",
    "                   on_bad_lines = \"skip\")\n",
    "print('뉴스 제목 개수 :',len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "510e4fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publish_date                                      headline_text\n",
      "0      20030219  aba decides against community broadcasting lic...\n",
      "1      20030219     act fire witnesses must be aware of defamation\n",
      "2      20030219     a g calls for infrastructure protection summit\n",
      "3      20030219           air nz staff in aust strike for pay rise\n",
      "4      20030219      air nz strike to affect australian travellers\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eda4fe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=data[['headline_text']]\n",
    "text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "429266aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-13f3ee43b6ec>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['headline_text'] = text.apply(lambda row: nltk.word_tokenize(row['headline_text']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "text['headline_text'] = text.apply(lambda row: nltk.word_tokenize(row['headline_text']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cadf15ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       headline_text\n",
      "0  [aba, decides, against, community, broadcastin...\n",
      "1  [act, fire, witnesses, must, be, aware, of, de...\n",
      "2  [a, g, calls, for, infrastructure, protection,...\n",
      "3  [air, nz, staff, in, aust, strike, for, pay, r...\n",
      "4  [air, nz, strike, to, affect, australian, trav...\n"
     ]
    }
   ],
   "source": [
    "print(text.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "093b88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-23365fcb41de>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['headline_text'] = text['headline_text'].apply(lambda x: [word for word in x if word not in (stop_words)])\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "text['headline_text'] = text['headline_text'].apply(lambda x: [word for word in x if word not in (stop_words)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b900b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       headline_text\n",
      "0   [aba, decides, community, broadcasting, licence]\n",
      "1    [act, fire, witnesses, must, aware, defamation]\n",
      "2     [g, calls, infrastructure, protection, summit]\n",
      "3          [air, nz, staff, aust, strike, pay, rise]\n",
      "4  [air, nz, strike, affect, australian, travellers]\n"
     ]
    }
   ],
   "source": [
    "print(text.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe7ddd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       headline_text\n",
      "0       [aba, decide, community, broadcast, licence]\n",
      "1      [act, fire, witness, must, aware, defamation]\n",
      "2      [g, call, infrastructure, protection, summit]\n",
      "3          [air, nz, staff, aust, strike, pay, rise]\n",
      "4  [air, nz, strike, affect, australian, travellers]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-07a07065d0f6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['headline_text'] = text['headline_text'].apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])\n"
     ]
    }
   ],
   "source": [
    "text['headline_text'] = text['headline_text'].apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])\n",
    "print(text.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af3cfbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [decide, community, broadcast, licence]\n",
      "1      [fire, witness, must, aware, defamation]\n",
      "2    [call, infrastructure, protection, summit]\n",
      "3                   [staff, aust, strike, rise]\n",
      "4      [strike, affect, australian, travellers]\n",
      "Name: headline_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tokenized_doc = text['headline_text'].apply(lambda x: [word for word in x if len(word) > 3])\n",
    "print(tokenized_doc[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af0895a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-93127686f901>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['headline_text'] = detokenized_doc\n"
     ]
    }
   ],
   "source": [
    "# 역토큰화 (토큰화 작업을 되돌림)\n",
    "detokenized_doc = []\n",
    "for i in range(len(text)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "# 다시 text['headline_text']에 재저장\n",
    "text['headline_text'] = detokenized_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc257a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       decide community broadcast licence\n",
       "1       fire witness must aware defamation\n",
       "2    call infrastructure protection summit\n",
       "3                   staff aust strike rise\n",
       "4      strike affect australian travellers\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['headline_text'][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba5be4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬의 크기 : (1244184, 1000)\n"
     ]
    }
   ],
   "source": [
    "# 상위 1,000개의 단어를 보존 \n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000)\n",
    "X = vectorizer.fit_transform(text['headline_text'])\n",
    "\n",
    "# TF-IDF 행렬의 크기 확인\n",
    "print('TF-IDF 행렬의 크기 :',X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba1bcfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=10,learning_method='online',random_state=777,max_iter=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84afd093",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_top = lda_model.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca8bfa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00005784e-01 1.00000401e-01 1.00000837e-01 ... 1.00008966e-01\n",
      "  1.00003001e-01 1.00003989e-01]\n",
      " [1.00001271e-01 1.00000170e-01 1.00000702e-01 ... 1.00009027e-01\n",
      "  1.00004822e-01 6.11677308e+02]\n",
      " [1.00001893e-01 1.00000747e-01 5.29631843e+02 ... 1.00004665e-01\n",
      "  1.00003828e-01 1.00003730e-01]\n",
      " ...\n",
      " [1.00006258e-01 1.00000570e-01 1.00000388e-01 ... 1.00006276e-01\n",
      "  1.00001666e-01 1.00008566e-01]\n",
      " [1.00000280e-01 1.00000135e-01 1.00001609e-01 ... 1.00003391e-01\n",
      "  1.00001003e-01 1.00006488e-01]\n",
      " [1.03272231e+02 1.00000349e-01 1.00001881e-01 ... 1.00005116e-01\n",
      "  1.00004106e-01 1.00006425e-01]]\n",
      "(10, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.components_)\n",
    "print(lda_model.components_.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21bc3459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('australia', 20556.0), ('sydney', 11219.29), ('melbourne', 8765.73), ('kill', 6646.06), ('court', 6004.12)]\n",
      "Topic 2: [('coronavirus', 41719.62), ('covid', 28960.68), ('government', 9793.89), ('change', 7576.98), ('home', 7457.74)]\n",
      "Topic 3: [('south', 7102.98), ('death', 6825.39), ('speak', 5402.31), ('care', 4521.48), ('interview', 4058.71)]\n",
      "Topic 4: [('donald', 8536.49), ('restrictions', 6456.4), ('world', 6320.61), ('state', 6087.5), ('water', 4219.67)]\n",
      "Topic 5: [('vaccine', 8040.87), ('open', 6915.17), ('coast', 5990.55), ('warn', 5472.84), ('morrison', 5247.93)]\n",
      "Topic 6: [('trump', 14878.13), ('charge', 7717.96), ('health', 6836.95), ('murder', 6663.45), ('house', 6624.13)]\n",
      "Topic 7: [('australian', 13885.88), ('queensland', 13373.53), ('record', 9037.88), ('test', 7713.9), ('help', 5922.05)]\n",
      "Topic 8: [('case', 13146.83), ('police', 11143.1), ('live', 7528.03), ('border', 6855.54), ('tasmania', 5664.64)]\n",
      "Topic 9: [('victoria', 11777.5), ('school', 6009.78), ('attack', 5503.39), ('national', 4672.53), ('concern', 4112.28)]\n",
      "Topic 10: [('election', 8942.32), ('news', 8568.78), ('china', 8452.56), ('people', 6645.62), ('make', 6482.1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ana\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합. 1,000개의 단어가 저장됨.\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "\n",
    "get_topics(lda_model.components_,terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b71238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in c:\\ana\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\ana\\lib\\site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: tqdm in c:\\ana\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\ana\\lib\\site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\ana\\lib\\site-packages (from sentence_transformers) (1.24.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\ana\\lib\\site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: nltk in c:\\ana\\lib\\site-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: torchvision in c:\\ana\\lib\\site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\ana\\lib\\site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\ana\\lib\\site-packages (from sentence_transformers) (4.34.0)\n",
      "Requirement already satisfied: scipy in c:\\ana\\lib\\site-packages (from sentence_transformers) (1.9.1)\n",
      "Requirement already satisfied: requests in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: fsspec in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.7.1)\n",
      "Requirement already satisfied: sympy in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\n",
      "Requirement already satisfied: joblib in c:\\ana\\lib\\site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: click in c:\\ana\\lib\\site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\ana\\lib\\site-packages (from torchvision->sentence_transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\ana\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\ana\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.11)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\ana\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e22e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3199a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "         Supervised learning is the machine learning task of \n",
    "         learning a function that maps an input to an output based \n",
    "         on example input-output pairs.[1] It infers a function \n",
    "         from labeled training data consisting of a set of \n",
    "         training examples.[2] In supervised learning, each \n",
    "         example is a pair consisting of an input object \n",
    "         (typically a vector) and a desired output value (also \n",
    "         called the supervisory signal). A supervised learning \n",
    "         algorithm analyzes the training data and produces an \n",
    "         inferred function, which can be used for mapping new \n",
    "         examples. An optimal scenario will allow for the algorithm \n",
    "         to correctly determine the class labels for unseen \n",
    "         instances. This requires the learning algorithm to  \n",
    "         generalize from the training data to unseen situations \n",
    "         in a 'reasonable' way (see inductive bias).\n",
    "      \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ec02a651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram 개수 : 72\n",
      "trigram 다섯개만 출력 : ['algorithm analyzes training' 'algorithm correctly determine'\n",
      " 'algorithm generalize training' 'allow algorithm correctly'\n",
      " 'analyzes training data']\n"
     ]
    }
   ],
   "source": [
    "# 3개의 단어 묶음인 단어구 추출\n",
    "n_gram_range = (3, 3)\n",
    "stop_words = \"english\"\n",
    "\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "candidates = count.get_feature_names_out()\n",
    "\n",
    "print('trigram 개수 :',len(candidates))\n",
    "print('trigram 다섯개만 출력 :',candidates[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1dc8cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa5a23fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm analyzes training', 'learning algorithm generalize', 'learning machine learning', 'learning algorithm analyzes', 'algorithm generalize training']\n"
     ]
    }
   ],
   "source": [
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "print(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffba7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sum_sim(doc_embedding, candidate_embeddings, words, top_n, nr_candidates):\n",
    "    # 문서와 각 키워드들 간의 유사도\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
    "                                            candidate_embeddings)\n",
    "\n",
    "    # 코사인 유사도에 기반하여 키워드들 중 상위 top_n개의 단어를 pick.\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # 각 키워드들 중에서 가장 덜 유사한 키워드들간의 조합을 계산\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62c43feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['requires learning algorithm',\n",
       " 'signal supervised learning',\n",
       " 'learning function maps',\n",
       " 'algorithm analyzes training',\n",
       " 'learning machine learning']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=5, nr_candidates=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec9a4d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set training examples',\n",
       " 'generalize training data',\n",
       " 'requires learning algorithm',\n",
       " 'supervised learning algorithm',\n",
       " 'learning machine learning']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=5, nr_candidates=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a2ee4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr(doc_embedding, candidate_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # 문서와 각 키워드들 간의 유사도가 적혀있는 리스트\n",
    "    word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    word_similarity = cosine_similarity(candidate_embeddings)\n",
    "\n",
    "    # 문서와 가장 높은 유사도를 가진 키워드의 인덱스를 추출.\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # keywords_idx = [2]\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "\n",
    "    # 가장 높은 유사도를 가진 키워드의 인덱스를 제외한 문서의 인덱스들\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # ==> candidates_idx = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10 ... 중략 ...]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    # 최고의 키워드는 이미 추출했으므로 top_n-1번만큼 아래를 반복.\n",
    "    # ex) top_n = 5라면, 아래의 loop는 4번 반복됨.\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # MMR을 계산\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # keywords & candidates를 업데이트\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce892915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithm generalize training',\n",
       " 'supervised learning algorithm',\n",
       " 'learning machine learning',\n",
       " 'learning algorithm analyzes',\n",
       " 'learning algorithm generalize']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad4d42c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithm generalize training',\n",
       " 'labels unseen instances',\n",
       " 'new examples optimal',\n",
       " 'determine class labels',\n",
       " 'supervised learning algorithm']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2731a0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"instal\" - maybe you meant \"install\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\ana\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\ana\\lib\\site-packages (from konlpy) (4.9.1)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\ana\\lib\\site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\ana\\lib\\site-packages (from konlpy) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\ana\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\ana\\lib\\site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip instal sentence_transformers\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f3f8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7844dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "드 론 활 용 범 위 도 점 차 확 대 되 고 있 다. 최 근 에 는 미 세 먼 지 관 리 에 드 론 이 활 용 되 고 있 다\n",
    ".\n",
    "서 울 시 는 '미 세 먼 지 계 절 관 리 제' 기 간 인 지 난 달 부 터 오 는 3월 까 지 4개 월 간 드 론 에 측 정\n",
    "장 치 를 달 아 미 세 먼 지 집 중 관 리 를 실 시 하 고 있 다.\n",
    "드 론 은 산 업 단 지 와 사 업 장 밀 집 지 역 을 날 아 다 니 며 미 세 먼 지 배 출 수 치 를 점 검 하 고 , 현 장\n",
    "모 습 을 영 상 으 로 담 는 다.\n",
    "영 상 을 통 해 미 세 먼 지 방 지 시 설 을 제 대 로 가 동 하 지 않 는 업 체 와 무 허 가 시 설 에 대 한 단\n",
    "속 이 한 층 수 월 해 질 전 망 이 다.\n",
    "드 론 활 용 에 가 장 적 극 적 인 소 방 청 은 광 범 위 하 고 복 합 적 인 재 난 대 응 차 원 에 서 드 론 과\n",
    "관 련 전 문 인 력 보 강 을 꾸 준 히 이 어 가 고 있 다.\n",
    "지 난 해 말 기 준 소 방 청 이 보 유 한 드 론 은 총 304대 , 드 론 조 종 자 격 증 을 갖 춘 소 방 대 원 의\n",
    "경 우 1,860명 이 다.\n",
    "이 중 실 기 평 가 지 도 자 격 증 까 지 갖 춘 ‘ 드 론 전 문 가 ’ 21명 도 배 치 돼 있 다.\n",
    "소 방 청 관 계 자 는 \"소 방 드 론 은 재 난 현 장 에 서 영 상 정 보 를 수 집 , 산 악 ㆍ 수 난 사 고 시 인 명\n",
    "수 색 · 구 조 활 동 ,\n",
    "유 독 가 스 · 폭 발 사 고 시 대 원 안 전 확 보 등 에 활 용 된 다\"며\n",
    "\"향 후 화 재 진 압 , 인 명 구 조 등 에 도 드 론 을 활 용 하 기 위 해 연 구 개 발(R&D)을 하 고 있 다\"고\n",
    "말 했 다.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d648cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태깅 10개만 출력: [('\\n', 'Foreign'), ('드', 'Noun'), ('론', 'Noun'), ('활', 'Noun'), ('용', 'Noun'), ('범', 'Noun'), ('위', 'Noun'), ('도', 'Noun'), ('점', 'Noun'), ('차', 'Noun')]\n",
      "명사추출: 드 론 활 용 범 위 도 점 차 확 고 최 세 관 리 드 론 이 활 용 고 울 시 세 계 절 관 리 제 기 간 인 난 달 부 터 오 개 월 간 드 론 정 장 치 를 달 세 집 중 관 리 를 실 시 고 드 론 은 산 업 단 사 업 장 밀 집 역 날 니 며 세 배 수 치 를 점 검 고 현 장 모 습 영 상 로 담 영 상 통 해 세 방 시 설 제 로 업 체 무 시 설 단 속 이 층 수 월 해 질 전 망 이 드 론 활 용 장 적 적 인 소 방 청 은 광 범 위 고 복 합 적 인 재 난 응 차 원 드 론 과 관 전 문 인 보 강 준 이 고 난 해 말 기 준 소 방 청 이 보 유 드 론 은 총 드 론 조 종 자 격 증 갖 소 방 원 의 경 명 이 이 중 실 기 평 도 자 격 증 갖 드 론 전 문 명 도 배 치 소 방 청 관 계 자 소 방 드 론 은 재 난 현 장 영 상 정 보 를 수 집 산 악 수 난 사 고 시 인 명 수 색 구 조 활 유 독 스 폭 발 사 고 시 원 안 전 확 보 등 활 용 며 향 후 화 재 진 압 인 명 구 조 등 도 드 론 활 용 기 위 해 연 구 개 발 고 고 말\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "tokenized_doc= okt.pos(doc)\n",
    "tokenized_nouns = ' '.join([word[0] for word in tokenized_doc if word[1] == 'Noun'])\n",
    "\n",
    "print('품사 태깅 10개만 출력:', tokenized_doc[:10])\n",
    "print('명사추출:', tokenized_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "202c4ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-530a8fc28f32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_gram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_gram_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokenized_nouns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trigram 개 수 :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trigram 다 섯 개 만 출 력 :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \"\"\"\n\u001b[0;32m   1282\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1221\u001b[0m                     \u001b[1;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "n_gram_range = (2, 3)\n",
    "count = CountVectorizer(ngram_range=n_gram_range).fit([tokenized_nouns])\n",
    "candidates = count.get_feature_names_out()\n",
    "print('trigram 개 수 :',len(candidates))\n",
    "print('trigram 다 섯 개 만 출 력 :',candidates[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5a773ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contextualized-topic-models in c:\\ana\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.56.0 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (4.64.1)\n",
      "Requirement already satisfied: wordcloud>=1.8.1 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (1.9.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (1.9.1)\n",
      "Requirement already satisfied: gensim>=3.8.3 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.19.1 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (1.24.4)\n",
      "Requirement already satisfied: sentence-transformers>=1.1.1 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (2.2.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (2.0.1)\n",
      "Requirement already satisfied: ipywidgets==7.5.1 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (7.5.1)\n",
      "Requirement already satisfied: ipython==7.16.1 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (7.16.1)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (3.5.2)\n",
      "Requirement already satisfied: torchvision>=0.7.0 in c:\\ana\\lib\\site-packages (from contextualized-topic-models) (0.15.2)\n",
      "Requirement already satisfied: decorator in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (5.1.1)\n",
      "Requirement already satisfied: backcall in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (3.0.20)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (0.4.5)\n",
      "Requirement already satisfied: pygments in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (2.11.2)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\ana\\lib\\site-packages (from ipython==7.16.1->contextualized-topic-models) (63.4.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\ana\\lib\\site-packages (from ipywidgets==7.5.1->contextualized-topic-models) (5.5.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\ana\\lib\\site-packages (from ipywidgets==7.5.1->contextualized-topic-models) (5.5.6)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\ana\\lib\\site-packages (from ipywidgets==7.5.1->contextualized-topic-models) (3.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\ana\\lib\\site-packages (from gensim>=3.8.3->contextualized-topic-models) (5.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\ana\\lib\\site-packages (from matplotlib>=3.1.3->contextualized-topic-models) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\ana\\lib\\site-packages (from matplotlib>=3.1.3->contextualized-topic-models) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\ana\\lib\\site-packages (from matplotlib>=3.1.3->contextualized-topic-models) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\ana\\lib\\site-packages (from matplotlib>=3.1.3->contextualized-topic-models) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\ana\\lib\\site-packages (from matplotlib>=3.1.3->contextualized-topic-models) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\ana\\lib\\site-packages (from matplotlib>=3.1.3->contextualized-topic-models) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\ana\\lib\\site-packages (from matplotlib>=3.1.3->contextualized-topic-models) (0.11.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\ana\\lib\\site-packages (from sentence-transformers>=1.1.1->contextualized-topic-models) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=1.1.1->contextualized-topic-models) (0.16.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\ana\\lib\\site-packages (from sentence-transformers>=1.1.1->contextualized-topic-models) (1.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=1.1.1->contextualized-topic-models) (4.34.0)\n",
      "Requirement already satisfied: nltk in c:\\ana\\lib\\site-packages (from sentence-transformers>=1.1.1->contextualized-topic-models) (3.7)\n",
      "Requirement already satisfied: filelock in c:\\ana\\lib\\site-packages (from torch>=1.6.0->contextualized-topic-models) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\ana\\lib\\site-packages (from torch>=1.6.0->contextualized-topic-models) (4.3.0)\n",
      "Requirement already satisfied: sympy in c:\\ana\\lib\\site-packages (from torch>=1.6.0->contextualized-topic-models) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\ana\\lib\\site-packages (from torch>=1.6.0->contextualized-topic-models) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\ana\\lib\\site-packages (from torch>=1.6.0->contextualized-topic-models) (2.11.3)\n",
      "Requirement already satisfied: requests in c:\\ana\\lib\\site-packages (from torchvision>=0.7.0->contextualized-topic-models) (2.28.1)\n",
      "Requirement already satisfied: fsspec in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=1.1.1->contextualized-topic-models) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=1.1.1->contextualized-topic-models) (6.0)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models) (6.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models) (7.3.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\ana\\lib\\site-packages (from jedi>=0.10->ipython==7.16.1->contextualized-topic-models) (0.8.3)\n",
      "Requirement already satisfied: jupyter_core in c:\\ana\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (4.11.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\ana\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\ana\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (4.16.0)\n",
      "Requirement already satisfied: wcwidth in c:\\ana\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.16.1->contextualized-topic-models) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ana\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->contextualized-topic-models) (1.16.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models) (0.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models) (0.3.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\ana\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (6.4.12)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\ana\\lib\\site-packages (from jinja2->torch>=1.6.0->contextualized-topic-models) (2.0.1)\n",
      "Requirement already satisfied: click in c:\\ana\\lib\\site-packages (from nltk->sentence-transformers>=1.1.1->contextualized-topic-models) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\ana\\lib\\site-packages (from nltk->sentence-transformers>=1.1.1->contextualized-topic-models) (1.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ana\\lib\\site-packages (from requests->torchvision>=0.7.0->contextualized-topic-models) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\ana\\lib\\site-packages (from requests->torchvision>=0.7.0->contextualized-topic-models) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ana\\lib\\site-packages (from requests->torchvision>=0.7.0->contextualized-topic-models) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\ana\\lib\\site-packages (from requests->torchvision>=0.7.0->contextualized-topic-models) (2.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn->sentence-transformers>=1.1.1->contextualized-topic-models) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\ana\\lib\\site-packages (from sympy->torch>=1.6.0->contextualized-topic-models) (1.2.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (21.4.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.13.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (23.2.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.5.5)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (6.4.4)\n",
      "Requirement already satisfied: entrypoints in c:\\ana\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models) (0.4)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\ana\\lib\\site-packages (from jupyter_core->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (302)\n",
      "Requirement already satisfied: testpath in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (4.12.2)\n",
      "Requirement already satisfied: defusedxml in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.7.1)\n",
      "Requirement already satisfied: bleach in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.5.13)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.8.4)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\ana\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\ana\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\ana\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\ana\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (2.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\ana\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\ana\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install contextualized-topic-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce27e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"dbpedia_sample_abstract_20k_unprep.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d43c6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "67a5d892",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\hdbscan_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\plots.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\prediction.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\robust_single_linkage_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\validity.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_hdbscan.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_prediction_utils.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_rsl.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  running build_ext\n",
      "  cythoning hdbscan/_hdbscan_tree.pyx to hdbscan\\_hdbscan_tree.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-zwgn4sew\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-gwrm2873\\hdbscan_0d0fe3379a354aa9bf6d0334db383993\\hdbscan\\_hdbscan_tree.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan\\_hdbscan_linkage.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-zwgn4sew\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-gwrm2873\\hdbscan_0d0fe3379a354aa9bf6d0334db383993\\hdbscan\\_hdbscan_linkage.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan\\_hdbscan_boruvka.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-zwgn4sew\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-gwrm2873\\hdbscan_0d0fe3379a354aa9bf6d0334db383993\\hdbscan\\_hdbscan_boruvka.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan\\_hdbscan_reachability.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-zwgn4sew\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-gwrm2873\\hdbscan_0d0fe3379a354aa9bf6d0334db383993\\hdbscan\\_hdbscan_reachability.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_prediction_utils.pyx to hdbscan\\_prediction_utils.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-zwgn4sew\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-gwrm2873\\hdbscan_0d0fe3379a354aa9bf6d0334db383993\\hdbscan\\_prediction_utils.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/dist_metrics.pyx to hdbscan\\dist_metrics.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-zwgn4sew\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-gwrm2873\\hdbscan_0d0fe3379a354aa9bf6d0334db383993\\hdbscan\\dist_metrics.pxd\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'hdbscan._hdbscan_tree' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached bertopic-0.15.0-py2.py3-none-any.whl (143 kB)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Using cached umap_learn-0.5.4-py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\ana\\lib\\site-packages (from bertopic) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\ana\\lib\\site-packages (from bertopic) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\ana\\lib\\site-packages (from bertopic) (1.24.4)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\ana\\lib\\site-packages (from bertopic) (2.2.2)\n",
      "Collecting hdbscan>=0.8.29\n",
      "  Using cached hdbscan-0.8.33.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\ana\\lib\\site-packages (from bertopic) (5.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\ana\\lib\\site-packages (from bertopic) (1.0.2)\n",
      "Requirement already satisfied: cython<3,>=0.27 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (0.29.32)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\ana\\lib\\site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (4.34.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.1)\n",
      "Requirement already satisfied: nltk in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Requirement already satisfied: torchvision in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.16.4)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.5)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\ana\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.10-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.3.0)\n",
      "Requirement already satisfied: fsspec in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.7.1)\n",
      "Requirement already satisfied: requests in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: setuptools in c:\\ana\\lib\\site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (63.4.1)\n",
      "Collecting numba>=0.51.2\n",
      "  Using cached numba-0.58.1-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Using cached llvmlite-0.41.1-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ana\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.11.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.3.3)\n",
      "Requirement already satisfied: click in c:\\ana\\lib\\site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\ana\\lib\\site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\ana\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\ana\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\ana\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.2.1)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "Failed to build hdbscan\n",
      "Collecting bertopic[visualization]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: bertopic 0.15.0 does not provide the extra 'visualization'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\hdbscan_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\plots.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\prediction.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\robust_single_linkage_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\validity.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_hdbscan.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_prediction_utils.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_rsl.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  running build_ext\n",
      "  cythoning hdbscan/_hdbscan_tree.pyx to hdbscan\\_hdbscan_tree.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-pm6k5gh7\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-_96qdxsh\\hdbscan_8d83369be8034b97a0d28369629ba430\\hdbscan\\_hdbscan_tree.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan\\_hdbscan_linkage.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-pm6k5gh7\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-_96qdxsh\\hdbscan_8d83369be8034b97a0d28369629ba430\\hdbscan\\_hdbscan_linkage.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan\\_hdbscan_boruvka.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-pm6k5gh7\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-_96qdxsh\\hdbscan_8d83369be8034b97a0d28369629ba430\\hdbscan\\_hdbscan_boruvka.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan\\_hdbscan_reachability.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-pm6k5gh7\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-_96qdxsh\\hdbscan_8d83369be8034b97a0d28369629ba430\\hdbscan\\_hdbscan_reachability.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_prediction_utils.pyx to hdbscan\\_prediction_utils.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-pm6k5gh7\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-_96qdxsh\\hdbscan_8d83369be8034b97a0d28369629ba430\\hdbscan\\_prediction_utils.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/dist_metrics.pyx to hdbscan\\dist_metrics.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-pm6k5gh7\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-_96qdxsh\\hdbscan_8d83369be8034b97a0d28369629ba430\\hdbscan\\dist_metrics.pxd\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'hdbscan._hdbscan_tree' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached bertopic-0.15.0-py2.py3-none-any.whl (143 kB)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Using cached umap_learn-0.5.4-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\ana\\lib\\site-packages (from bertopic[visualization]) (1.24.4)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\ana\\lib\\site-packages (from bertopic[visualization]) (2.2.2)\n",
      "Collecting hdbscan>=0.8.29\n",
      "  Using cached hdbscan-0.8.33.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\ana\\lib\\site-packages (from bertopic[visualization]) (5.9.0)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\ana\\lib\\site-packages (from bertopic[visualization]) (4.64.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\ana\\lib\\site-packages (from bertopic[visualization]) (1.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\ana\\lib\\site-packages (from bertopic[visualization]) (2.1.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic[visualization]) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic[visualization]) (1.9.1)\n",
      "Requirement already satisfied: cython<3,>=0.27 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic[visualization]) (0.29.32)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic[visualization]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic[visualization]) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic[visualization]) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\ana\\lib\\site-packages (from plotly>=4.7.0->bertopic[visualization]) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic[visualization]) (2.2.0)\n",
      "Requirement already satisfied: nltk in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (3.7)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.16.4)\n",
      "Requirement already satisfied: torchvision in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.15.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.1.99)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (4.34.0)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from tqdm>=4.41.1->bertopic[visualization]) (0.4.5)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\ana\\lib\\site-packages (from umap-learn>=0.5.0->bertopic[visualization]) (0.55.1)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.10-py3-none-any.whl\n",
      "Requirement already satisfied: fsspec in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (6.0)\n",
      "Requirement already satisfied: requests in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.6.0)\n",
      "Collecting numba>=0.51.2\n",
      "  Using cached numba-0.58.1-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Using cached llvmlite-0.41.1-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ana\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic[visualization]) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.11.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.3.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\ana\\lib\\site-packages (from nltk->sentence-transformers>=0.4.1->bertopic[visualization]) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\ana\\lib\\site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic[visualization]) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\ana\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\ana\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\ana\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.2.1)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "Failed to build hdbscan\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic\n",
    "!pip install bertopic[visualization]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "35443dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopicNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running bdist_wheel"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached bertopic-0.15.0-py2.py3-none-any.whl (143 kB)\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\ana\\lib\\site-packages (from bertopic) (5.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\ana\\lib\\site-packages (from bertopic) (1.24.4)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\ana\\lib\\site-packages (from bertopic) (4.64.1)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Using cached umap_learn-0.5.4-py3-none-any.whl\n",
      "Collecting hdbscan>=0.8.29\n",
      "  Using cached hdbscan-0.8.33.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\ana\\lib\\site-packages (from bertopic) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\ana\\lib\\site-packages (from bertopic) (1.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\ana\\lib\\site-packages (from bertopic) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.9.1)\n",
      "Requirement already satisfied: cython<3,>=0.27 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (0.29.32)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\ana\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ana\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\ana\\lib\\site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.16.4)\n",
      "Requirement already satisfied: torchvision in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.15.2)\n",
      "Requirement already satisfied: nltk in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.99)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (4.34.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\ana\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.5)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.10-py3-none-any.whl\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\ana\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\n",
      "Requirement already satisfied: fsspec in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: requests in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\ana\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\ana\\lib\\site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.38.0)\n",
      "Collecting numba>=0.51.2\n",
      "  Using cached numba-0.58.1-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Using cached llvmlite-0.41.1-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ana\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\ana\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.11.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\ana\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.3.3)\n",
      "Requirement already satisfied: click in c:\\ana\\lib\\site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\ana\\lib\\site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\ana\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\ana\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\ana\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\ana\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.2.1)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "Failed to build hdbscan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\hdbscan_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\plots.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\prediction.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\robust_single_linkage_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\validity.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_hdbscan.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_prediction_utils.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_rsl.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  running build_ext\n",
      "  cythoning hdbscan/_hdbscan_tree.pyx to hdbscan\\_hdbscan_tree.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-43i664zj\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-de6szuat\\hdbscan_e9bcada81926461482566e753b1463ff\\hdbscan\\_hdbscan_tree.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan\\_hdbscan_linkage.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-43i664zj\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-de6szuat\\hdbscan_e9bcada81926461482566e753b1463ff\\hdbscan\\_hdbscan_linkage.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan\\_hdbscan_boruvka.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-43i664zj\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-de6szuat\\hdbscan_e9bcada81926461482566e753b1463ff\\hdbscan\\_hdbscan_boruvka.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan\\_hdbscan_reachability.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-43i664zj\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-de6szuat\\hdbscan_e9bcada81926461482566e753b1463ff\\hdbscan\\_hdbscan_reachability.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_prediction_utils.pyx to hdbscan\\_prediction_utils.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-43i664zj\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-de6szuat\\hdbscan_e9bcada81926461482566e753b1463ff\\hdbscan\\_prediction_utils.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/dist_metrics.pyx to hdbscan\\dist_metrics.c\n",
      "  C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-build-env-43i664zj\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\kimchaeyeon\\AppData\\Local\\Temp\\pip-install-de6szuat\\hdbscan_e9bcada81926461482566e753b1463ff\\hdbscan\\dist_metrics.pxd\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'hdbscan._hdbscan_tree' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\ana\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "780b9b25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-48ce5cafa364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b314caf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\",\n",
       " 'My brother is in the market for a high-performance video card that supports\\nVESA local bus with 1-2MB RAM.  Does anyone have suggestions/ideas on:\\n\\n  - Diamond Stealth Pro Local Bus\\n\\n  - Orchid Farenheit 1280\\n\\n  - ATI Graphics Ultra Pro\\n\\n  - Any other high-performance VLB card\\n\\n\\nPlease post or email.  Thank you!\\n\\n  - Matt\\n',\n",
       " '\\n\\n\\n\\n\\tFinally you said what you dream about. Mediterranean???? That was new....\\n\\tThe area will be \"greater\" after some years, like your \"holocaust\" numbers......\\n\\n\\n\\n\\n\\t\\t*****\\n\\tIs\\'t July in USA now????? Here in Sweden it\\'s April and still cold.\\n\\tOr have you changed your calendar???\\n\\n\\n\\t\\t\\t\\t\\t\\t    ****************\\n\\t\\t\\t\\t\\t\\t    ******************\\n\\t\\t\\t    ***************\\n\\n\\n\\tNOTHING OF THE MENTIONED IS TRUE, BUT LET SAY IT\\'s TRUE.\\n\\t\\n\\tSHALL THE AZERI WOMEN AND CHILDREN GOING TO PAY THE PRICE WITH\\n\\t\\t\\t\\t\\t\\t    **************\\n\\tBEING RAPED, KILLED AND TORTURED BY THE ARMENIANS??????????\\n\\t\\n\\tHAVE YOU HEARDED SOMETHING CALLED: \"GENEVA CONVENTION\"???????\\n\\tYOU FACIST!!!!!\\n\\n\\n\\n\\tOhhh i forgot, this is how Armenians fight, nobody has forgot\\n\\tyou killings, rapings and torture against the Kurds and Turks once\\n\\tupon a time!\\n      \\n       \\n\\n\\nOhhhh so swedish RedCross workers do lie they too? What ever you say\\n\"regional killer\", if you don\\'t like the person then shoot him that\\'s your policy.....l\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n\\tConfused?????\\t\\t\\t\\t\\t\\t\\t\\ti\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n        Search Turkish planes? You don\\'t know what you are talking about.\\ti\\n        Turkey\\'s government has announced that it\\'s giving weapons  <-----------i\\n        to Azerbadjan since Armenia started to attack Azerbadjan\\t\\t\\n        it self, not the Karabag province. So why search a plane for weapons\\t\\n        since it\\'s content is announced to be weapons?   \\n\\n\\tIf there is one that\\'s confused then that\\'s you! We have the right (and we do)\\n\\tto give weapons to the Azeris, since Armenians started the fight in Azerbadjan!\\n \\n\\n\\n\\tShoot down with what? Armenian bread and butter? Or the arms and personel \\n\\tof the Russian army?\\n\\n\\n',\n",
       " \"\\nThink!\\n\\nIt's the SCSI card doing the DMA transfers NOT the disks...\\n\\nThe SCSI card can do DMA transfers containing data from any of the SCSI devices\\nit is attached when it wants to.\\n\\nAn important feature of SCSI is the ability to detach a device. This frees the\\nSCSI bus for other devices. This is typically used in a multi-tasking OS to\\nstart transfers on several devices. While each device is seeking the data the\\nbus is free for other commands and data transfers. When the devices are\\nready to transfer the data they can aquire the bus and send the data.\\n\\nOn an IDE bus when you start a transfer the bus is busy until the disk has seeked\\nthe data and transfered it. This is typically a 10-20ms second lock out for other\\nprocesses wanting the bus irrespective of transfer time.\\n\",\n",
       " '1)    I have an old Jasmine drive which I cannot use with my new system.\\n My understanding is that I have to upsate the driver with a more modern\\none in order to gain compatability with system 7.0.1.  does anyone know\\nof an inexpensive program to do this?  ( I have seen formatters for <$20\\nbuit have no idea if they will work)\\n \\n2)     I have another ancient device, this one a tape drive for which\\nthe back utility freezes the system if I try to use it.  THe drive is a\\njasmine direct tape (bought used for $150 w/ 6 tapes, techmar\\nmechanism).  Essentially I have the same question as above, anyone know\\nof an inexpensive beckup utility I can use with system 7.0.1']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "docs[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78f15265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문서의 수 : 18846\n"
     ]
    }
   ],
   "source": [
    "print('총 문서의 수 :', len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1350ee9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BERTopic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-7698afa733ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtopics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'각 문서의 토픽 번호 리스트 :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'첫번째 문서의 토픽 번호 :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BERTopic' is not defined"
     ]
    }
   ],
   "source": [
    "model = BERTopic()\n",
    "topics, probabilities = model.fit_transform(docs)\n",
    "\n",
    "print('각 문서의 토픽 번호 리스트 :',len(topics))\n",
    "print('첫번째 문서의 토픽 번호 :', topics[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54312b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic_info()['Count'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068b2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc5de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9219b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470bc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ce2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e2169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc6dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd9599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b2536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
